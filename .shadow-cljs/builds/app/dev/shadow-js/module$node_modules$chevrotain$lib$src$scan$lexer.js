["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/chevrotain/lib/src/scan/lexer.js"],"~:js","shadow$provide.module$node_modules$chevrotain$lib$src$scan$lexer=function(global,require,module,exports){function validateRegExpPattern(tokenTypes){var errors=[];tokenTypes=utils_1.filter(tokenTypes,function(currTokType){return utils_1.isRegExp(currTokType.PATTERN)});errors=errors.concat(findEndOfInputAnchor(tokenTypes));errors=errors.concat(findStartOfInputAnchor(tokenTypes));errors=errors.concat(findUnsupportedFlags(tokenTypes));errors=errors.concat(findDuplicatePatterns(tokenTypes));return errors=\nerrors.concat(findEmptyMatchRegExps(tokenTypes))}function findMissingPatterns(tokenTypes){var tokenTypesWithMissingPattern=utils_1.filter(tokenTypes,function(currType){return!utils_1.has(currType,\"PATTERN\")}),errors=utils_1.map(tokenTypesWithMissingPattern,function(currType){return{message:\"Token Type: -\\x3e\"+currType.name+\"\\x3c- missing static 'PATTERN' property\",type:lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,tokenTypes:[currType]}});tokenTypes=utils_1.difference(tokenTypes,tokenTypesWithMissingPattern);\nreturn{errors,valid:tokenTypes}}function findInvalidPatterns(tokenTypes){var tokenTypesWithInvalidPattern=utils_1.filter(tokenTypes,function(currType){currType=currType.PATTERN;return!utils_1.isRegExp(currType)&&!utils_1.isFunction(currType)&&!utils_1.has(currType,\"exec\")&&!utils_1.isString(currType)}),errors=utils_1.map(tokenTypesWithInvalidPattern,function(currType){return{message:\"Token Type: -\\x3e\"+currType.name+\"\\x3c- static 'PATTERN' can only be a RegExp, a Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\ntype:lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,tokenTypes:[currType]}});tokenTypes=utils_1.difference(tokenTypes,tokenTypesWithInvalidPattern);return{errors,valid:tokenTypes}}function findEndOfInputAnchor(tokenTypes){var EndAnchorFinder=function(_super){function EndAnchorFinder(){var _this=null!==_super&&_super.apply(this,arguments)||this;_this.found=!1;return _this}__extends(EndAnchorFinder,_super);EndAnchorFinder.prototype.visitEndAnchor=function(node){this.found=!0};return EndAnchorFinder}(regexp_to_ast_1.BaseRegExpVisitor);\ntokenTypes=utils_1.filter(tokenTypes,function(currType){currType=currType.PATTERN;try{var regexpAst=reg_exp_parser_1.getRegExpAst(currType),endAnchorVisitor=new EndAnchorFinder;endAnchorVisitor.visit(regexpAst);return endAnchorVisitor.found}catch(e){return end_of_input.test(currType.source)}});return utils_1.map(tokenTypes,function(currType){return{message:\"Unexpected RegExp Anchor Error:\\n\\tToken Type: -\\x3e\"+currType.name+\"\\x3c- static 'PATTERN' cannot contain end of input anchor '$'\\n\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\\tfor details.\",\ntype:lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,tokenTypes:[currType]}})}function findEmptyMatchRegExps(tokenTypes){tokenTypes=utils_1.filter(tokenTypes,function(currType){return currType.PATTERN.test(\"\")});return utils_1.map(tokenTypes,function(currType){return{message:\"Token Type: -\\x3e\"+currType.name+\"\\x3c- static 'PATTERN' must not match an empty string\",type:lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,tokenTypes:[currType]}})}function findStartOfInputAnchor(tokenTypes){var StartAnchorFinder=\nfunction(_super){function StartAnchorFinder(){var _this=null!==_super&&_super.apply(this,arguments)||this;_this.found=!1;return _this}__extends(StartAnchorFinder,_super);StartAnchorFinder.prototype.visitStartAnchor=function(node){this.found=!0};return StartAnchorFinder}(regexp_to_ast_1.BaseRegExpVisitor);tokenTypes=utils_1.filter(tokenTypes,function(currType){currType=currType.PATTERN;try{var regexpAst=reg_exp_parser_1.getRegExpAst(currType),startAnchorVisitor=new StartAnchorFinder;startAnchorVisitor.visit(regexpAst);\nreturn startAnchorVisitor.found}catch(e){return start_of_input.test(currType.source)}});return utils_1.map(tokenTypes,function(currType){return{message:\"Unexpected RegExp Anchor Error:\\n\\tToken Type: -\\x3e\"+currType.name+\"\\x3c- static 'PATTERN' cannot contain start of input anchor '^'\\n\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\\tfor details.\",type:lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,tokenTypes:[currType]}})}function findUnsupportedFlags(tokenTypes){tokenTypes=\nutils_1.filter(tokenTypes,function(currType){currType=currType.PATTERN;return currType instanceof RegExp&&(currType.multiline||currType.global)});return utils_1.map(tokenTypes,function(currType){return{message:\"Token Type: -\\x3e\"+currType.name+\"\\x3c- static 'PATTERN' may NOT contain global('g') or multiline('m')\",type:lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,tokenTypes:[currType]}})}function findDuplicatePatterns(tokenTypes){var found=[],identicalPatterns=utils_1.map(tokenTypes,\nfunction(outerType){return utils_1.reduce(tokenTypes,function(result,innerType){outerType.PATTERN.source!==innerType.PATTERN.source||utils_1.contains(found,innerType)||innerType.PATTERN===lexer_public_1.Lexer.NA||(found.push(innerType),result.push(innerType));return result},[])});identicalPatterns=utils_1.compact(identicalPatterns);identicalPatterns=utils_1.filter(identicalPatterns,function(currIdenticalSet){return 1<currIdenticalSet.length});return utils_1.map(identicalPatterns,function(setOfIdentical){var tokenTypeNames=\nutils_1.map(setOfIdentical,function(currType){return currType.name});return{message:\"The same RegExp pattern -\\x3e\"+utils_1.first(setOfIdentical).PATTERN+\"\\x3c-has been used in all of the following Token Types: \"+(tokenTypeNames.join(\", \")+\" \\x3c-\"),type:lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,tokenTypes:setOfIdentical}})}function findInvalidGroupType(tokenTypes){tokenTypes=utils_1.filter(tokenTypes,function(clazz){if(!utils_1.has(clazz,\"GROUP\"))return!1;clazz=clazz.GROUP;\nreturn clazz!==lexer_public_1.Lexer.SKIPPED&&clazz!==lexer_public_1.Lexer.NA&&!utils_1.isString(clazz)});return utils_1.map(tokenTypes,function(currType){return{message:\"Token Type: -\\x3e\"+currType.name+\"\\x3c- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",type:lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,tokenTypes:[currType]}})}function findModesThatDoNotExist(tokenTypes,validModes){tokenTypes=utils_1.filter(tokenTypes,function(clazz){return void 0!==clazz.PUSH_MODE&&\n!utils_1.contains(validModes,clazz.PUSH_MODE)});return utils_1.map(tokenTypes,function(tokType){return{message:\"Token Type: -\\x3e\"+tokType.name+\"\\x3c- static 'PUSH_MODE' value cannot refer to a Lexer Mode -\\x3e\"+tokType.PUSH_MODE+\"\\x3c-which does not exist\",type:lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,tokenTypes:[tokType]}})}function findUnreachablePatterns(tokenTypes){var errors=[],canBeTested=utils_1.reduce(tokenTypes,function(result,tokType,idx){var pattern=tokType.PATTERN;\nif(pattern===lexer_public_1.Lexer.NA)return result;utils_1.isString(pattern)?result.push({str:pattern,idx,tokenType:tokType}):utils_1.isRegExp(pattern)&&noMetaChar(pattern)&&result.push({str:pattern.source,idx,tokenType:tokType});return result},[]);utils_1.forEach(tokenTypes,function(tokType,testIdx){utils_1.forEach(canBeTested,function(_a){var str=_a.str,tokenType=_a.tokenType;testIdx<_a.idx&&testTokenType(str,tokType.PATTERN)&&errors.push({message:\"Token: -\\x3e\"+tokenType.name+\"\\x3c- can never be matched.\\nBecause it appears AFTER the Token Type -\\x3e\"+\n(tokType.name+\"\\x3c-in the lexer's definition.\\nSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE\"),type:lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,tokenTypes:[tokType,tokenType]})})});return errors}function testTokenType(str,pattern){if(utils_1.isRegExp(pattern))return str=pattern.exec(str),null!==str&&0===str.index;if(utils_1.isFunction(pattern))return pattern(str,0,[],{});if(utils_1.has(pattern,\"exec\"))return pattern.exec(str,0,[],{});if(\"string\"===typeof pattern)return pattern===\nstr;throw Error(\"non exhaustive match\");}function noMetaChar(regExp){return void 0===utils_1.find(\".\\\\[]|^$()?*+{\".split(\"\"),function(char){return-1!==regExp.source.indexOf(char)})}function addStartOfInput(pattern){return new RegExp(\"^(?:\"+pattern.source+\")\",pattern.ignoreCase?\"i\":\"\")}function addStickyFlag(pattern){return new RegExp(\"\"+pattern.source,pattern.ignoreCase?\"iy\":\"y\")}function isCustomPattern(tokenType){tokenType=tokenType.PATTERN;if(utils_1.isRegExp(tokenType))return!1;if(utils_1.isFunction(tokenType)||\nutils_1.has(tokenType,\"exec\"))return!0;if(utils_1.isString(tokenType))return!1;throw Error(\"non exhaustive match\");}function isShortPattern(pattern){return utils_1.isString(pattern)&&1===pattern.length?pattern.charCodeAt(0):!1}function checkLineBreaksIssues(tokType,lineTerminatorCharCodes){if(utils_1.has(tokType,\"LINE_BREAKS\"))return!1;if(utils_1.isRegExp(tokType.PATTERN)){try{reg_exp_1.canMatchCharCode(lineTerminatorCharCodes,tokType.PATTERN)}catch(e){return{issue:lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\nerrMsg:e.message}}return!1}if(utils_1.isString(tokType.PATTERN))return!1;if(isCustomPattern(tokType))return{issue:lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK};throw Error(\"non exhaustive match\");}function buildLineBreakIssueMessage(tokType,details){if(details.issue===lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR)return\"Warning: unable to identify line terminator usage in pattern.\\n\\tThe problem is in the \\x3c\"+(tokType.name+\"\\x3e Token Type\\n\\t Root cause: \")+(details.errMsg+\n\".\\n\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\");if(details.issue===lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK)return\"Warning: A Custom Token Pattern should specify the \\x3cline_breaks\\x3e option.\\n\\tThe problem is in the \\x3c\"+(tokType.name+\"\\x3e Token Type\\n\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\");throw Error(\"non exhaustive match\");}function getCharCodes(charsOrCodes){return utils_1.map(charsOrCodes,\nfunction(numOrString){return utils_1.isString(numOrString)&&0<numOrString.length?numOrString.charCodeAt(0):numOrString})}function addToMapOfArrays(map,key,value){void 0===map[key]?map[key]=[value]:map[key].push(value)}function charCodeToOptimizedIndex(charCode){return charCode<exports.minOptimizationVal?charCode:charCodeToOptimizedIdxMap[charCode]}var __extends=this&&this.__extends||function(){var extendStatics=function(d$jscomp$0,b$jscomp$0){extendStatics=Object.setPrototypeOf||{__proto__:[]}instanceof\nArray&&function(d,b){d.__proto__=b}||function(d,b){for(var p in b)Object.prototype.hasOwnProperty.call(b,p)&&(d[p]=b[p])};return extendStatics(d$jscomp$0,b$jscomp$0)};return function(d,b){function __(){this.constructor=d}if(\"function\"!==typeof b&&null!==b)throw new TypeError(\"Class extends value \"+String(b)+\" is not a constructor or null\");extendStatics(d,b);d.prototype=null===b?Object.create(b):(__.prototype=b.prototype,new __)}}();Object.defineProperty(exports,\"__esModule\",{value:!0});exports.charCodeToOptimizedIndex=\nexports.minOptimizationVal=exports.buildLineBreakIssueMessage=exports.LineTerminatorOptimizedTester=exports.isShortPattern=exports.isCustomPattern=exports.cloneEmptyGroups=exports.performWarningRuntimeChecks=exports.performRuntimeChecks=exports.addStickyFlag=exports.addStartOfInput=exports.findUnreachablePatterns=exports.findModesThatDoNotExist=exports.findInvalidGroupType=exports.findDuplicatePatterns=exports.findUnsupportedFlags=exports.findStartOfInputAnchor=exports.findEmptyMatchRegExps=exports.findEndOfInputAnchor=\nexports.findInvalidPatterns=exports.findMissingPatterns=exports.validatePatterns=exports.analyzeTokenTypes=exports.enableSticky=exports.disableSticky=exports.SUPPORT_STICKY=exports.MODES=exports.DEFAULT_MODE=void 0;var regexp_to_ast_1=require(\"module$node_modules$regexp_to_ast$lib$regexp_to_ast\"),lexer_public_1=require(\"module$node_modules$chevrotain$lib$src$scan$lexer_public\"),utils_1=require(\"module$node_modules$$chevrotain$utils$lib$src$api\"),reg_exp_1=require(\"module$node_modules$chevrotain$lib$src$scan$reg_exp\"),\nreg_exp_parser_1=require(\"module$node_modules$chevrotain$lib$src$scan$reg_exp_parser\");exports.DEFAULT_MODE=\"defaultMode\";exports.MODES=\"modes\";exports.SUPPORT_STICKY=\"boolean\"===typeof/(?:)/.sticky;exports.disableSticky=function(){exports.SUPPORT_STICKY=!1};exports.enableSticky=function(){exports.SUPPORT_STICKY=!0};exports.analyzeTokenTypes=function(tokenTypes,options){options=utils_1.defaults(options,{useSticky:exports.SUPPORT_STICKY,debug:!1,safeMode:!1,positionTracking:\"full\",lineTerminatorCharacters:[\"\\r\",\n\"\\n\"],tracer:function(msg,action){return action()}});var tracer=options.tracer;tracer(\"initCharCodeToOptimizedIndexMap\",function(){if(utils_1.isEmpty(charCodeToOptimizedIdxMap)){charCodeToOptimizedIdxMap=Array(65536);for(var i=0;65536>i;i++)charCodeToOptimizedIdxMap[i]=255<i?255+~~(i/255):i}});var onlyRelevantTypes;tracer(\"Reject Lexer.NA\",function(){onlyRelevantTypes=utils_1.reject(tokenTypes,function(currType){return currType.PATTERN===lexer_public_1.Lexer.NA})});var hasCustom=!1,allTransformedPatterns;\ntracer(\"Transform Patterns\",function(){hasCustom=!1;allTransformedPatterns=utils_1.map(onlyRelevantTypes,function(currType){currType=currType.PATTERN;if(utils_1.isRegExp(currType)){var regExpSource=currType.source;return 1!==regExpSource.length||\"^\"===regExpSource||\"$\"===regExpSource||\".\"===regExpSource||currType.ignoreCase?2!==regExpSource.length||\"\\\\\"!==regExpSource[0]||utils_1.contains(\"dDsStrnt0cbBfvwW\".split(\"\"),regExpSource[1])?options.useSticky?addStickyFlag(currType):addStartOfInput(currType):\nregExpSource[1]:regExpSource}if(utils_1.isFunction(currType))return hasCustom=!0,{exec:currType};if(utils_1.has(currType,\"exec\"))return hasCustom=!0,currType;if(\"string\"===typeof currType){if(1===currType.length)return currType;currType=currType.replace(/[\\\\^$.*+?()[\\]{}|]/g,\"\\\\$\\x26\");currType=new RegExp(currType);return options.useSticky?addStickyFlag(currType):addStartOfInput(currType)}throw Error(\"non exhaustive match\");})});var patternIdxToType,patternIdxToGroup,patternIdxToLongerAltIdx,patternIdxToPushMode,\npatternIdxToPopMode;tracer(\"misc mapping\",function(){patternIdxToType=utils_1.map(onlyRelevantTypes,function(currType){return currType.tokenTypeIdx});patternIdxToGroup=utils_1.map(onlyRelevantTypes,function(clazz){clazz=clazz.GROUP;if(clazz!==lexer_public_1.Lexer.SKIPPED){if(utils_1.isString(clazz))return clazz;if(utils_1.isUndefined(clazz))return!1;throw Error(\"non exhaustive match\");}});patternIdxToLongerAltIdx=utils_1.map(onlyRelevantTypes,function(clazz){if(clazz=clazz.LONGER_ALT)return utils_1.indexOf(onlyRelevantTypes,\nclazz)});patternIdxToPushMode=utils_1.map(onlyRelevantTypes,function(clazz){return clazz.PUSH_MODE});patternIdxToPopMode=utils_1.map(onlyRelevantTypes,function(clazz){return utils_1.has(clazz,\"POP_MODE\")})});var patternIdxToCanLineTerminator;tracer(\"Line Terminator Handling\",function(){var lineTerminatorCharCodes=getCharCodes(options.lineTerminatorCharacters);patternIdxToCanLineTerminator=utils_1.map(onlyRelevantTypes,function(tokType){return!1});\"onlyOffset\"!==options.positionTracking&&(patternIdxToCanLineTerminator=\nutils_1.map(onlyRelevantTypes,function(tokType){if(utils_1.has(tokType,\"LINE_BREAKS\"))return tokType.LINE_BREAKS;if(!1===checkLineBreaksIssues(tokType,lineTerminatorCharCodes))return reg_exp_1.canMatchCharCode(lineTerminatorCharCodes,tokType.PATTERN)}))});var patternIdxToIsCustom,patternIdxToShort,emptyGroups,patternIdxToConfig;tracer(\"Misc Mapping #2\",function(){patternIdxToIsCustom=utils_1.map(onlyRelevantTypes,isCustomPattern);patternIdxToShort=utils_1.map(allTransformedPatterns,isShortPattern);\nemptyGroups=utils_1.reduce(onlyRelevantTypes,function(acc,clazz){clazz=clazz.GROUP;utils_1.isString(clazz)&&clazz!==lexer_public_1.Lexer.SKIPPED&&(acc[clazz]=[]);return acc},{});patternIdxToConfig=utils_1.map(allTransformedPatterns,function(x,idx){return{pattern:allTransformedPatterns[idx],longerAlt:patternIdxToLongerAltIdx[idx],canLineTerminator:patternIdxToCanLineTerminator[idx],isCustom:patternIdxToIsCustom[idx],short:patternIdxToShort[idx],group:patternIdxToGroup[idx],push:patternIdxToPushMode[idx],\npop:patternIdxToPopMode[idx],tokenTypeIdx:patternIdxToType[idx],tokenType:onlyRelevantTypes[idx]}})});var canBeOptimized=!0,charCodeToPatternIdxToConfig=[];options.safeMode||tracer(\"First Char Optimization\",function(){charCodeToPatternIdxToConfig=utils_1.reduce(onlyRelevantTypes,function(result,currTokType,idx){if(\"string\"===typeof currTokType.PATTERN)currTokType=currTokType.PATTERN.charCodeAt(0),currTokType=charCodeToOptimizedIndex(currTokType),addToMapOfArrays(result,currTokType,patternIdxToConfig[idx]);\nelse if(utils_1.isArray(currTokType.START_CHARS_HINT)){var lastOptimizedIdx_1;utils_1.forEach(currTokType.START_CHARS_HINT,function(charOrInt){charOrInt=\"string\"===typeof charOrInt?charOrInt.charCodeAt(0):charOrInt;charOrInt=charCodeToOptimizedIndex(charOrInt);lastOptimizedIdx_1!==charOrInt&&(lastOptimizedIdx_1=charOrInt,addToMapOfArrays(result,charOrInt,patternIdxToConfig[idx]))})}else utils_1.isRegExp(currTokType.PATTERN)?currTokType.PATTERN.unicode?(canBeOptimized=!1,options.ensureOptimizations&&\nutils_1.PRINT_ERROR(\"\"+reg_exp_1.failedOptimizationPrefixMsg+(\"\\tUnable to analyze \\x3c \"+currTokType.PATTERN.toString()+\" \\x3e pattern.\\n\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\\tThis will disable the lexer's first char optimizations.\\n\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\"))):(currTokType=reg_exp_1.getOptimizedStartCodesIndices(currTokType.PATTERN,options.ensureOptimizations),utils_1.isEmpty(currTokType)&&\n(canBeOptimized=!1),utils_1.forEach(currTokType,function(code){addToMapOfArrays(result,code,patternIdxToConfig[idx])})):(options.ensureOptimizations&&utils_1.PRINT_ERROR(\"\"+reg_exp_1.failedOptimizationPrefixMsg+(\"\\tTokenType: \\x3c\"+currTokType.name+\"\\x3e is using a custom token pattern without providing \\x3cstart_chars_hint\\x3e parameter.\\n\\tThis will disable the lexer's first char optimizations.\\n\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\")),canBeOptimized=\n!1);return result},[])});tracer(\"ArrayPacking\",function(){charCodeToPatternIdxToConfig=utils_1.packArray(charCodeToPatternIdxToConfig)});return{emptyGroups,patternIdxToConfig,charCodeToPatternIdxToConfig,hasCustom,canBeOptimized}};exports.validatePatterns=function(tokenTypes,validModesNames){var errors=[];tokenTypes=findMissingPatterns(tokenTypes);errors=errors.concat(tokenTypes.errors);tokenTypes=findInvalidPatterns(tokenTypes.valid);var validTokenTypes=tokenTypes.valid;errors=errors.concat(tokenTypes.errors);\nerrors=errors.concat(validateRegExpPattern(validTokenTypes));errors=errors.concat(findInvalidGroupType(validTokenTypes));errors=errors.concat(findModesThatDoNotExist(validTokenTypes,validModesNames));return errors=errors.concat(findUnreachablePatterns(validTokenTypes))};exports.findMissingPatterns=findMissingPatterns;exports.findInvalidPatterns=findInvalidPatterns;var end_of_input=/[^\\\\][\\$]/;exports.findEndOfInputAnchor=findEndOfInputAnchor;exports.findEmptyMatchRegExps=findEmptyMatchRegExps;var start_of_input=\n/[^\\\\[][\\^]|^\\^/;exports.findStartOfInputAnchor=findStartOfInputAnchor;exports.findUnsupportedFlags=findUnsupportedFlags;exports.findDuplicatePatterns=findDuplicatePatterns;exports.findInvalidGroupType=findInvalidGroupType;exports.findModesThatDoNotExist=findModesThatDoNotExist;exports.findUnreachablePatterns=findUnreachablePatterns;exports.addStartOfInput=addStartOfInput;exports.addStickyFlag=addStickyFlag;exports.performRuntimeChecks=function(lexerDefinition,trackLines,lineTerminatorCharacters){var errors=\n[];utils_1.has(lexerDefinition,exports.DEFAULT_MODE)||errors.push({message:\"A MultiMode Lexer cannot be initialized without a \\x3c\"+exports.DEFAULT_MODE+\"\\x3e property in its definition\\n\",type:lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE});utils_1.has(lexerDefinition,exports.MODES)||errors.push({message:\"A MultiMode Lexer cannot be initialized without a \\x3c\"+exports.MODES+\"\\x3e property in its definition\\n\",type:lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY});\nutils_1.has(lexerDefinition,exports.MODES)&&utils_1.has(lexerDefinition,exports.DEFAULT_MODE)&&!utils_1.has(lexerDefinition.modes,lexerDefinition.defaultMode)&&errors.push({message:\"A MultiMode Lexer cannot be initialized with a \"+exports.DEFAULT_MODE+\": \\x3c\"+lexerDefinition.defaultMode+\"\\x3ewhich does not exist\\n\",type:lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST});utils_1.has(lexerDefinition,exports.MODES)&&utils_1.forEach(lexerDefinition.modes,function(currModeValue,\ncurrModeName){utils_1.forEach(currModeValue,function(currTokType,currIdx){utils_1.isUndefined(currTokType)&&errors.push({message:\"A Lexer cannot be initialized using an undefined Token Type. Mode:\\x3c\"+(currModeName+\"\\x3e at index: \\x3c\"+currIdx+\"\\x3e\\n\"),type:lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED})})});return errors};exports.performWarningRuntimeChecks=function(lexerDefinition,trackLines,lineTerminatorCharacters){var warnings=[],hasAnyLineBreak=!1;lexerDefinition=\nutils_1.compact(utils_1.flatten(utils_1.mapValues(lexerDefinition.modes,function(tokTypes){return tokTypes})));lexerDefinition=utils_1.reject(lexerDefinition,function(currType){return currType.PATTERN===lexer_public_1.Lexer.NA});var terminatorCharCodes=getCharCodes(lineTerminatorCharacters);trackLines&&utils_1.forEach(lexerDefinition,function(tokType){var currIssue=checkLineBreaksIssues(tokType,terminatorCharCodes);!1!==currIssue?(tokType={message:buildLineBreakIssueMessage(tokType,currIssue),type:currIssue.issue,\ntokenType:tokType},warnings.push(tokType)):utils_1.has(tokType,\"LINE_BREAKS\")?!0===tokType.LINE_BREAKS&&(hasAnyLineBreak=!0):reg_exp_1.canMatchCharCode(terminatorCharCodes,tokType.PATTERN)&&(hasAnyLineBreak=!0)});trackLines&&!hasAnyLineBreak&&warnings.push({message:\"Warning: No LINE_BREAKS Found.\\n\\tThis Lexer has been defined to track line and column information,\\n\\tBut none of the Token Types can be identified as matching a line terminator.\\n\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\\tfor details.\",\ntype:lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS});return warnings};exports.cloneEmptyGroups=function(emptyGroups){var clonedResult={},groupKeys=utils_1.keys(emptyGroups);utils_1.forEach(groupKeys,function(currKey){if(utils_1.isArray(emptyGroups[currKey]))clonedResult[currKey]=[];else throw Error(\"non exhaustive match\");});return clonedResult};exports.isCustomPattern=isCustomPattern;exports.isShortPattern=isShortPattern;exports.LineTerminatorOptimizedTester={test:function(text){for(var len=\ntext.length,i=this.lastIndex;i<len;i++){var c=text.charCodeAt(i);if(10===c)return this.lastIndex=i+1,!0;if(13===c)return 10===text.charCodeAt(i+1)?this.lastIndex=i+2:this.lastIndex=i+1,!0}return!1},lastIndex:0};exports.buildLineBreakIssueMessage=buildLineBreakIssueMessage;exports.minOptimizationVal=256;var charCodeToOptimizedIdxMap=[];exports.charCodeToOptimizedIndex=charCodeToOptimizedIndex}","~:source","shadow$provide[\"module$node_modules$chevrotain$lib$src$scan$lexer\"] = function(global,require,module,exports) {\n\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\nvar regexp_to_ast_1 = require(\"regexp-to-ast\");\nvar lexer_public_1 = require(\"./lexer_public\");\nvar utils_1 = require(\"@chevrotain/utils\");\nvar reg_exp_1 = require(\"./reg_exp\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nexports.SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nfunction disableSticky() {\n    exports.SUPPORT_STICKY = false;\n}\nexports.disableSticky = disableSticky;\nfunction enableSticky() {\n    exports.SUPPORT_STICKY = true;\n}\nexports.enableSticky = enableSticky;\nfunction analyzeTokenTypes(tokenTypes, options) {\n    options = utils_1.defaults(options, {\n        useSticky: exports.SUPPORT_STICKY,\n        debug: false,\n        safeMode: false,\n        positionTracking: \"full\",\n        lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n        tracer: function (msg, action) { return action(); }\n    });\n    var tracer = options.tracer;\n    tracer(\"initCharCodeToOptimizedIndexMap\", function () {\n        initCharCodeToOptimizedIndexMap();\n    });\n    var onlyRelevantTypes;\n    tracer(\"Reject Lexer.NA\", function () {\n        onlyRelevantTypes = utils_1.reject(tokenTypes, function (currType) {\n            return currType[PATTERN] === lexer_public_1.Lexer.NA;\n        });\n    });\n    var hasCustom = false;\n    var allTransformedPatterns;\n    tracer(\"Transform Patterns\", function () {\n        hasCustom = false;\n        allTransformedPatterns = utils_1.map(onlyRelevantTypes, function (currType) {\n            var currPattern = currType[PATTERN];\n            /* istanbul ignore else */\n            if (utils_1.isRegExp(currPattern)) {\n                var regExpSource = currPattern.source;\n                if (regExpSource.length === 1 &&\n                    // only these regExp meta characters which can appear in a length one regExp\n                    regExpSource !== \"^\" &&\n                    regExpSource !== \"$\" &&\n                    regExpSource !== \".\" &&\n                    !currPattern.ignoreCase) {\n                    return regExpSource;\n                }\n                else if (regExpSource.length === 2 &&\n                    regExpSource[0] === \"\\\\\" &&\n                    // not a meta character\n                    !utils_1.contains([\n                        \"d\",\n                        \"D\",\n                        \"s\",\n                        \"S\",\n                        \"t\",\n                        \"r\",\n                        \"n\",\n                        \"t\",\n                        \"0\",\n                        \"c\",\n                        \"b\",\n                        \"B\",\n                        \"f\",\n                        \"v\",\n                        \"w\",\n                        \"W\"\n                    ], regExpSource[1])) {\n                    // escaped meta Characters: /\\+/ /\\[/\n                    // or redundant escaping: /\\a/\n                    // without the escaping \"\\\"\n                    return regExpSource[1];\n                }\n                else {\n                    return options.useSticky\n                        ? addStickyFlag(currPattern)\n                        : addStartOfInput(currPattern);\n                }\n            }\n            else if (utils_1.isFunction(currPattern)) {\n                hasCustom = true;\n                // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n                return { exec: currPattern };\n            }\n            else if (utils_1.has(currPattern, \"exec\")) {\n                hasCustom = true;\n                // ICustomPattern\n                return currPattern;\n            }\n            else if (typeof currPattern === \"string\") {\n                if (currPattern.length === 1) {\n                    return currPattern;\n                }\n                else {\n                    var escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n                    var wrappedRegExp = new RegExp(escapedRegExpString);\n                    return options.useSticky\n                        ? addStickyFlag(wrappedRegExp)\n                        : addStartOfInput(wrappedRegExp);\n                }\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    });\n    var patternIdxToType;\n    var patternIdxToGroup;\n    var patternIdxToLongerAltIdx;\n    var patternIdxToPushMode;\n    var patternIdxToPopMode;\n    tracer(\"misc mapping\", function () {\n        patternIdxToType = utils_1.map(onlyRelevantTypes, function (currType) { return currType.tokenTypeIdx; });\n        patternIdxToGroup = utils_1.map(onlyRelevantTypes, function (clazz) {\n            var groupName = clazz.GROUP;\n            /* istanbul ignore next */\n            if (groupName === lexer_public_1.Lexer.SKIPPED) {\n                return undefined;\n            }\n            else if (utils_1.isString(groupName)) {\n                return groupName;\n            }\n            else if (utils_1.isUndefined(groupName)) {\n                return false;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n        patternIdxToLongerAltIdx = utils_1.map(onlyRelevantTypes, function (clazz) {\n            var longerAltType = clazz.LONGER_ALT;\n            if (longerAltType) {\n                var longerAltIdx = utils_1.indexOf(onlyRelevantTypes, longerAltType);\n                return longerAltIdx;\n            }\n        });\n        patternIdxToPushMode = utils_1.map(onlyRelevantTypes, function (clazz) { return clazz.PUSH_MODE; });\n        patternIdxToPopMode = utils_1.map(onlyRelevantTypes, function (clazz) {\n            return utils_1.has(clazz, \"POP_MODE\");\n        });\n    });\n    var patternIdxToCanLineTerminator;\n    tracer(\"Line Terminator Handling\", function () {\n        var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n        patternIdxToCanLineTerminator = utils_1.map(onlyRelevantTypes, function (tokType) { return false; });\n        if (options.positionTracking !== \"onlyOffset\") {\n            patternIdxToCanLineTerminator = utils_1.map(onlyRelevantTypes, function (tokType) {\n                if (utils_1.has(tokType, \"LINE_BREAKS\")) {\n                    return tokType.LINE_BREAKS;\n                }\n                else {\n                    if (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false) {\n                        return reg_exp_1.canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n                    }\n                }\n            });\n        }\n    });\n    var patternIdxToIsCustom;\n    var patternIdxToShort;\n    var emptyGroups;\n    var patternIdxToConfig;\n    tracer(\"Misc Mapping #2\", function () {\n        patternIdxToIsCustom = utils_1.map(onlyRelevantTypes, isCustomPattern);\n        patternIdxToShort = utils_1.map(allTransformedPatterns, isShortPattern);\n        emptyGroups = utils_1.reduce(onlyRelevantTypes, function (acc, clazz) {\n            var groupName = clazz.GROUP;\n            if (utils_1.isString(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n                acc[groupName] = [];\n            }\n            return acc;\n        }, {});\n        patternIdxToConfig = utils_1.map(allTransformedPatterns, function (x, idx) {\n            return {\n                pattern: allTransformedPatterns[idx],\n                longerAlt: patternIdxToLongerAltIdx[idx],\n                canLineTerminator: patternIdxToCanLineTerminator[idx],\n                isCustom: patternIdxToIsCustom[idx],\n                short: patternIdxToShort[idx],\n                group: patternIdxToGroup[idx],\n                push: patternIdxToPushMode[idx],\n                pop: patternIdxToPopMode[idx],\n                tokenTypeIdx: patternIdxToType[idx],\n                tokenType: onlyRelevantTypes[idx]\n            };\n        });\n    });\n    var canBeOptimized = true;\n    var charCodeToPatternIdxToConfig = [];\n    if (!options.safeMode) {\n        tracer(\"First Char Optimization\", function () {\n            charCodeToPatternIdxToConfig = utils_1.reduce(onlyRelevantTypes, function (result, currTokType, idx) {\n                if (typeof currTokType.PATTERN === \"string\") {\n                    var charCode = currTokType.PATTERN.charCodeAt(0);\n                    var optimizedIdx = charCodeToOptimizedIndex(charCode);\n                    addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n                }\n                else if (utils_1.isArray(currTokType.START_CHARS_HINT)) {\n                    var lastOptimizedIdx_1;\n                    utils_1.forEach(currTokType.START_CHARS_HINT, function (charOrInt) {\n                        var charCode = typeof charOrInt === \"string\"\n                            ? charOrInt.charCodeAt(0)\n                            : charOrInt;\n                        var currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n                        // Avoid adding the config multiple times\n                        /* istanbul ignore else */\n                        // - Difficult to check this scenario effects as it is only a performance\n                        //   optimization that does not change correctness\n                        if (lastOptimizedIdx_1 !== currOptimizedIdx) {\n                            lastOptimizedIdx_1 = currOptimizedIdx;\n                            addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n                        }\n                    });\n                }\n                else if (utils_1.isRegExp(currTokType.PATTERN)) {\n                    if (currTokType.PATTERN.unicode) {\n                        canBeOptimized = false;\n                        if (options.ensureOptimizations) {\n                            utils_1.PRINT_ERROR(\"\" + reg_exp_1.failedOptimizationPrefixMsg +\n                                (\"\\tUnable to analyze < \" + currTokType.PATTERN.toString() + \" > pattern.\\n\") +\n                                \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                                \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n                        }\n                    }\n                    else {\n                        var optimizedCodes = reg_exp_1.getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\n                        /* istanbul ignore if */\n                        // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n                        // the first should be a different validation and the second cannot be tested.\n                        if (utils_1.isEmpty(optimizedCodes)) {\n                            // we cannot understand what codes may start possible matches\n                            // The optimization correctness requires knowing start codes for ALL patterns.\n                            // Not actually sure this is an error, no debug message\n                            canBeOptimized = false;\n                        }\n                        utils_1.forEach(optimizedCodes, function (code) {\n                            addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n                        });\n                    }\n                }\n                else {\n                    if (options.ensureOptimizations) {\n                        utils_1.PRINT_ERROR(\"\" + reg_exp_1.failedOptimizationPrefixMsg +\n                            (\"\\tTokenType: <\" + currTokType.name + \"> is using a custom token pattern without providing <start_chars_hint> parameter.\\n\") +\n                            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n                    }\n                    canBeOptimized = false;\n                }\n                return result;\n            }, []);\n        });\n    }\n    tracer(\"ArrayPacking\", function () {\n        charCodeToPatternIdxToConfig = utils_1.packArray(charCodeToPatternIdxToConfig);\n    });\n    return {\n        emptyGroups: emptyGroups,\n        patternIdxToConfig: patternIdxToConfig,\n        charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n        hasCustom: hasCustom,\n        canBeOptimized: canBeOptimized\n    };\n}\nexports.analyzeTokenTypes = analyzeTokenTypes;\nfunction validatePatterns(tokenTypes, validModesNames) {\n    var errors = [];\n    var missingResult = findMissingPatterns(tokenTypes);\n    errors = errors.concat(missingResult.errors);\n    var invalidResult = findInvalidPatterns(missingResult.valid);\n    var validTokenTypes = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n    return errors;\n}\nexports.validatePatterns = validatePatterns;\nfunction validateRegExpPattern(tokenTypes) {\n    var errors = [];\n    var withRegExpPatterns = utils_1.filter(tokenTypes, function (currTokType) {\n        return utils_1.isRegExp(currTokType[PATTERN]);\n    });\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n    return errors;\n}\nfunction findMissingPatterns(tokenTypes) {\n    var tokenTypesWithMissingPattern = utils_1.filter(tokenTypes, function (currType) {\n        return !utils_1.has(currType, PATTERN);\n    });\n    var errors = utils_1.map(tokenTypesWithMissingPattern, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- missing static 'PATTERN' property\",\n            type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    var valid = utils_1.difference(tokenTypes, tokenTypesWithMissingPattern);\n    return { errors: errors, valid: valid };\n}\nexports.findMissingPatterns = findMissingPatterns;\nfunction findInvalidPatterns(tokenTypes) {\n    var tokenTypesWithInvalidPattern = utils_1.filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return (!utils_1.isRegExp(pattern) &&\n            !utils_1.isFunction(pattern) &&\n            !utils_1.has(pattern, \"exec\") &&\n            !utils_1.isString(pattern));\n    });\n    var errors = utils_1.map(tokenTypesWithInvalidPattern, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' can only be a RegExp, a\" +\n                \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    var valid = utils_1.difference(tokenTypes, tokenTypesWithInvalidPattern);\n    return { errors: errors, valid: valid };\n}\nexports.findInvalidPatterns = findInvalidPatterns;\nvar end_of_input = /[^\\\\][\\$]/;\nfunction findEndOfInputAnchor(tokenTypes) {\n    var EndAnchorFinder = /** @class */ (function (_super) {\n        __extends(EndAnchorFinder, _super);\n        function EndAnchorFinder() {\n            var _this = _super !== null && _super.apply(this, arguments) || this;\n            _this.found = false;\n            return _this;\n        }\n        EndAnchorFinder.prototype.visitEndAnchor = function (node) {\n            this.found = true;\n        };\n        return EndAnchorFinder;\n    }(regexp_to_ast_1.BaseRegExpVisitor));\n    var invalidRegex = utils_1.filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        try {\n            var regexpAst = reg_exp_parser_1.getRegExpAst(pattern);\n            var endAnchorVisitor = new EndAnchorFinder();\n            endAnchorVisitor.visit(regexpAst);\n            return endAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return end_of_input.test(pattern.source);\n        }\n    });\n    var errors = utils_1.map(invalidRegex, function (currType) {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n                \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\nfunction findEmptyMatchRegExps(tokenTypes) {\n    var matchesEmptyString = utils_1.filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return pattern.test(\"\");\n    });\n    var errors = utils_1.map(matchesEmptyString, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' must not match an empty string\",\n            type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\nvar start_of_input = /[^\\\\[][\\^]|^\\^/;\nfunction findStartOfInputAnchor(tokenTypes) {\n    var StartAnchorFinder = /** @class */ (function (_super) {\n        __extends(StartAnchorFinder, _super);\n        function StartAnchorFinder() {\n            var _this = _super !== null && _super.apply(this, arguments) || this;\n            _this.found = false;\n            return _this;\n        }\n        StartAnchorFinder.prototype.visitStartAnchor = function (node) {\n            this.found = true;\n        };\n        return StartAnchorFinder;\n    }(regexp_to_ast_1.BaseRegExpVisitor));\n    var invalidRegex = utils_1.filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        try {\n            var regexpAst = reg_exp_parser_1.getRegExpAst(pattern);\n            var startAnchorVisitor = new StartAnchorFinder();\n            startAnchorVisitor.visit(regexpAst);\n            return startAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return start_of_input.test(pattern.source);\n        }\n    });\n    var errors = utils_1.map(invalidRegex, function (currType) {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\nfunction findUnsupportedFlags(tokenTypes) {\n    var invalidFlags = utils_1.filter(tokenTypes, function (currType) {\n        var pattern = currType[PATTERN];\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    var errors = utils_1.map(invalidFlags, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n            type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findUnsupportedFlags = findUnsupportedFlags;\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nfunction findDuplicatePatterns(tokenTypes) {\n    var found = [];\n    var identicalPatterns = utils_1.map(tokenTypes, function (outerType) {\n        return utils_1.reduce(tokenTypes, function (result, innerType) {\n            if (outerType.PATTERN.source === innerType.PATTERN.source &&\n                !utils_1.contains(found, innerType) &&\n                innerType.PATTERN !== lexer_public_1.Lexer.NA) {\n                // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n                // in essence we are creating Equivalence classes on equality relation.\n                found.push(innerType);\n                result.push(innerType);\n                return result;\n            }\n            return result;\n        }, []);\n    });\n    identicalPatterns = utils_1.compact(identicalPatterns);\n    var duplicatePatterns = utils_1.filter(identicalPatterns, function (currIdenticalSet) {\n        return currIdenticalSet.length > 1;\n    });\n    var errors = utils_1.map(duplicatePatterns, function (setOfIdentical) {\n        var tokenTypeNames = utils_1.map(setOfIdentical, function (currType) {\n            return currType.name;\n        });\n        var dupPatternSrc = utils_1.first(setOfIdentical).PATTERN;\n        return {\n            message: \"The same RegExp pattern ->\" + dupPatternSrc + \"<-\" +\n                (\"has been used in all of the following Token Types: \" + tokenTypeNames.join(\", \") + \" <-\"),\n            type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n            tokenTypes: setOfIdentical\n        };\n    });\n    return errors;\n}\nexports.findDuplicatePatterns = findDuplicatePatterns;\nfunction findInvalidGroupType(tokenTypes) {\n    var invalidTypes = utils_1.filter(tokenTypes, function (clazz) {\n        if (!utils_1.has(clazz, \"GROUP\")) {\n            return false;\n        }\n        var group = clazz.GROUP;\n        return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !utils_1.isString(group);\n    });\n    var errors = utils_1.map(invalidTypes, function (currType) {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findInvalidGroupType = findInvalidGroupType;\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n    var invalidModes = utils_1.filter(tokenTypes, function (clazz) {\n        return (clazz.PUSH_MODE !== undefined && !utils_1.contains(validModes, clazz.PUSH_MODE));\n    });\n    var errors = utils_1.map(invalidModes, function (tokType) {\n        var msg = \"Token Type: ->\" + tokType.name + \"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\" + tokType.PUSH_MODE + \"<-\" +\n            \"which does not exist\";\n        return {\n            message: msg,\n            type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n            tokenTypes: [tokType]\n        };\n    });\n    return errors;\n}\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\nfunction findUnreachablePatterns(tokenTypes) {\n    var errors = [];\n    var canBeTested = utils_1.reduce(tokenTypes, function (result, tokType, idx) {\n        var pattern = tokType.PATTERN;\n        if (pattern === lexer_public_1.Lexer.NA) {\n            return result;\n        }\n        // a more comprehensive validation for all forms of regExps would require\n        // deeper regExp analysis capabilities\n        if (utils_1.isString(pattern)) {\n            result.push({ str: pattern, idx: idx, tokenType: tokType });\n        }\n        else if (utils_1.isRegExp(pattern) && noMetaChar(pattern)) {\n            result.push({ str: pattern.source, idx: idx, tokenType: tokType });\n        }\n        return result;\n    }, []);\n    utils_1.forEach(tokenTypes, function (tokType, testIdx) {\n        utils_1.forEach(canBeTested, function (_a) {\n            var str = _a.str, idx = _a.idx, tokenType = _a.tokenType;\n            if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n                var msg = \"Token: ->\" + tokenType.name + \"<- can never be matched.\\n\" +\n                    (\"Because it appears AFTER the Token Type ->\" + tokType.name + \"<-\") +\n                    \"in the lexer's definition.\\n\" +\n                    \"See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE\";\n                errors.push({\n                    message: msg,\n                    type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n                    tokenTypes: [tokType, tokenType]\n                });\n            }\n        });\n    });\n    return errors;\n}\nexports.findUnreachablePatterns = findUnreachablePatterns;\nfunction testTokenType(str, pattern) {\n    /* istanbul ignore else */\n    if (utils_1.isRegExp(pattern)) {\n        var regExpArray = pattern.exec(str);\n        return regExpArray !== null && regExpArray.index === 0;\n    }\n    else if (utils_1.isFunction(pattern)) {\n        // maintain the API of custom patterns\n        return pattern(str, 0, [], {});\n    }\n    else if (utils_1.has(pattern, \"exec\")) {\n        // maintain the API of custom patterns\n        return pattern.exec(str, 0, [], {});\n    }\n    else if (typeof pattern === \"string\") {\n        return pattern === str;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction noMetaChar(regExp) {\n    //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n    var metaChars = [\n        \".\",\n        \"\\\\\",\n        \"[\",\n        \"]\",\n        \"|\",\n        \"^\",\n        \"$\",\n        \"(\",\n        \")\",\n        \"?\",\n        \"*\",\n        \"+\",\n        \"{\"\n    ];\n    return (utils_1.find(metaChars, function (char) { return regExp.source.indexOf(char) !== -1; }) === undefined);\n}\nfunction addStartOfInput(pattern) {\n    var flags = pattern.ignoreCase ? \"i\" : \"\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(\"^(?:\" + pattern.source + \")\", flags);\n}\nexports.addStartOfInput = addStartOfInput;\nfunction addStickyFlag(pattern) {\n    var flags = pattern.ignoreCase ? \"iy\" : \"y\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(\"\" + pattern.source, flags);\n}\nexports.addStickyFlag = addStickyFlag;\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    var errors = [];\n    // some run time checks to help the end users.\n    if (!utils_1.has(lexerDefinition, exports.DEFAULT_MODE)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                exports.DEFAULT_MODE +\n                \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n        });\n    }\n    if (!utils_1.has(lexerDefinition, exports.MODES)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                exports.MODES +\n                \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n        });\n    }\n    if (utils_1.has(lexerDefinition, exports.MODES) &&\n        utils_1.has(lexerDefinition, exports.DEFAULT_MODE) &&\n        !utils_1.has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized with a \" + exports.DEFAULT_MODE + \": <\" + lexerDefinition.defaultMode + \">\" +\n                \"which does not exist\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n        });\n    }\n    if (utils_1.has(lexerDefinition, exports.MODES)) {\n        utils_1.forEach(lexerDefinition.modes, function (currModeValue, currModeName) {\n            utils_1.forEach(currModeValue, function (currTokType, currIdx) {\n                if (utils_1.isUndefined(currTokType)) {\n                    errors.push({\n                        message: \"A Lexer cannot be initialized using an undefined Token Type. Mode:\" +\n                            (\"<\" + currModeName + \"> at index: <\" + currIdx + \">\\n\"),\n                        type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n                    });\n                }\n            });\n        });\n    }\n    return errors;\n}\nexports.performRuntimeChecks = performRuntimeChecks;\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    var warnings = [];\n    var hasAnyLineBreak = false;\n    var allTokenTypes = utils_1.compact(utils_1.flatten(utils_1.mapValues(lexerDefinition.modes, function (tokTypes) { return tokTypes; })));\n    var concreteTokenTypes = utils_1.reject(allTokenTypes, function (currType) { return currType[PATTERN] === lexer_public_1.Lexer.NA; });\n    var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n    if (trackLines) {\n        utils_1.forEach(concreteTokenTypes, function (tokType) {\n            var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n            if (currIssue !== false) {\n                var message = buildLineBreakIssueMessage(tokType, currIssue);\n                var warningDescriptor = {\n                    message: message,\n                    type: currIssue.issue,\n                    tokenType: tokType\n                };\n                warnings.push(warningDescriptor);\n            }\n            else {\n                // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n                if (utils_1.has(tokType, \"LINE_BREAKS\")) {\n                    if (tokType.LINE_BREAKS === true) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n                else {\n                    if (reg_exp_1.canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n            }\n        });\n    }\n    if (trackLines && !hasAnyLineBreak) {\n        warnings.push({\n            message: \"Warning: No LINE_BREAKS Found.\\n\" +\n                \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n                \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n        });\n    }\n    return warnings;\n}\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\nfunction cloneEmptyGroups(emptyGroups) {\n    var clonedResult = {};\n    var groupKeys = utils_1.keys(emptyGroups);\n    utils_1.forEach(groupKeys, function (currKey) {\n        var currGroupValue = emptyGroups[currKey];\n        /* istanbul ignore else */\n        if (utils_1.isArray(currGroupValue)) {\n            clonedResult[currKey] = [];\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    });\n    return clonedResult;\n}\nexports.cloneEmptyGroups = cloneEmptyGroups;\n// TODO: refactor to avoid duplication\nfunction isCustomPattern(tokenType) {\n    var pattern = tokenType.PATTERN;\n    /* istanbul ignore else */\n    if (utils_1.isRegExp(pattern)) {\n        return false;\n    }\n    else if (utils_1.isFunction(pattern)) {\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return true;\n    }\n    else if (utils_1.has(pattern, \"exec\")) {\n        // ICustomPattern\n        return true;\n    }\n    else if (utils_1.isString(pattern)) {\n        return false;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexports.isCustomPattern = isCustomPattern;\nfunction isShortPattern(pattern) {\n    if (utils_1.isString(pattern) && pattern.length === 1) {\n        return pattern.charCodeAt(0);\n    }\n    else {\n        return false;\n    }\n}\nexports.isShortPattern = isShortPattern;\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexports.LineTerminatorOptimizedTester = {\n    // implements /\\n|\\r\\n?/g.test\n    test: function (text) {\n        var len = text.length;\n        for (var i = this.lastIndex; i < len; i++) {\n            var c = text.charCodeAt(i);\n            if (c === 10) {\n                this.lastIndex = i + 1;\n                return true;\n            }\n            else if (c === 13) {\n                if (text.charCodeAt(i + 1) === 10) {\n                    this.lastIndex = i + 2;\n                }\n                else {\n                    this.lastIndex = i + 1;\n                }\n                return true;\n            }\n        }\n        return false;\n    },\n    lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n    if (utils_1.has(tokType, \"LINE_BREAKS\")) {\n        // if the user explicitly declared the line_breaks option we will respect their choice\n        // and assume it is correct.\n        return false;\n    }\n    else {\n        /* istanbul ignore else */\n        if (utils_1.isRegExp(tokType.PATTERN)) {\n            try {\n                // TODO: why is the casting suddenly needed?\n                reg_exp_1.canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\n            }\n            catch (e) {\n                /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n                return {\n                    issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n                    errMsg: e.message\n                };\n            }\n            return false;\n        }\n        else if (utils_1.isString(tokType.PATTERN)) {\n            // string literal patterns can always be analyzed to detect line terminator usage\n            return false;\n        }\n        else if (isCustomPattern(tokType)) {\n            // custom token types\n            return { issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n}\nfunction buildLineBreakIssueMessage(tokType, details) {\n    /* istanbul ignore else */\n    if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n        return (\"Warning: unable to identify line terminator usage in pattern.\\n\" +\n            (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") +\n            (\"\\t Root cause: \" + details.errMsg + \".\\n\") +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\");\n    }\n    else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n        return (\"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n            (\"\\tThe problem is in the <\" + tokType.name + \"> Token Type\\n\") +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\");\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\nfunction getCharCodes(charsOrCodes) {\n    var charCodes = utils_1.map(charsOrCodes, function (numOrString) {\n        if (utils_1.isString(numOrString) && numOrString.length > 0) {\n            return numOrString.charCodeAt(0);\n        }\n        else {\n            return numOrString;\n        }\n    });\n    return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n    if (map[key] === undefined) {\n        map[key] = [value];\n    }\n    else {\n        map[key].push(value);\n    }\n}\nexports.minOptimizationVal = 256;\n/**\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nvar charCodeToOptimizedIdxMap = [];\nfunction charCodeToOptimizedIndex(charCode) {\n    return charCode < exports.minOptimizationVal\n        ? charCode\n        : charCodeToOptimizedIdxMap[charCode];\n}\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n    if (utils_1.isEmpty(charCodeToOptimizedIdxMap)) {\n        charCodeToOptimizedIdxMap = new Array(65536);\n        for (var i = 0; i < 65536; i++) {\n            /* tslint:disable */\n            charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n            /* tslint:enable */\n        }\n    }\n}\n//# sourceMappingURL=lexer.js.map\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$module$node_modules$chevrotain$lib$src$scan$reg_exp_parser","~$module$node_modules$$chevrotain$utils$lib$src$api","~$shadow.js","~$module$node_modules$regexp_to_ast$lib$regexp_to_ast","~$module$node_modules$chevrotain$lib$src$scan$reg_exp","~$module$node_modules$chevrotain$lib$src$scan$lexer_public"]],"~:properties",["^5",["isCustomPattern","message","visitEndAnchor","buildLineBreakIssueMessage","canBeOptimized","findEmptyMatchRegExps","hasCustom","findUnsupportedFlags","issue","isShortPattern","prototype","isCustom","group","patternIdxToConfig","str","pop","visitStartAnchor","found","__esModule","useSticky","tokenType","positionTracking","lastIndex","findMissingPatterns","push","longerAlt","findInvalidPatterns","minOptimizationVal","errors","validatePatterns","short","addStickyFlag","findEndOfInputAnchor","exec","disableSticky","MODES","value","valid","tokenTypeIdx","enableSticky","errMsg","debug","charCodeToOptimizedIndex","safeMode","tracer","emptyGroups","SUPPORT_STICKY","findModesThatDoNotExist","findUnreachablePatterns","pattern","type","charCodeToPatternIdxToConfig","canLineTerminator","__proto__","DEFAULT_MODE","findDuplicatePatterns","findStartOfInputAnchor","idx","performWarningRuntimeChecks","cloneEmptyGroups","analyzeTokenTypes","tokenTypes","findInvalidGroupType","lineTerminatorCharacters","LineTerminatorOptimizedTester","performRuntimeChecks","test","constructor","addStartOfInput"]],"~:compiled-at",1630917515672,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$chevrotain$lib$src$scan$lexer.js\",\n\"lineCount\":45,\n\"mappings\":\"AAAAA,cAAA,CAAA,iDAAA,CAAsE,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAiT9GC,QAASA,sBAAqB,CAACC,UAAD,CAAa,CACvC,IAAIC,OAAS,EACTC,WAAAA,CAAqBC,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACK,WAAD,CAAc,CACvE,MAAOF,QAAQG,CAAAA,QAAR,CAAiBD,WAAA,CAAA,OAAjB,CADgE,CAAlD,CAGzBJ,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcC,oBAAA,CAAqBN,UAArB,CAAd,CACTD,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcE,sBAAA,CAAuBP,UAAvB,CAAd,CACTD,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcG,oBAAA,CAAqBR,UAArB,CAAd,CACTD,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcI,qBAAA,CAAsBT,UAAtB,CAAd,CAET,OADAD,OACA;AADSA,MAAOM,CAAAA,MAAP,CAAcK,qBAAA,CAAsBV,UAAtB,CAAd,CAT8B,CAY3CW,QAASA,oBAAmB,CAACb,UAAD,CAAa,CACrC,IAAIc,6BAA+BX,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACe,QAAD,CAAW,CAC9E,MAAO,CAACZ,OAAQa,CAAAA,GAAR,CAAYD,QAAZ,CAvSFE,SAuSE,CADsE,CAA/C,CAAnC,CAGIhB,OAASE,OAAQe,CAAAA,GAAR,CAAYJ,4BAAZ,CAA0C,QAAS,CAACC,QAAD,CAAW,CACvE,MAAO,CACHI,QAAS,mBAATA,CACIJ,QAASK,CAAAA,IADbD,CAEI,yCAHD,CAIHE,KAAMC,cAAeC,CAAAA,wBAAyBC,CAAAA,eAJ3C,CAKHxB,WAAY,CAACe,QAAD,CALT,CADgE,CAA9D,CASTU,WAAAA,CAAQtB,OAAQuB,CAAAA,UAAR,CAAmB1B,UAAnB,CAA+Bc,4BAA/B,CACZ;MAAO,CAAUb,MAAV,CAAkBwB,MAAOA,UAAzB,CAd8B,CAiBzCE,QAASA,oBAAmB,CAAC3B,UAAD,CAAa,CACrC,IAAI4B,6BAA+BzB,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACe,QAAD,CAAW,CAC1Ec,QAAAA,CAAUd,QAAA,CAAA,OACd,OAAQ,CAACZ,OAAQG,CAAAA,QAAR,CAAiBuB,QAAjB,CAAT,EACI,CAAC1B,OAAQ2B,CAAAA,UAAR,CAAmBD,QAAnB,CADL,EAEI,CAAC1B,OAAQa,CAAAA,GAAR,CAAYa,QAAZ,CAAqB,MAArB,CAFL,EAGI,CAAC1B,OAAQ4B,CAAAA,QAAR,CAAiBF,QAAjB,CALyE,CAA/C,CAAnC,CAOI5B,OAASE,OAAQe,CAAAA,GAAR,CAAYU,4BAAZ,CAA0C,QAAS,CAACb,QAAD,CAAW,CACvE,MAAO,CACHI,QAAS,mBAATA,CACIJ,QAASK,CAAAA,IADbD,CAEI,4JAHD;AAKHE,KAAMC,cAAeC,CAAAA,wBAAyBS,CAAAA,eAL3C,CAMHhC,WAAY,CAACe,QAAD,CANT,CADgE,CAA9D,CAUTU,WAAAA,CAAQtB,OAAQuB,CAAAA,UAAR,CAAmB1B,UAAnB,CAA+B4B,4BAA/B,CACZ,OAAO,CAAU3B,MAAV,CAAkBwB,MAAOA,UAAzB,CAnB8B,CAuBzCjB,QAASA,qBAAoB,CAACR,UAAD,CAAa,CACtC,IAAIiC,gBAAiC,QAAS,CAACC,MAAD,CAAS,CAEnDD,QAASA,gBAAe,EAAG,CACvB,IAAIE,MAAmB,IAAnBA,GAAQD,MAARC,EAA2BD,MAAOE,CAAAA,KAAP,CAAa,IAAb,CAAmBC,SAAnB,CAA3BF,EAA4D,IAChEA,MAAMG,CAAAA,KAAN,CAAc,CAAA,CACd,OAAOH,MAHgB,CAD3BI,SAAA,CAAUN,eAAV,CAA2BC,MAA3B,CAMAD,gBAAgBO,CAAAA,SAAUC,CAAAA,cAA1B,CAA2CC,QAAS,CAACC,IAAD,CAAO,CACvD,IAAKL,CAAAA,KAAL,CAAa,CAAA,CAD0C,CAG3D,OAAOL,gBAV4C,CAAlB,CAWnCW,eAAgBC,CAAAA,iBAXmB,CAYjCC;UAAAA,CAAe3C,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACe,QAAD,CAAW,CAC1Dc,QAAAA,CAAUd,QAAA,CAAA,OACd,IAAI,CACA,IAAIgC,UAAYC,gBAAiBC,CAAAA,YAAjB,CAA8BpB,QAA9B,CAAhB,CACIqB,iBAAmB,IAAIjB,eAC3BiB,iBAAiBC,CAAAA,KAAjB,CAAuBJ,SAAvB,CACA,OAAOG,iBAAiBZ,CAAAA,KAJxB,CAMJ,MAAOc,CAAP,CAAU,CAGN,MAAOC,aAAaC,CAAAA,IAAb,CAAkBzB,QAAQ0B,CAAAA,MAA1B,CAHD,CARoD,CAA/C,CA0BnB,OAZapD,QAAQe,CAAAA,GAARjB,CAAY6C,UAAZ7C,CAA0B,QAAS,CAACc,QAAD,CAAW,CACvD,MAAO,CACHI,QAAS,sDAATA,CAEIJ,QAASK,CAAAA,IAFbD,CAGI,iJAJD;AAOHE,KAAMC,cAAeC,CAAAA,wBAAyBiC,CAAAA,gBAP3C,CAQHxD,WAAY,CAACe,QAAD,CART,CADgD,CAA9Cd,CA3ByB,CA0C1CW,QAASA,sBAAqB,CAACZ,UAAD,CAAa,CACnCyD,UAAAA,CAAqBtD,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACe,QAAD,CAAW,CAEpE,MADcA,SAAAc,CAAAA,OACCyB,CAAAA,IAAR,CAAa,EAAb,CAF6D,CAA/C,CAazB,OATanD,QAAQe,CAAAA,GAARjB,CAAYwD,UAAZxD,CAAgC,QAAS,CAACc,QAAD,CAAW,CAC7D,MAAO,CACHI,QAAS,mBAATA,CACIJ,QAASK,CAAAA,IADbD,CAEI,uDAHD,CAIHE,KAAMC,cAAeC,CAAAA,wBAAyBmC,CAAAA,mBAJ3C,CAKH1D,WAAY,CAACe,QAAD,CALT,CADsD,CAApDd,CAL0B,CAkB3CQ,QAASA,uBAAsB,CAACT,UAAD,CAAa,CACxC,IAAI2D;AAAmC,QAAS,CAACzB,MAAD,CAAS,CAErDyB,QAASA,kBAAiB,EAAG,CACzB,IAAIxB,MAAmB,IAAnBA,GAAQD,MAARC,EAA2BD,MAAOE,CAAAA,KAAP,CAAa,IAAb,CAAmBC,SAAnB,CAA3BF,EAA4D,IAChEA,MAAMG,CAAAA,KAAN,CAAc,CAAA,CACd,OAAOH,MAHkB,CAD7BI,SAAA,CAAUoB,iBAAV,CAA6BzB,MAA7B,CAMAyB,kBAAkBnB,CAAAA,SAAUoB,CAAAA,gBAA5B,CAA+CC,QAAS,CAAClB,IAAD,CAAO,CAC3D,IAAKL,CAAAA,KAAL,CAAa,CAAA,CAD8C,CAG/D,OAAOqB,kBAV8C,CAAlB,CAWrCf,eAAgBC,CAAAA,iBAXqB,CAYnCC,WAAAA,CAAe3C,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACe,QAAD,CAAW,CAC1Dc,QAAAA,CAAUd,QAAA,CAAA,OACd,IAAI,CACA,IAAIgC,UAAYC,gBAAiBC,CAAAA,YAAjB,CAA8BpB,QAA9B,CAAhB,CACIiC,mBAAqB,IAAIH,iBAC7BG,mBAAmBX,CAAAA,KAAnB,CAAyBJ,SAAzB,CACA;MAAOe,mBAAmBxB,CAAAA,KAJ1B,CAMJ,MAAOc,CAAP,CAAU,CAGN,MAAOW,eAAeT,CAAAA,IAAf,CAAoBzB,QAAQ0B,CAAAA,MAA5B,CAHD,CARoD,CAA/C,CA0BnB,OAZapD,QAAQe,CAAAA,GAARjB,CAAY6C,UAAZ7C,CAA0B,QAAS,CAACc,QAAD,CAAW,CACvD,MAAO,CACHI,QAAS,sDAATA,CAEIJ,QAASK,CAAAA,IAFbD,CAGI,2JAJD,CAOHE,KAAMC,cAAeC,CAAAA,wBAAyByC,CAAAA,gBAP3C,CAQHhE,WAAY,CAACe,QAAD,CART,CADgD,CAA9Cd,CA3B2B,CA0C5CS,QAASA,qBAAoB,CAACV,UAAD,CAAa,CAClCiE,UAAAA;AAAe9D,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACe,QAAD,CAAW,CAC1Dc,QAAAA,CAAUd,QAAA,CAAA,OACd,OAAOc,SAAP,WAA0BqC,OAA1B,GAAqCrC,QAAQsC,CAAAA,SAA7C,EAA0DtC,QAAQlC,CAAAA,MAAlE,CAF8D,CAA/C,CAanB,OATaQ,QAAQe,CAAAA,GAARjB,CAAYgE,UAAZhE,CAA0B,QAAS,CAACc,QAAD,CAAW,CACvD,MAAO,CACHI,QAAS,mBAATA,CACIJ,QAASK,CAAAA,IADbD,CAEI,sEAHD,CAIHE,KAAMC,cAAeC,CAAAA,wBAAyB6C,CAAAA,uBAJ3C,CAKHpE,WAAY,CAACe,QAAD,CALT,CADgD,CAA9Cd,CALyB,CAkB1CU,QAASA,sBAAqB,CAACX,UAAD,CAAa,CACvC,IAAIsC,MAAQ,EAAZ,CACI+B,kBAAoBlE,OAAQe,CAAAA,GAAR,CAAYlB,UAAZ;AAAwB,QAAS,CAACsE,SAAD,CAAY,CACjE,MAAOnE,QAAQoE,CAAAA,MAAR,CAAevE,UAAf,CAA2B,QAAS,CAACwE,MAAD,CAASC,SAAT,CAAoB,CACvDH,SAAUrD,CAAAA,OAAQsC,CAAAA,MAAtB,GAAiCkB,SAAUxD,CAAAA,OAAQsC,CAAAA,MAAnD,EACKpD,OAAQuE,CAAAA,QAAR,CAAiBpC,KAAjB,CAAwBmC,SAAxB,CADL,EAEIA,SAAUxD,CAAAA,OAFd,GAE0BK,cAAeqD,CAAAA,KAAMC,CAAAA,EAF/C,GAKItC,KAAMuC,CAAAA,IAAN,CAAWJ,SAAX,CACA,CAAAD,MAAOK,CAAAA,IAAP,CAAYJ,SAAZ,CANJ,CASA,OAAOD,OAVoD,CAAxD,CAWJ,EAXI,CAD0D,CAA7C,CAcxBH,kBAAA,CAAoBlE,OAAQ2E,CAAAA,OAAR,CAAgBT,iBAAhB,CAChBU,kBAAAA,CAAoB5E,OAAQC,CAAAA,MAAR,CAAeiE,iBAAf,CAAkC,QAAS,CAACW,gBAAD,CAAmB,CAClF,MAAiC,EAAjC,CAAOA,gBAAiBC,CAAAA,MAD0D,CAA9D,CAexB,OAZa9E,QAAQe,CAAAA,GAARjB,CAAY8E,iBAAZ9E,CAA+B,QAAS,CAACiF,cAAD,CAAiB,CAClE,IAAIC;AAAiBhF,OAAQe,CAAAA,GAAR,CAAYgE,cAAZ,CAA4B,QAAS,CAACnE,QAAD,CAAW,CACjE,MAAOA,SAASK,CAAAA,IADiD,CAAhD,CAIrB,OAAO,CACHD,QAAS,+BAATA,CAFgBhB,OAAQiF,CAAAA,KAAR,CAAcF,cAAd,CAA8BjE,CAAAA,OAE9CE,CAAwD,0DAAxDA,EAC6DgE,cAAeE,CAAAA,IAAf,CAAoB,IAApB,CAD7DlE,CACyF,QADzFA,CADG,CAGHE,KAAMC,cAAeC,CAAAA,wBAAyB+D,CAAAA,wBAH3C,CAIHtF,WAAYkF,cAJT,CAL2D,CAAzDjF,CApB0B,CAmC3CsF,QAASA,qBAAoB,CAACvF,UAAD,CAAa,CAClCwF,UAAAA,CAAerF,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACyF,KAAD,CAAQ,CAC3D,GAAI,CAACtF,OAAQa,CAAAA,GAAR,CAAYyE,KAAZ,CAAmB,OAAnB,CAAL,CACI,MAAO,CAAA,CAEPC,MAAAA,CAAQD,KAAME,CAAAA,KAClB;MAAOD,MAAP,GAAiBpE,cAAeqD,CAAAA,KAAMiB,CAAAA,OAAtC,EAAiDF,KAAjD,GAA2DpE,cAAeqD,CAAAA,KAAMC,CAAAA,EAAhF,EAAsF,CAACzE,OAAQ4B,CAAAA,QAAR,CAAiB2D,KAAjB,CAL5B,CAA5C,CAgBnB,OATavF,QAAQe,CAAAA,GAARjB,CAAYuF,UAAZvF,CAA0B,QAAS,CAACc,QAAD,CAAW,CACvD,MAAO,CACHI,QAAS,mBAATA,CACIJ,QAASK,CAAAA,IADbD,CAEI,kEAHD,CAIHE,KAAMC,cAAeC,CAAAA,wBAAyBsE,CAAAA,wBAJ3C,CAKH7F,WAAY,CAACe,QAAD,CALT,CADgD,CAA9Cd,CARyB,CAoB1C6F,QAASA,wBAAuB,CAAC9F,UAAD,CAAa+F,UAAb,CAAyB,CACjDC,UAAAA,CAAe7F,OAAQC,CAAAA,MAAR,CAAeJ,UAAf,CAA2B,QAAS,CAACyF,KAAD,CAAQ,CAC3D,MAA4BQ,KAAAA,EAA5B,GAAQR,KAAMS,CAAAA,SAAd;AAAyC,CAAC/F,OAAQuE,CAAAA,QAAR,CAAiBqB,UAAjB,CAA6BN,KAAMS,CAAAA,SAAnC,CADiB,CAA5C,CAYnB,OATa/F,QAAQe,CAAAA,GAARjB,CAAY+F,UAAZ/F,CAA0B,QAAS,CAACkG,OAAD,CAAU,CAGtD,MAAO,CACHhF,QAHM,mBAGNA,CAHyBgF,OAAQ/E,CAAAA,IAGjCD,CAHwC,mEAGxCA,CAHwGgF,OAAQD,CAAAA,SAGhH/E,CAH4H,2BAEzH,CAEHE,KAAMC,cAAeC,CAAAA,wBAAyB6E,CAAAA,wBAF3C,CAGHpG,WAAY,CAACmG,OAAD,CAHT,CAH+C,CAA7ClG,CAJwC,CAgBzDoG,QAASA,wBAAuB,CAACrG,UAAD,CAAa,CACzC,IAAIC,OAAS,EAAb,CACIqG,YAAcnG,OAAQoE,CAAAA,MAAR,CAAevE,UAAf,CAA2B,QAAS,CAACwE,MAAD,CAAS2B,OAAT,CAAkBI,GAAlB,CAAuB,CACzE,IAAI1E,QAAUsE,OAAQlF,CAAAA,OACtB;GAAIY,OAAJ,GAAgBP,cAAeqD,CAAAA,KAAMC,CAAAA,EAArC,CACI,MAAOJ,OAIPrE,QAAQ4B,CAAAA,QAAR,CAAiBF,OAAjB,CAAJ,CACI2C,MAAOK,CAAAA,IAAP,CAAY,CAAE2B,IAAK3E,OAAP,CAAqB0E,GAArB,CAA0BE,UAAWN,OAArC,CAAZ,CADJ,CAGShG,OAAQG,CAAAA,QAAR,CAAiBuB,OAAjB,CAHT,EAGsC6E,UAAA,CAAW7E,OAAX,CAHtC,EAII2C,MAAOK,CAAAA,IAAP,CAAY,CAAE2B,IAAK3E,OAAQ0B,CAAAA,MAAf,CAA4BgD,GAA5B,CAAiCE,UAAWN,OAA5C,CAAZ,CAEJ,OAAO3B,OAbkE,CAA3D,CAcf,EAde,CAelBrE,QAAQwG,CAAAA,OAAR,CAAgB3G,UAAhB,CAA4B,QAAS,CAACmG,OAAD,CAAUS,OAAV,CAAmB,CACpDzG,OAAQwG,CAAAA,OAAR,CAAgBL,WAAhB,CAA6B,QAAS,CAACO,EAAD,CAAK,CAAA,IACnCL,IAAMK,EAAGL,CAAAA,GAD0B,CACPC,UAAYI,EAAGJ,CAAAA,SAC3CG,QAAJ,CADwBC,EAAGN,CAAAA,GAC3B,EAAqBO,aAAA,CAAcN,GAAd,CAAmBL,OAAQlF,CAAAA,OAA3B,CAArB,EAKIhB,MAAO4E,CAAAA,IAAP,CAAY,CACR1D,QALM,cAKNA,CALoBsF,SAAUrF,CAAAA,IAK9BD,CALqC,4EAKrCA;CAJgDgF,OAAQ/E,CAAAA,IAIxDD,CAJ+D,+GAI/DA,CADQ,CAERE,KAAMC,cAAeC,CAAAA,wBAAyBwF,CAAAA,mBAFtC,CAGR/G,WAAY,CAACmG,OAAD,CAAUM,SAAV,CAHJ,CAAZ,CAPmC,CAA3C,CADoD,CAAxD,CAgBA,OAAOxG,OAjCkC,CAoC7C6G,QAASA,cAAa,CAACN,GAAD,CAAM3E,OAAN,CAAe,CAEjC,GAAI1B,OAAQG,CAAAA,QAAR,CAAiBuB,OAAjB,CAAJ,CAEI,MADImF,IACG,CADWnF,OAAQoF,CAAAA,IAAR,CAAaT,GAAb,CACX,CAAgB,IAAhB,GAAAQ,GAAA,EAA8C,CAA9C,GAAwBA,GAAYE,CAAAA,KAE1C,IAAI/G,OAAQ2B,CAAAA,UAAR,CAAmBD,OAAnB,CAAJ,CAED,MAAOA,QAAA,CAAQ2E,GAAR,CAAa,CAAb,CAAgB,EAAhB,CAAoB,EAApB,CAEN,IAAIrG,OAAQa,CAAAA,GAAR,CAAYa,OAAZ,CAAqB,MAArB,CAAJ,CAED,MAAOA,QAAQoF,CAAAA,IAAR,CAAaT,GAAb,CAAkB,CAAlB,CAAqB,EAArB,CAAyB,EAAzB,CAEN,IAAuB,QAAvB,GAAI,MAAO3E,QAAX,CACD,MAAOA,QAAP;AAAmB2E,GAGnB,MAAMW,MAAA,CAAM,sBAAN,CAAN,CAlB6B,CAqBrCT,QAASA,WAAU,CAACU,MAAD,CAAS,CAiBxB,MAAoGnB,KAAAA,EAApG,GAAQ9F,OAAQkH,CAAAA,IAAR,CAfQC,gBAAAA,CAAAA,KAAAA,CAAAA,EAAAA,CAeR,CAAwB,QAAS,CAACC,IAAD,CAAO,CAAE,MAAuC,EAAvC,GAAOH,MAAO7D,CAAAA,MAAOiE,CAAAA,OAAd,CAAsBD,IAAtB,CAAT,CAAxC,CAjBgB,CAmB5BE,QAASA,gBAAe,CAAC5F,OAAD,CAAU,CAI9B,MAAO,KAAIqC,MAAJ,CAAW,MAAX,CAAoBrC,OAAQ0B,CAAAA,MAA5B,CAAqC,GAArC,CAHK1B,OAAQ6F,CAAAA,UAARC,CAAqB,GAArBA,CAA2B,EAGhC,CAJuB,CAOlCC,QAASA,cAAa,CAAC/F,OAAD,CAAU,CAI5B,MAAO,KAAIqC,MAAJ,CAAW,EAAX,CAAgBrC,OAAQ0B,CAAAA,MAAxB,CAHK1B,OAAQ6F,CAAAA,UAARC,CAAqB,IAArBA,CAA4B,GAGjC,CAJqB,CAkHhCE,QAASA,gBAAe,CAACpB,SAAD,CAAY,CAC5B5E,SAAAA,CAAU4E,SAAUxF,CAAAA,OAExB,IAAId,OAAQG,CAAAA,QAAR,CAAiBuB,SAAjB,CAAJ,CACI,MAAO,CAAA,CAMN,IAJI1B,OAAQ2B,CAAAA,UAAR,CAAmBD,SAAnB,CAIJ;AAAI1B,OAAQa,CAAAA,GAAR,CAAYa,SAAZ,CAAqB,MAArB,CAAJ,CAED,MAAO,CAAA,CAEN,IAAI1B,OAAQ4B,CAAAA,QAAR,CAAiBF,SAAjB,CAAJ,CACD,MAAO,CAAA,CAGP,MAAMsF,MAAA,CAAM,sBAAN,CAAN,CAlB4B,CAsBpCW,QAASA,eAAc,CAACjG,OAAD,CAAU,CAC7B,MAAI1B,QAAQ4B,CAAAA,QAAR,CAAiBF,OAAjB,CAAJ,EAAoD,CAApD,GAAiCA,OAAQoD,CAAAA,MAAzC,CACWpD,OAAQkG,CAAAA,UAAR,CAAmB,CAAnB,CADX,CAIW,CAAA,CALkB,CAoCjCC,QAASA,sBAAqB,CAAC7B,OAAD,CAAU8B,uBAAV,CAAmC,CAC7D,GAAI9H,OAAQa,CAAAA,GAAR,CAAYmF,OAAZ,CAAqB,aAArB,CAAJ,CAGI,MAAO,CAAA,CAIP,IAAIhG,OAAQG,CAAAA,QAAR,CAAiB6F,OAAQlF,CAAAA,OAAzB,CAAJ,CAAuC,CACnC,GAAI,CAEAiH,SAAUC,CAAAA,gBAAV,CAA2BF,uBAA3B,CAAoD9B,OAAQlF,CAAAA,OAA5D,CAFA,CAIJ,MAAOmC,CAAP,CAAU,CAEN,MAAO,CACHgF,MAAO9G,cAAeC,CAAAA,wBAAyB8G,CAAAA,mBAD5C;AAEHC,OAAQlF,CAAEjC,CAAAA,OAFP,CAFD,CAOV,MAAO,CAAA,CAZ4B,CAclC,GAAIhB,OAAQ4B,CAAAA,QAAR,CAAiBoE,OAAQlF,CAAAA,OAAzB,CAAJ,CAED,MAAO,CAAA,CAEN,IAAI4G,eAAA,CAAgB1B,OAAhB,CAAJ,CAED,MAAO,CAAEiC,MAAO9G,cAAeC,CAAAA,wBAAyBgH,CAAAA,iBAAjD,CAGP,MAAMpB,MAAA,CAAM,sBAAN,CAAN,CA/BqD,CAmCjEqB,QAASA,2BAA0B,CAACrC,OAAD,CAAUsC,OAAV,CAAmB,CAElD,GAAIA,OAAQL,CAAAA,KAAZ,GAAsB9G,cAAeC,CAAAA,wBAAyB8G,CAAAA,mBAA9D,CACI,MAAQ,6FAAR,EACmClC,OAAQ/E,CAAAA,IAD3C,CACkD,kCADlD,GAEyBqH,OAAQH,CAAAA,MAFjC;AAE0C,wGAF1C,CAKC,IAAIG,OAAQL,CAAAA,KAAZ,GAAsB9G,cAAeC,CAAAA,wBAAyBgH,CAAAA,iBAA9D,CACD,MAAQ,8GAAR,EACmCpC,OAAQ/E,CAAAA,IAD3C,CACkD,oHADlD,CAKA,MAAM+F,MAAA,CAAM,sBAAN,CAAN,CAd8C,CAkBtDuB,QAASA,aAAY,CAACC,YAAD,CAAe,CAShC,MARgBxI,QAAQe,CAAAA,GAAR0H,CAAYD,YAAZC;AAA0B,QAAS,CAACC,WAAD,CAAc,CAC7D,MAAI1I,QAAQ4B,CAAAA,QAAR,CAAiB8G,WAAjB,CAAJ,EAA0D,CAA1D,CAAqCA,WAAY5D,CAAAA,MAAjD,CACW4D,WAAYd,CAAAA,UAAZ,CAAuB,CAAvB,CADX,CAIWc,WALkD,CAAjDD,CADgB,CAWpCE,QAASA,iBAAgB,CAAC5H,GAAD,CAAM6H,GAAN,CAAWC,KAAX,CAAkB,CACtB/C,IAAAA,EAAjB,GAAI/E,GAAA,CAAI6H,GAAJ,CAAJ,CACI7H,GAAA,CAAI6H,GAAJ,CADJ,CACe,CAACC,KAAD,CADf,CAII9H,GAAA,CAAI6H,GAAJ,CAASlE,CAAAA,IAAT,CAAcmE,KAAd,CALmC,CAyB3CC,QAASA,yBAAwB,CAACC,QAAD,CAAW,CACxC,MAAOA,SAAA,CAAWpJ,OAAQqJ,CAAAA,kBAAnB,CACDD,QADC,CAEDE,yBAAA,CAA0BF,QAA1B,CAHkC,CA13B5C,IAAI3G,UAAa,IAAbA,EAAqB,IAAKA,CAAAA,SAA1BA,EAAyC,QAAS,EAAG,CACrD,IAAI8G,cAAgBA,QAAS,CAACC,UAAD,CAAIC,UAAJ,CAAO,CAChCF,aAAA,CAAgBG,MAAOC,CAAAA,cAAvB,EACK,CAAEC,UAAW,EAAb,CADL;AACkCC,KADlC,EAC2C,QAAS,CAACL,CAAD,CAAIC,CAAJ,CAAO,CAAED,CAAEI,CAAAA,SAAF,CAAcH,CAAhB,CAD3D,EAEI,QAAS,CAACD,CAAD,CAAIC,CAAJ,CAAO,CAAE,IAAKK,IAAIA,CAAT,GAAcL,EAAd,CAAqBC,MAAOhH,CAAAA,SAAUqH,CAAAA,cAAeC,CAAAA,IAAhC,CAAqCP,CAArC,CAAwCK,CAAxC,CAAJ,GAAgDN,CAAA,CAAEM,CAAF,CAAhD,CAAuDL,CAAA,CAAEK,CAAF,CAAvD,CAAnB,CACpB,OAAOP,cAAA,CAAcC,UAAd,CAAiBC,UAAjB,CAJyB,CAMpC,OAAO,SAAS,CAACD,CAAD,CAAIC,CAAJ,CAAO,CAInBQ,QAASA,GAAE,EAAG,CAAE,IAAKC,CAAAA,WAAL,CAAmBV,CAArB,CAHd,GAAiB,UAAjB,GAAI,MAAOC,EAAX,EAAqC,IAArC,GAA+BA,CAA/B,CACI,KAAM,KAAIU,SAAJ,CAAc,sBAAd,CAAuCC,MAAA,CAAOX,CAAP,CAAvC,CAAmD,+BAAnD,CAAN,CACJF,aAAA,CAAcC,CAAd,CAAiBC,CAAjB,CAEAD,EAAE9G,CAAAA,SAAF,CAAoB,IAAN,GAAA+G,CAAA,CAAaC,MAAOW,CAAAA,MAAP,CAAcZ,CAAd,CAAb,EAAiCQ,EAAGvH,CAAAA,SAAH,CAAe+G,CAAE/G,CAAAA,SAAjB,CAA4B,IAAIuH,EAAjE,CALK,CAP8B,CAAb,EAe5CP,OAAOY,CAAAA,cAAP,CAAsBtK,OAAtB,CAA+B,YAA/B,CAA6C,CAAEkJ,MAAO,CAAA,CAAT,CAA7C,CACAlJ,QAAQmJ,CAAAA,wBAAR;AAAmCnJ,OAAQqJ,CAAAA,kBAA3C,CAAgErJ,OAAQ0I,CAAAA,0BAAxE,CAAqG1I,OAAQuK,CAAAA,6BAA7G,CAA6IvK,OAAQgI,CAAAA,cAArJ,CAAsKhI,OAAQ+H,CAAAA,eAA9K,CAAgM/H,OAAQwK,CAAAA,gBAAxM,CAA2NxK,OAAQyK,CAAAA,2BAAnO,CAAiQzK,OAAQ0K,CAAAA,oBAAzQ,CAAgS1K,OAAQ8H,CAAAA,aAAxS,CAAwT9H,OAAQ2H,CAAAA,eAAhU,CAAkV3H,OAAQuG,CAAAA,uBAA1V,CAAoXvG,OAAQgG,CAAAA,uBAA5X,CAAsZhG,OAAQyF,CAAAA,oBAA9Z,CAAqbzF,OAAQa,CAAAA,qBAA7b,CAAqdb,OAAQY,CAAAA,oBAA7d,CAAofZ,OAAQW,CAAAA,sBAA5f,CAAqhBX,OAAQc,CAAAA,qBAA7hB,CAAqjBd,OAAQU,CAAAA,oBAA7jB;AAAolBV,OAAQ6B,CAAAA,mBAA5lB,CAAknB7B,OAAQe,CAAAA,mBAA1nB,CAAgpBf,OAAQ2K,CAAAA,gBAAxpB,CAA2qB3K,OAAQ4K,CAAAA,iBAAnrB,CAAusB5K,OAAQ6K,CAAAA,YAA/sB,CAA8tB7K,OAAQ8K,CAAAA,aAAtuB,CAAsvB9K,OAAQ+K,CAAAA,cAA9vB,CAA+wB/K,OAAQgL,CAAAA,KAAvxB,CAA+xBhL,OAAQiL,CAAAA,YAAvyB,CAAszB,IAAK,EAC3zB,KAAInI,gBAAkBhD,OAAA,CAAQ,qDAAR,CAAtB,CACI0B,eAAiB1B,OAAA,CAAQ,0DAAR,CADrB,CAEIO,QAAUP,OAAA,CAAQ,mDAAR,CAFd,CAGIsI,UAAYtI,OAAA,CAAQ,qDAAR,CAHhB;AAIIoD,iBAAmBpD,OAAA,CAAQ,4DAAR,CAEvBE,QAAQiL,CAAAA,YAAR,CAAuB,aACvBjL,QAAQgL,CAAAA,KAAR,CAAgB,OAChBhL,QAAQ+K,CAAAA,cAAR,CAA8D,SAA9D,GAAyB,MAAO,MAAmBG,CAAAA,MAInDlL,QAAQ8K,CAAAA,aAAR,CAHAA,QAAsB,EAAG,CACrB9K,OAAQ+K,CAAAA,cAAR,CAAyB,CAAA,CADJ,CAOzB/K,QAAQ6K,CAAAA,YAAR,CAHAA,QAAqB,EAAG,CACpB7K,OAAQ+K,CAAAA,cAAR,CAAyB,CAAA,CADL,CAkQxB/K,QAAQ4K,CAAAA,iBAAR,CA9PAA,QAA0B,CAAC1K,UAAD,CAAaiL,OAAb,CAAsB,CAC5CA,OAAA,CAAU9K,OAAQ+K,CAAAA,QAAR,CAAiBD,OAAjB,CAA0B,CAChCE,UAAWrL,OAAQ+K,CAAAA,cADa,CAEhCO,MAAO,CAAA,CAFyB,CAGhCC,SAAU,CAAA,CAHsB,CAIhCC,iBAAkB,MAJc,CAKhCC,yBAA0B,CAAC,IAAD;AAAO,IAAP,CALM,CAMhCC,OAAQA,QAAS,CAACC,GAAD,CAAMC,MAAN,CAAc,CAAE,MAAOA,OAAA,EAAT,CANC,CAA1B,CAQV,KAAIF,OAASP,OAAQO,CAAAA,MACrBA,OAAA,CAAO,iCAAP,CAA0C,QAAS,EAAG,CA61BtD,GAAIrL,OAAQwL,CAAAA,OAAR,CAAgBvC,yBAAhB,CAAJ,CAAgD,CAC5CA,yBAAA,CAAgCO,KAAJ,CAAU,KAAV,CAC5B,KAAK,IAAIiC,EAAI,CAAb,CAAoB,KAApB,CAAgBA,CAAhB,CAA2BA,CAAA,EAA3B,CAEIxC,yBAAA,CAA0BwC,CAA1B,CAAA,CAAmC,GAAJ,CAAAA,CAAA,CAAU,GAAV,CAAgB,CAAC,EAAEA,CAAF,CAAM,GAAN,CAAjB,CAA8BA,CAJrB,CA71BM,CAAtD,CAGA,KAAIC,iBACJL,OAAA,CAAO,iBAAP,CAA0B,QAAS,EAAG,CAClCK,iBAAA,CAAoB1L,OAAQ2L,CAAAA,MAAR,CAAe9L,UAAf,CAA2B,QAAS,CAACe,QAAD,CAAW,CAC/D,MAAOA,SAAA,CAAA,OAAP,GAA6BO,cAAeqD,CAAAA,KAAMC,CAAAA,EADa,CAA/C,CADc,CAAtC,CAKA,KAAImH,UAAY,CAAA,CAAhB,CACIC,sBACJR;MAAA,CAAO,oBAAP,CAA6B,QAAS,EAAG,CACrCO,SAAA,CAAY,CAAA,CACZC,uBAAA,CAAyB7L,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAAC9K,QAAD,CAAW,CACpEkL,QAAAA,CAAclL,QAAA,CAAA,OAElB,IAAIZ,OAAQG,CAAAA,QAAR,CAAiB2L,QAAjB,CAAJ,CAAmC,CAC/B,IAAIC,aAAeD,QAAY1I,CAAAA,MAC/B,OAA4B,EAA5B,GAAI2I,YAAajH,CAAAA,MAAjB,EAEqB,GAFrB,GAEIiH,YAFJ,EAGqB,GAHrB,GAGIA,YAHJ,EAIqB,GAJrB,GAIIA,YAJJ,EAKKD,QAAYvE,CAAAA,UALjB,CAQiC,CAA5B,GAAIwE,YAAajH,CAAAA,MAAjB,EACmB,IADnB,GACDiH,YAAA,CAAa,CAAb,CADC,EAGA/L,OAAQuE,CAAAA,QAAR,CAAiB,kBAAA,CAAA,KAAA,CAAA,EAAA,CAAjB,CAiBEwH,YAAA,CAAa,CAAb,CAjBF,CAHA,CA2BMjB,OAAQE,CAAAA,SAAR,CACDvD,aAAA,CAAcqE,QAAd,CADC,CAEDxE,eAAA,CAAgBwE,QAAhB,CA7BL;AAwBMC,YAAA,CAAa,CAAb,CAhCX,CAMWA,YARoB,CA0C9B,GAAI/L,OAAQ2B,CAAAA,UAAR,CAAmBmK,QAAnB,CAAJ,CAGD,MAFAF,UAEO,CAFK,CAAA,CAEL,CAAA,CAAE9E,KAAMgF,QAAR,CAEN,IAAI9L,OAAQa,CAAAA,GAAR,CAAYiL,QAAZ,CAAyB,MAAzB,CAAJ,CAGD,MAFAF,UAEOE,CAFK,CAAA,CAELA,CAAAA,QAEN,IAA2B,QAA3B,GAAI,MAAOA,SAAX,CAAqC,CACtC,GAA2B,CAA3B,GAAIA,QAAYhH,CAAAA,MAAhB,CACI,MAAOgH,SAGHE,SAAAA,CAAsBF,QAAYG,CAAAA,OAAZ,CAAoB,qBAApB,CAA2C,SAA3C,CACtBC,SAAAA,CAAgB,IAAInI,MAAJ,CAAWiI,QAAX,CACpB,OAAOlB,QAAQE,CAAAA,SAAR,CACDvD,aAAA,CAAcyE,QAAd,CADC,CAED5E,eAAA,CAAgB4E,QAAhB,CAT4B,CAatC,KAAMlF,MAAA,CAAM,sBAAN,CAAN,CApEoE,CAAnD,CAFY,CAAzC,CA0EA,KAAImF,gBAAJ,CACIC,iBADJ,CAEIC,wBAFJ,CAGIC,oBAHJ;AAIIC,mBACJlB,OAAA,CAAO,cAAP,CAAuB,QAAS,EAAG,CAC/Bc,gBAAA,CAAmBnM,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAAC9K,QAAD,CAAW,CAAE,MAAOA,SAAS4L,CAAAA,YAAlB,CAAnD,CACnBJ,kBAAA,CAAoBpM,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAACpG,KAAD,CAAQ,CAC5DmH,KAAAA,CAAYnH,KAAME,CAAAA,KAEtB,IAAIiH,KAAJ,GAAkBtL,cAAeqD,CAAAA,KAAMiB,CAAAA,OAAvC,CAGK,CAAA,GAAIzF,OAAQ4B,CAAAA,QAAR,CAAiB6K,KAAjB,CAAJ,CACD,MAAOA,MAEN,IAAIzM,OAAQ0M,CAAAA,WAAR,CAAoBD,KAApB,CAAJ,CACD,MAAO,CAAA,CAGP,MAAMzF,MAAA,CAAM,sBAAN,CAAN,CAPC,CAN2D,CAAhD,CAgBpBqF,yBAAA,CAA2BrM,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAACpG,KAAD,CAAQ,CAEvE,GADIqH,KACJ,CADoBrH,KAAMsH,CAAAA,UAC1B,CAEI,MADmB5M,QAAQqH,CAAAA,OAARwF,CAAgBnB,iBAAhBmB;AAAmCF,KAAnCE,CAHgD,CAAhD,CAO3BP,qBAAA,CAAuBtM,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAACpG,KAAD,CAAQ,CAAE,MAAOA,MAAMS,CAAAA,SAAf,CAAhD,CACvBwG,oBAAA,CAAsBvM,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAACpG,KAAD,CAAQ,CAClE,MAAOtF,QAAQa,CAAAA,GAAR,CAAYyE,KAAZ,CAAmB,UAAnB,CAD2D,CAAhD,CA1BS,CAAnC,CA8BA,KAAIwH,6BACJzB,OAAA,CAAO,0BAAP,CAAmC,QAAS,EAAG,CAC3C,IAAIvD,wBAA0BS,YAAA,CAAauC,OAAQM,CAAAA,wBAArB,CAC9B0B,8BAAA,CAAgC9M,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAAC1F,OAAD,CAAU,CAAE,MAAO,CAAA,CAAT,CAAlD,CACC,aAAjC,GAAI8E,OAAQK,CAAAA,gBAAZ,GACI2B,6BADJ;AACoC9M,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+B,QAAS,CAAC1F,OAAD,CAAU,CAC9E,GAAIhG,OAAQa,CAAAA,GAAR,CAAYmF,OAAZ,CAAqB,aAArB,CAAJ,CACI,MAAOA,QAAQ+G,CAAAA,WAGf,IAAgE,CAAA,CAAhE,GAAIlF,qBAAA,CAAsB7B,OAAtB,CAA+B8B,uBAA/B,CAAJ,CACI,MAAOC,UAAUC,CAAAA,gBAAV,CAA2BF,uBAA3B,CAAoD9B,OAAQlF,CAAAA,OAA5D,CAN+D,CAAlD,CADpC,CAH2C,CAA/C,CAgBA,KAAIkM,oBAAJ,CACIC,iBADJ,CAEIC,WAFJ,CAGIC,kBACJ9B,OAAA,CAAO,iBAAP,CAA0B,QAAS,EAAG,CAClC2B,oBAAA,CAAuBhN,OAAQe,CAAAA,GAAR,CAAY2K,iBAAZ,CAA+BhE,eAA/B,CACvBuF,kBAAA,CAAoBjN,OAAQe,CAAAA,GAAR,CAAY8K,sBAAZ,CAAoClE,cAApC,CACpBuF;WAAA,CAAclN,OAAQoE,CAAAA,MAAR,CAAesH,iBAAf,CAAkC,QAAS,CAAC0B,GAAD,CAAM9H,KAAN,CAAa,CAC9DmH,KAAAA,CAAYnH,KAAME,CAAAA,KAClBxF,QAAQ4B,CAAAA,QAAR,CAAiB6K,KAAjB,CAAJ,EAAqCA,KAArC,GAAmDtL,cAAeqD,CAAAA,KAAMiB,CAAAA,OAAxE,GACI2H,GAAA,CAAIX,KAAJ,CADJ,CACqB,EADrB,CAGA,OAAOW,IAL2D,CAAxD,CAMX,EANW,CAOdD,mBAAA,CAAqBnN,OAAQe,CAAAA,GAAR,CAAY8K,sBAAZ,CAAoC,QAAS,CAACwB,CAAD,CAAIjH,GAAJ,CAAS,CACvE,MAAO,CACH1E,QAASmK,sBAAA,CAAuBzF,GAAvB,CADN,CAEHkH,UAAWjB,wBAAA,CAAyBjG,GAAzB,CAFR,CAGHmH,kBAAmBT,6BAAA,CAA8B1G,GAA9B,CAHhB,CAIHoH,SAAUR,oBAAA,CAAqB5G,GAArB,CAJP,CAKHqH,MAAOR,iBAAA,CAAkB7G,GAAlB,CALJ,CAMHb,MAAO6G,iBAAA,CAAkBhG,GAAlB,CANJ,CAOH1B,KAAM4H,oBAAA,CAAqBlG,GAArB,CAPH;AAQHsH,IAAKnB,mBAAA,CAAoBnG,GAApB,CARF,CASHoG,aAAcL,gBAAA,CAAiB/F,GAAjB,CATX,CAUHE,UAAWoF,iBAAA,CAAkBtF,GAAlB,CAVR,CADgE,CAAtD,CAVa,CAAtC,CAyBA,KAAIuH,eAAiB,CAAA,CAArB,CACIC,6BAA+B,EAC9B9C,QAAQI,CAAAA,QAAb,EACIG,MAAA,CAAO,yBAAP,CAAkC,QAAS,EAAG,CAC1CuC,4BAAA,CAA+B5N,OAAQoE,CAAAA,MAAR,CAAesH,iBAAf,CAAkC,QAAS,CAACrH,MAAD,CAASnE,WAAT,CAAsBkG,GAAtB,CAA2B,CACjG,GAAmC,QAAnC,GAAI,MAAOlG,YAAYY,CAAAA,OAAvB,CACQiI,WAEJ,CAFe7I,WAAYY,CAAAA,OAAQ8G,CAAAA,UAApB,CAA+B,CAA/B,CAEf,CADIiG,WACJ,CADmB/E,wBAAA,CAAyBC,WAAzB,CACnB,CAAAJ,gBAAA,CAAiBtE,MAAjB,CAAyBwJ,WAAzB,CAAuCV,kBAAA,CAAmB/G,GAAnB,CAAvC,CAHJ;IAKK,IAAIpG,OAAQ8N,CAAAA,OAAR,CAAgB5N,WAAY6N,CAAAA,gBAA5B,CAAJ,CAAmD,CACpD,IAAIC,kBACJhO,QAAQwG,CAAAA,OAAR,CAAgBtG,WAAY6N,CAAAA,gBAA5B,CAA8C,QAAS,CAACE,SAAD,CAAY,CAC3DlF,SAAAA,CAAgC,QAArB,GAAA,MAAOkF,UAAP,CACTA,SAAUrG,CAAAA,UAAV,CAAqB,CAArB,CADS,CAETqG,SACFC,UAAAA,CAAmBpF,wBAAA,CAAyBC,SAAzB,CAKnBiF,mBAAJ,GAA2BE,SAA3B,GACIF,kBACA,CADqBE,SACrB,CAAAvF,gBAAA,CAAiBtE,MAAjB,CAAyB6J,SAAzB,CAA2Cf,kBAAA,CAAmB/G,GAAnB,CAA3C,CAFJ,CAT+D,CAAnE,CAFoD,CAAnD,IAiBIpG,QAAQG,CAAAA,QAAR,CAAiBD,WAAYY,CAAAA,OAA7B,CAAJ,CACGZ,WAAYY,CAAAA,OAAQqN,CAAAA,OAAxB,EACIR,cACA,CADiB,CAAA,CACjB,CAAI7C,OAAQsD,CAAAA,mBAAZ;AACIpO,OAAQqO,CAAAA,WAAR,CAAoB,EAApB,CAAyBtG,SAAUuG,CAAAA,2BAAnC,EACK,2BADL,CACgCpO,WAAYY,CAAAA,OAAQyN,CAAAA,QAApB,EADhC,CACiE,iQADjE,EAHR,GAWQC,WAUJ,CAVqBzG,SAAU0G,CAAAA,6BAAV,CAAwCvO,WAAYY,CAAAA,OAApD,CAA6DgK,OAAQsD,CAAAA,mBAArE,CAUrB,CANIpO,OAAQwL,CAAAA,OAAR,CAAgBgD,WAAhB,CAMJ;CAFIb,cAEJ,CAFqB,CAAA,CAErB,EAAA3N,OAAQwG,CAAAA,OAAR,CAAgBgI,WAAhB,CAAgC,QAAS,CAACE,IAAD,CAAO,CAC5C/F,gBAAA,CAAiBtE,MAAjB,CAAyBqK,IAAzB,CAA+BvB,kBAAA,CAAmB/G,GAAnB,CAA/B,CAD4C,CAAhD,CArBJ,CADC,EA4BG0E,OAAQsD,CAAAA,mBAMZ,EALIpO,OAAQqO,CAAAA,WAAR,CAAoB,EAApB,CAAyBtG,SAAUuG,CAAAA,2BAAnC,EACK,mBADL,CACwBpO,WAAYe,CAAAA,IADpC,CAC2C,wPAD3C,EAKJ,CAAA0M,cAAA;AAAiB,CAAA,CAlChB,CAoCL,OAAOtJ,OA3D0F,CAAtE,CA4D5B,EA5D4B,CADW,CAA9C,CAgEJgH,OAAA,CAAO,cAAP,CAAuB,QAAS,EAAG,CAC/BuC,4BAAA,CAA+B5N,OAAQ2O,CAAAA,SAAR,CAAkBf,4BAAlB,CADA,CAAnC,CAGA,OAAO,CACUV,WADV,CAEiBC,kBAFjB,CAG2BS,4BAH3B,CAIQhC,SAJR,CAKa+B,cALb,CAtPqC,CA4QhDhO,QAAQ2K,CAAAA,gBAAR,CAbAA,QAAyB,CAACzK,UAAD,CAAa+O,eAAb,CAA8B,CACnD,IAAI9O,OAAS,EACT+O,WAAAA,CAAgBnO,mBAAA,CAAoBb,UAApB,CACpBC,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcyO,UAAc/O,CAAAA,MAA5B,CACLgP,WAAAA,CAAgBtN,mBAAA,CAAoBqN,UAAcvN,CAAAA,KAAlC,CACpB,KAAIyN,gBAAkBD,UAAcxN,CAAAA,KACpCxB,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAc0O,UAAchP,CAAAA,MAA5B,CACTA;MAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcR,qBAAA,CAAsBmP,eAAtB,CAAd,CACTjP,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcgF,oBAAA,CAAqB2J,eAArB,CAAd,CACTjP,OAAA,CAASA,MAAOM,CAAAA,MAAP,CAAcuF,uBAAA,CAAwBoJ,eAAxB,CAAyCH,eAAzC,CAAd,CAET,OADA9O,OACA,CADSA,MAAOM,CAAAA,MAAP,CAAc8F,uBAAA,CAAwB6I,eAAxB,CAAd,CAV0C,CA0CvDpP,QAAQe,CAAAA,mBAAR,CAA8BA,mBAsB9Bf,QAAQ6B,CAAAA,mBAAR,CAA8BA,mBAC9B,KAAI0B,aAAe,WA0CnBvD,QAAQU,CAAAA,oBAAR,CAA+BA,oBAiB/BV,QAAQc,CAAAA,qBAAR,CAAgCA,qBAChC,KAAImD;AAAiB,gBA0CrBjE,QAAQW,CAAAA,sBAAR,CAAiCA,sBAiBjCX,QAAQY,CAAAA,oBAAR,CAA+BA,oBAoC/BZ,QAAQa,CAAAA,qBAAR,CAAgCA,qBAoBhCb,QAAQyF,CAAAA,oBAAR,CAA+BA,oBAgB/BzF,QAAQgG,CAAAA,uBAAR,CAAkCA,uBAoClChG,QAAQuG,CAAAA,uBAAR,CAAkCA,uBA+ClCvG,QAAQ2H,CAAAA,eAAR,CAA0BA,eAO1B3H,QAAQ8H,CAAAA,aAAR,CAAwBA,aA4CxB9H,QAAQ0K,CAAAA,oBAAR,CA3CAA,QAA6B,CAAC2E,eAAD,CAAkBC,UAAlB,CAA8B7D,wBAA9B,CAAwD,CACjF,IAAItL;AAAS,EAERE,QAAQa,CAAAA,GAAR,CAAYmO,eAAZ,CAA6BrP,OAAQiL,CAAAA,YAArC,CAAL,EACI9K,MAAO4E,CAAAA,IAAP,CAAY,CACR1D,QAAS,wDAATA,CACIrB,OAAQiL,CAAAA,YADZ5J,CAEI,mCAHI,CAIRE,KAAMC,cAAeC,CAAAA,wBAAyB8N,CAAAA,qCAJtC,CAAZ,CAOClP,QAAQa,CAAAA,GAAR,CAAYmO,eAAZ,CAA6BrP,OAAQgL,CAAAA,KAArC,CAAL,EACI7K,MAAO4E,CAAAA,IAAP,CAAY,CACR1D,QAAS,wDAATA,CACIrB,OAAQgL,CAAAA,KADZ3J,CAEI,mCAHI,CAIRE,KAAMC,cAAeC,CAAAA,wBAAyB+N,CAAAA,uCAJtC,CAAZ,CAOAnP;OAAQa,CAAAA,GAAR,CAAYmO,eAAZ,CAA6BrP,OAAQgL,CAAAA,KAArC,CAAJ,EACI3K,OAAQa,CAAAA,GAAR,CAAYmO,eAAZ,CAA6BrP,OAAQiL,CAAAA,YAArC,CADJ,EAEI,CAAC5K,OAAQa,CAAAA,GAAR,CAAYmO,eAAgBI,CAAAA,KAA5B,CAAmCJ,eAAgBK,CAAAA,WAAnD,CAFL,EAGIvP,MAAO4E,CAAAA,IAAP,CAAY,CACR1D,QAAS,iDAATA,CAA6DrB,OAAQiL,CAAAA,YAArE5J,CAAoF,QAApFA,CAA4FgO,eAAgBK,CAAAA,WAA5GrO,CAA0H,4BADlH,CAGRE,KAAMC,cAAeC,CAAAA,wBAAyBkO,CAAAA,kDAHtC,CAAZ,CAMAtP,QAAQa,CAAAA,GAAR,CAAYmO,eAAZ,CAA6BrP,OAAQgL,CAAAA,KAArC,CAAJ,EACI3K,OAAQwG,CAAAA,OAAR,CAAgBwI,eAAgBI,CAAAA,KAAhC,CAAuC,QAAS,CAACG,aAAD;AAAgBC,YAAhB,CAA8B,CAC1ExP,OAAQwG,CAAAA,OAAR,CAAgB+I,aAAhB,CAA+B,QAAS,CAACrP,WAAD,CAAcuP,OAAd,CAAuB,CACvDzP,OAAQ0M,CAAAA,WAAR,CAAoBxM,WAApB,CAAJ,EACIJ,MAAO4E,CAAAA,IAAP,CAAY,CACR1D,QAAS,wEAATA,EACWwO,YADXxO,CAC0B,qBAD1BA,CAC4CyO,OAD5CzO,CACsD,QADtDA,CADQ,CAGRE,KAAMC,cAAeC,CAAAA,wBAAyBsO,CAAAA,yCAHtC,CAAZ,CAFuD,CAA/D,CAD0E,CAA9E,CAYJ,OAAO5P,OAzC0E,CAyFrFH,QAAQyK,CAAAA,2BAAR,CA7CAA,QAAoC,CAAC4E,eAAD,CAAkBC,UAAlB,CAA8B7D,wBAA9B,CAAwD,CACxF,IAAIuE,SAAW,EAAf,CACIC,gBAAkB,CAAA,CAClBC,gBAAAA;AAAgB7P,OAAQ2E,CAAAA,OAAR,CAAgB3E,OAAQ8P,CAAAA,OAAR,CAAgB9P,OAAQ+P,CAAAA,SAAR,CAAkBf,eAAgBI,CAAAA,KAAlC,CAAyC,QAAS,CAACY,QAAD,CAAW,CAAE,MAAOA,SAAT,CAA7D,CAAhB,CAAhB,CAChBC,gBAAAA,CAAqBjQ,OAAQ2L,CAAAA,MAAR,CAAekE,eAAf,CAA8B,QAAS,CAACjP,QAAD,CAAW,CAAE,MAAOA,SAAA,CAAA,OAAP,GAA6BO,cAAeqD,CAAAA,KAAMC,CAAAA,EAApD,CAAlD,CACzB,KAAIyL,oBAAsB3H,YAAA,CAAa6C,wBAAb,CACtB6D,WAAJ,EACIjP,OAAQwG,CAAAA,OAAR,CAAgByJ,eAAhB,CAAoC,QAAS,CAACjK,OAAD,CAAU,CACnD,IAAImK,UAAYtI,qBAAA,CAAsB7B,OAAtB,CAA+BkK,mBAA/B,CACE,EAAA,CAAlB,GAAIC,SAAJ,EAEQC,OAKJ,CALwB,CACpBpP,QAFUqH,0BAAArH,CAA2BgF,OAA3BhF,CAAoCmP,SAApCnP,CACU,CAEpBE,KAAMiP,SAAUlI,CAAAA,KAFI;AAGpB3B,UAAWN,OAHS,CAKxB,CAAA2J,QAASjL,CAAAA,IAAT,CAAc0L,OAAd,CAPJ,EAWQpQ,OAAQa,CAAAA,GAAR,CAAYmF,OAAZ,CAAqB,aAArB,CAAJ,CACgC,CAAA,CADhC,GACQA,OAAQ+G,CAAAA,WADhB,GAEQ6C,eAFR,CAE0B,CAAA,CAF1B,EAMQ7H,SAAUC,CAAAA,gBAAV,CAA2BkI,mBAA3B,CAAgDlK,OAAQlF,CAAAA,OAAxD,CANR,GAOQ8O,eAPR,CAO0B,CAAA,CAP1B,CAb+C,CAAvD,CA0BAX,WAAJ,EAAkB,CAACW,eAAnB,EACID,QAASjL,CAAAA,IAAT,CAAc,CACV1D,QAAS,sRADC;AAMVE,KAAMC,cAAeC,CAAAA,wBAAyBiP,CAAAA,oBANpC,CAAd,CASJ,OAAOV,SA3CiF,CA6D5FhQ,QAAQwK,CAAAA,gBAAR,CAfAA,QAAyB,CAAC+C,WAAD,CAAc,CACnC,IAAIoD,aAAe,EAAnB,CACIC,UAAYvQ,OAAQwQ,CAAAA,IAAR,CAAatD,WAAb,CAChBlN,QAAQwG,CAAAA,OAAR,CAAgB+J,SAAhB,CAA2B,QAAS,CAACE,OAAD,CAAU,CAG1C,GAAIzQ,OAAQ8N,CAAAA,OAAR,CAFiBZ,WAAAwD,CAAYD,OAAZC,CAEjB,CAAJ,CACIJ,YAAA,CAAaG,OAAb,CAAA,CAAwB,EAD5B,KAII,MAAMzJ,MAAA,CAAM,sBAAN,CAAN,CAPsC,CAA9C,CAUA,OAAOsJ,aAb4B,CAsCvC3Q,QAAQ+H,CAAAA,eAAR,CAA0BA,eAS1B/H,QAAQgI,CAAAA,cAAR,CAAyBA,cAIzBhI,QAAQuK,CAAAA,6BAAR,CAAwC,CAEpC/G,KAAMA,QAAS,CAACwN,IAAD,CAAO,CAElB,IADA,IAAIC;AAAMD,IAAK7L,CAAAA,MAAf,CACS2G,EAAI,IAAKoF,CAAAA,SAAlB,CAA6BpF,CAA7B,CAAiCmF,GAAjC,CAAsCnF,CAAA,EAAtC,CAA2C,CACvC,IAAIqF,EAAIH,IAAK/I,CAAAA,UAAL,CAAgB6D,CAAhB,CACR,IAAU,EAAV,GAAIqF,CAAJ,CAEI,MADA,KAAKD,CAAAA,SACE,CADUpF,CACV,CADc,CACd,CAAA,CAAA,CAEN,IAAU,EAAV,GAAIqF,CAAJ,CAOD,MAN+B,GAA/B,GAAIH,IAAK/I,CAAAA,UAAL,CAAgB6D,CAAhB,CAAoB,CAApB,CAAJ,CACI,IAAKoF,CAAAA,SADT,CACqBpF,CADrB,CACyB,CADzB,CAII,IAAKoF,CAAAA,SAJT,CAIqBpF,CAJrB,CAIyB,CAElB,CAAA,CAAA,CAb4B,CAgB3C,MAAO,CAAA,CAlBW,CAFc,CAsBpCoF,UAAW,CAtByB,CA4ExClR,QAAQ0I,CAAAA,0BAAR,CAAqCA,0BAoBrC1I,QAAQqJ,CAAAA,kBAAR,CAA6B,GAgB7B,KAAIC,0BAA4B,EAMhCtJ,QAAQmJ,CAAAA,wBAAR,CAAmCA,wBAj4B2E;\",\n\"sources\":[\"node_modules/chevrotain/lib/src/scan/lexer.js\"],\n\"sourcesContent\":[\"shadow$provide[\\\"module$node_modules$chevrotain$lib$src$scan$lexer\\\"] = function(global,require,module,exports) {\\n\\\"use strict\\\";\\nvar __extends = (this && this.__extends) || (function () {\\n    var extendStatics = function (d, b) {\\n        extendStatics = Object.setPrototypeOf ||\\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\\n        return extendStatics(d, b);\\n    };\\n    return function (d, b) {\\n        if (typeof b !== \\\"function\\\" && b !== null)\\n            throw new TypeError(\\\"Class extends value \\\" + String(b) + \\\" is not a constructor or null\\\");\\n        extendStatics(d, b);\\n        function __() { this.constructor = d; }\\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\\n    };\\n})();\\nObject.defineProperty(exports, \\\"__esModule\\\", { value: true });\\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\\nvar regexp_to_ast_1 = require(\\\"regexp-to-ast\\\");\\nvar lexer_public_1 = require(\\\"./lexer_public\\\");\\nvar utils_1 = require(\\\"@chevrotain/utils\\\");\\nvar reg_exp_1 = require(\\\"./reg_exp\\\");\\nvar reg_exp_parser_1 = require(\\\"./reg_exp_parser\\\");\\nvar PATTERN = \\\"PATTERN\\\";\\nexports.DEFAULT_MODE = \\\"defaultMode\\\";\\nexports.MODES = \\\"modes\\\";\\nexports.SUPPORT_STICKY = typeof new RegExp(\\\"(?:)\\\").sticky === \\\"boolean\\\";\\nfunction disableSticky() {\\n    exports.SUPPORT_STICKY = false;\\n}\\nexports.disableSticky = disableSticky;\\nfunction enableSticky() {\\n    exports.SUPPORT_STICKY = true;\\n}\\nexports.enableSticky = enableSticky;\\nfunction analyzeTokenTypes(tokenTypes, options) {\\n    options = utils_1.defaults(options, {\\n        useSticky: exports.SUPPORT_STICKY,\\n        debug: false,\\n        safeMode: false,\\n        positionTracking: \\\"full\\\",\\n        lineTerminatorCharacters: [\\\"\\\\r\\\", \\\"\\\\n\\\"],\\n        tracer: function (msg, action) { return action(); }\\n    });\\n    var tracer = options.tracer;\\n    tracer(\\\"initCharCodeToOptimizedIndexMap\\\", function () {\\n        initCharCodeToOptimizedIndexMap();\\n    });\\n    var onlyRelevantTypes;\\n    tracer(\\\"Reject Lexer.NA\\\", function () {\\n        onlyRelevantTypes = utils_1.reject(tokenTypes, function (currType) {\\n            return currType[PATTERN] === lexer_public_1.Lexer.NA;\\n        });\\n    });\\n    var hasCustom = false;\\n    var allTransformedPatterns;\\n    tracer(\\\"Transform Patterns\\\", function () {\\n        hasCustom = false;\\n        allTransformedPatterns = utils_1.map(onlyRelevantTypes, function (currType) {\\n            var currPattern = currType[PATTERN];\\n            /* istanbul ignore else */\\n            if (utils_1.isRegExp(currPattern)) {\\n                var regExpSource = currPattern.source;\\n                if (regExpSource.length === 1 &&\\n                    // only these regExp meta characters which can appear in a length one regExp\\n                    regExpSource !== \\\"^\\\" &&\\n                    regExpSource !== \\\"$\\\" &&\\n                    regExpSource !== \\\".\\\" &&\\n                    !currPattern.ignoreCase) {\\n                    return regExpSource;\\n                }\\n                else if (regExpSource.length === 2 &&\\n                    regExpSource[0] === \\\"\\\\\\\\\\\" &&\\n                    // not a meta character\\n                    !utils_1.contains([\\n                        \\\"d\\\",\\n                        \\\"D\\\",\\n                        \\\"s\\\",\\n                        \\\"S\\\",\\n                        \\\"t\\\",\\n                        \\\"r\\\",\\n                        \\\"n\\\",\\n                        \\\"t\\\",\\n                        \\\"0\\\",\\n                        \\\"c\\\",\\n                        \\\"b\\\",\\n                        \\\"B\\\",\\n                        \\\"f\\\",\\n                        \\\"v\\\",\\n                        \\\"w\\\",\\n                        \\\"W\\\"\\n                    ], regExpSource[1])) {\\n                    // escaped meta Characters: /\\\\+/ /\\\\[/\\n                    // or redundant escaping: /\\\\a/\\n                    // without the escaping \\\"\\\\\\\"\\n                    return regExpSource[1];\\n                }\\n                else {\\n                    return options.useSticky\\n                        ? addStickyFlag(currPattern)\\n                        : addStartOfInput(currPattern);\\n                }\\n            }\\n            else if (utils_1.isFunction(currPattern)) {\\n                hasCustom = true;\\n                // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\\n                return { exec: currPattern };\\n            }\\n            else if (utils_1.has(currPattern, \\\"exec\\\")) {\\n                hasCustom = true;\\n                // ICustomPattern\\n                return currPattern;\\n            }\\n            else if (typeof currPattern === \\\"string\\\") {\\n                if (currPattern.length === 1) {\\n                    return currPattern;\\n                }\\n                else {\\n                    var escapedRegExpString = currPattern.replace(/[\\\\\\\\^$.*+?()[\\\\]{}|]/g, \\\"\\\\\\\\$&\\\");\\n                    var wrappedRegExp = new RegExp(escapedRegExpString);\\n                    return options.useSticky\\n                        ? addStickyFlag(wrappedRegExp)\\n                        : addStartOfInput(wrappedRegExp);\\n                }\\n            }\\n            else {\\n                throw Error(\\\"non exhaustive match\\\");\\n            }\\n        });\\n    });\\n    var patternIdxToType;\\n    var patternIdxToGroup;\\n    var patternIdxToLongerAltIdx;\\n    var patternIdxToPushMode;\\n    var patternIdxToPopMode;\\n    tracer(\\\"misc mapping\\\", function () {\\n        patternIdxToType = utils_1.map(onlyRelevantTypes, function (currType) { return currType.tokenTypeIdx; });\\n        patternIdxToGroup = utils_1.map(onlyRelevantTypes, function (clazz) {\\n            var groupName = clazz.GROUP;\\n            /* istanbul ignore next */\\n            if (groupName === lexer_public_1.Lexer.SKIPPED) {\\n                return undefined;\\n            }\\n            else if (utils_1.isString(groupName)) {\\n                return groupName;\\n            }\\n            else if (utils_1.isUndefined(groupName)) {\\n                return false;\\n            }\\n            else {\\n                throw Error(\\\"non exhaustive match\\\");\\n            }\\n        });\\n        patternIdxToLongerAltIdx = utils_1.map(onlyRelevantTypes, function (clazz) {\\n            var longerAltType = clazz.LONGER_ALT;\\n            if (longerAltType) {\\n                var longerAltIdx = utils_1.indexOf(onlyRelevantTypes, longerAltType);\\n                return longerAltIdx;\\n            }\\n        });\\n        patternIdxToPushMode = utils_1.map(onlyRelevantTypes, function (clazz) { return clazz.PUSH_MODE; });\\n        patternIdxToPopMode = utils_1.map(onlyRelevantTypes, function (clazz) {\\n            return utils_1.has(clazz, \\\"POP_MODE\\\");\\n        });\\n    });\\n    var patternIdxToCanLineTerminator;\\n    tracer(\\\"Line Terminator Handling\\\", function () {\\n        var lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\\n        patternIdxToCanLineTerminator = utils_1.map(onlyRelevantTypes, function (tokType) { return false; });\\n        if (options.positionTracking !== \\\"onlyOffset\\\") {\\n            patternIdxToCanLineTerminator = utils_1.map(onlyRelevantTypes, function (tokType) {\\n                if (utils_1.has(tokType, \\\"LINE_BREAKS\\\")) {\\n                    return tokType.LINE_BREAKS;\\n                }\\n                else {\\n                    if (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false) {\\n                        return reg_exp_1.canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\\n                    }\\n                }\\n            });\\n        }\\n    });\\n    var patternIdxToIsCustom;\\n    var patternIdxToShort;\\n    var emptyGroups;\\n    var patternIdxToConfig;\\n    tracer(\\\"Misc Mapping #2\\\", function () {\\n        patternIdxToIsCustom = utils_1.map(onlyRelevantTypes, isCustomPattern);\\n        patternIdxToShort = utils_1.map(allTransformedPatterns, isShortPattern);\\n        emptyGroups = utils_1.reduce(onlyRelevantTypes, function (acc, clazz) {\\n            var groupName = clazz.GROUP;\\n            if (utils_1.isString(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\\n                acc[groupName] = [];\\n            }\\n            return acc;\\n        }, {});\\n        patternIdxToConfig = utils_1.map(allTransformedPatterns, function (x, idx) {\\n            return {\\n                pattern: allTransformedPatterns[idx],\\n                longerAlt: patternIdxToLongerAltIdx[idx],\\n                canLineTerminator: patternIdxToCanLineTerminator[idx],\\n                isCustom: patternIdxToIsCustom[idx],\\n                short: patternIdxToShort[idx],\\n                group: patternIdxToGroup[idx],\\n                push: patternIdxToPushMode[idx],\\n                pop: patternIdxToPopMode[idx],\\n                tokenTypeIdx: patternIdxToType[idx],\\n                tokenType: onlyRelevantTypes[idx]\\n            };\\n        });\\n    });\\n    var canBeOptimized = true;\\n    var charCodeToPatternIdxToConfig = [];\\n    if (!options.safeMode) {\\n        tracer(\\\"First Char Optimization\\\", function () {\\n            charCodeToPatternIdxToConfig = utils_1.reduce(onlyRelevantTypes, function (result, currTokType, idx) {\\n                if (typeof currTokType.PATTERN === \\\"string\\\") {\\n                    var charCode = currTokType.PATTERN.charCodeAt(0);\\n                    var optimizedIdx = charCodeToOptimizedIndex(charCode);\\n                    addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\\n                }\\n                else if (utils_1.isArray(currTokType.START_CHARS_HINT)) {\\n                    var lastOptimizedIdx_1;\\n                    utils_1.forEach(currTokType.START_CHARS_HINT, function (charOrInt) {\\n                        var charCode = typeof charOrInt === \\\"string\\\"\\n                            ? charOrInt.charCodeAt(0)\\n                            : charOrInt;\\n                        var currOptimizedIdx = charCodeToOptimizedIndex(charCode);\\n                        // Avoid adding the config multiple times\\n                        /* istanbul ignore else */\\n                        // - Difficult to check this scenario effects as it is only a performance\\n                        //   optimization that does not change correctness\\n                        if (lastOptimizedIdx_1 !== currOptimizedIdx) {\\n                            lastOptimizedIdx_1 = currOptimizedIdx;\\n                            addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\\n                        }\\n                    });\\n                }\\n                else if (utils_1.isRegExp(currTokType.PATTERN)) {\\n                    if (currTokType.PATTERN.unicode) {\\n                        canBeOptimized = false;\\n                        if (options.ensureOptimizations) {\\n                            utils_1.PRINT_ERROR(\\\"\\\" + reg_exp_1.failedOptimizationPrefixMsg +\\n                                (\\\"\\\\tUnable to analyze < \\\" + currTokType.PATTERN.toString() + \\\" > pattern.\\\\n\\\") +\\n                                \\\"\\\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\\\n\\\" +\\n                                \\\"\\\\tThis will disable the lexer's first char optimizations.\\\\n\\\" +\\n                                \\\"\\\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\\\");\\n                        }\\n                    }\\n                    else {\\n                        var optimizedCodes = reg_exp_1.getOptimizedStartCodesIndices(currTokType.PATTERN, options.ensureOptimizations);\\n                        /* istanbul ignore if */\\n                        // start code will only be empty given an empty regExp or failure of regexp-to-ast library\\n                        // the first should be a different validation and the second cannot be tested.\\n                        if (utils_1.isEmpty(optimizedCodes)) {\\n                            // we cannot understand what codes may start possible matches\\n                            // The optimization correctness requires knowing start codes for ALL patterns.\\n                            // Not actually sure this is an error, no debug message\\n                            canBeOptimized = false;\\n                        }\\n                        utils_1.forEach(optimizedCodes, function (code) {\\n                            addToMapOfArrays(result, code, patternIdxToConfig[idx]);\\n                        });\\n                    }\\n                }\\n                else {\\n                    if (options.ensureOptimizations) {\\n                        utils_1.PRINT_ERROR(\\\"\\\" + reg_exp_1.failedOptimizationPrefixMsg +\\n                            (\\\"\\\\tTokenType: <\\\" + currTokType.name + \\\"> is using a custom token pattern without providing <start_chars_hint> parameter.\\\\n\\\") +\\n                            \\\"\\\\tThis will disable the lexer's first char optimizations.\\\\n\\\" +\\n                            \\\"\\\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\\\");\\n                    }\\n                    canBeOptimized = false;\\n                }\\n                return result;\\n            }, []);\\n        });\\n    }\\n    tracer(\\\"ArrayPacking\\\", function () {\\n        charCodeToPatternIdxToConfig = utils_1.packArray(charCodeToPatternIdxToConfig);\\n    });\\n    return {\\n        emptyGroups: emptyGroups,\\n        patternIdxToConfig: patternIdxToConfig,\\n        charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\\n        hasCustom: hasCustom,\\n        canBeOptimized: canBeOptimized\\n    };\\n}\\nexports.analyzeTokenTypes = analyzeTokenTypes;\\nfunction validatePatterns(tokenTypes, validModesNames) {\\n    var errors = [];\\n    var missingResult = findMissingPatterns(tokenTypes);\\n    errors = errors.concat(missingResult.errors);\\n    var invalidResult = findInvalidPatterns(missingResult.valid);\\n    var validTokenTypes = invalidResult.valid;\\n    errors = errors.concat(invalidResult.errors);\\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\\n    return errors;\\n}\\nexports.validatePatterns = validatePatterns;\\nfunction validateRegExpPattern(tokenTypes) {\\n    var errors = [];\\n    var withRegExpPatterns = utils_1.filter(tokenTypes, function (currTokType) {\\n        return utils_1.isRegExp(currTokType[PATTERN]);\\n    });\\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\\n    return errors;\\n}\\nfunction findMissingPatterns(tokenTypes) {\\n    var tokenTypesWithMissingPattern = utils_1.filter(tokenTypes, function (currType) {\\n        return !utils_1.has(currType, PATTERN);\\n    });\\n    var errors = utils_1.map(tokenTypesWithMissingPattern, function (currType) {\\n        return {\\n            message: \\\"Token Type: ->\\\" +\\n                currType.name +\\n                \\\"<- missing static 'PATTERN' property\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\\n            tokenTypes: [currType]\\n        };\\n    });\\n    var valid = utils_1.difference(tokenTypes, tokenTypesWithMissingPattern);\\n    return { errors: errors, valid: valid };\\n}\\nexports.findMissingPatterns = findMissingPatterns;\\nfunction findInvalidPatterns(tokenTypes) {\\n    var tokenTypesWithInvalidPattern = utils_1.filter(tokenTypes, function (currType) {\\n        var pattern = currType[PATTERN];\\n        return (!utils_1.isRegExp(pattern) &&\\n            !utils_1.isFunction(pattern) &&\\n            !utils_1.has(pattern, \\\"exec\\\") &&\\n            !utils_1.isString(pattern));\\n    });\\n    var errors = utils_1.map(tokenTypesWithInvalidPattern, function (currType) {\\n        return {\\n            message: \\\"Token Type: ->\\\" +\\n                currType.name +\\n                \\\"<- static 'PATTERN' can only be a RegExp, a\\\" +\\n                \\\" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\\n            tokenTypes: [currType]\\n        };\\n    });\\n    var valid = utils_1.difference(tokenTypes, tokenTypesWithInvalidPattern);\\n    return { errors: errors, valid: valid };\\n}\\nexports.findInvalidPatterns = findInvalidPatterns;\\nvar end_of_input = /[^\\\\\\\\][\\\\$]/;\\nfunction findEndOfInputAnchor(tokenTypes) {\\n    var EndAnchorFinder = /** @class */ (function (_super) {\\n        __extends(EndAnchorFinder, _super);\\n        function EndAnchorFinder() {\\n            var _this = _super !== null && _super.apply(this, arguments) || this;\\n            _this.found = false;\\n            return _this;\\n        }\\n        EndAnchorFinder.prototype.visitEndAnchor = function (node) {\\n            this.found = true;\\n        };\\n        return EndAnchorFinder;\\n    }(regexp_to_ast_1.BaseRegExpVisitor));\\n    var invalidRegex = utils_1.filter(tokenTypes, function (currType) {\\n        var pattern = currType[PATTERN];\\n        try {\\n            var regexpAst = reg_exp_parser_1.getRegExpAst(pattern);\\n            var endAnchorVisitor = new EndAnchorFinder();\\n            endAnchorVisitor.visit(regexpAst);\\n            return endAnchorVisitor.found;\\n        }\\n        catch (e) {\\n            // old behavior in case of runtime exceptions with regexp-to-ast.\\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\\n            return end_of_input.test(pattern.source);\\n        }\\n    });\\n    var errors = utils_1.map(invalidRegex, function (currType) {\\n        return {\\n            message: \\\"Unexpected RegExp Anchor Error:\\\\n\\\" +\\n                \\\"\\\\tToken Type: ->\\\" +\\n                currType.name +\\n                \\\"<- static 'PATTERN' cannot contain end of input anchor '$'\\\\n\\\" +\\n                \\\"\\\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\\\" +\\n                \\\"\\\\tfor details.\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\\n            tokenTypes: [currType]\\n        };\\n    });\\n    return errors;\\n}\\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\\nfunction findEmptyMatchRegExps(tokenTypes) {\\n    var matchesEmptyString = utils_1.filter(tokenTypes, function (currType) {\\n        var pattern = currType[PATTERN];\\n        return pattern.test(\\\"\\\");\\n    });\\n    var errors = utils_1.map(matchesEmptyString, function (currType) {\\n        return {\\n            message: \\\"Token Type: ->\\\" +\\n                currType.name +\\n                \\\"<- static 'PATTERN' must not match an empty string\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\\n            tokenTypes: [currType]\\n        };\\n    });\\n    return errors;\\n}\\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\\nvar start_of_input = /[^\\\\\\\\[][\\\\^]|^\\\\^/;\\nfunction findStartOfInputAnchor(tokenTypes) {\\n    var StartAnchorFinder = /** @class */ (function (_super) {\\n        __extends(StartAnchorFinder, _super);\\n        function StartAnchorFinder() {\\n            var _this = _super !== null && _super.apply(this, arguments) || this;\\n            _this.found = false;\\n            return _this;\\n        }\\n        StartAnchorFinder.prototype.visitStartAnchor = function (node) {\\n            this.found = true;\\n        };\\n        return StartAnchorFinder;\\n    }(regexp_to_ast_1.BaseRegExpVisitor));\\n    var invalidRegex = utils_1.filter(tokenTypes, function (currType) {\\n        var pattern = currType[PATTERN];\\n        try {\\n            var regexpAst = reg_exp_parser_1.getRegExpAst(pattern);\\n            var startAnchorVisitor = new StartAnchorFinder();\\n            startAnchorVisitor.visit(regexpAst);\\n            return startAnchorVisitor.found;\\n        }\\n        catch (e) {\\n            // old behavior in case of runtime exceptions with regexp-to-ast.\\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\\n            return start_of_input.test(pattern.source);\\n        }\\n    });\\n    var errors = utils_1.map(invalidRegex, function (currType) {\\n        return {\\n            message: \\\"Unexpected RegExp Anchor Error:\\\\n\\\" +\\n                \\\"\\\\tToken Type: ->\\\" +\\n                currType.name +\\n                \\\"<- static 'PATTERN' cannot contain start of input anchor '^'\\\\n\\\" +\\n                \\\"\\\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\\\" +\\n                \\\"\\\\tfor details.\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\\n            tokenTypes: [currType]\\n        };\\n    });\\n    return errors;\\n}\\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\\nfunction findUnsupportedFlags(tokenTypes) {\\n    var invalidFlags = utils_1.filter(tokenTypes, function (currType) {\\n        var pattern = currType[PATTERN];\\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\\n    });\\n    var errors = utils_1.map(invalidFlags, function (currType) {\\n        return {\\n            message: \\\"Token Type: ->\\\" +\\n                currType.name +\\n                \\\"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\\n            tokenTypes: [currType]\\n        };\\n    });\\n    return errors;\\n}\\nexports.findUnsupportedFlags = findUnsupportedFlags;\\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\\nfunction findDuplicatePatterns(tokenTypes) {\\n    var found = [];\\n    var identicalPatterns = utils_1.map(tokenTypes, function (outerType) {\\n        return utils_1.reduce(tokenTypes, function (result, innerType) {\\n            if (outerType.PATTERN.source === innerType.PATTERN.source &&\\n                !utils_1.contains(found, innerType) &&\\n                innerType.PATTERN !== lexer_public_1.Lexer.NA) {\\n                // this avoids duplicates in the result, each Token Type may only appear in one \\\"set\\\"\\n                // in essence we are creating Equivalence classes on equality relation.\\n                found.push(innerType);\\n                result.push(innerType);\\n                return result;\\n            }\\n            return result;\\n        }, []);\\n    });\\n    identicalPatterns = utils_1.compact(identicalPatterns);\\n    var duplicatePatterns = utils_1.filter(identicalPatterns, function (currIdenticalSet) {\\n        return currIdenticalSet.length > 1;\\n    });\\n    var errors = utils_1.map(duplicatePatterns, function (setOfIdentical) {\\n        var tokenTypeNames = utils_1.map(setOfIdentical, function (currType) {\\n            return currType.name;\\n        });\\n        var dupPatternSrc = utils_1.first(setOfIdentical).PATTERN;\\n        return {\\n            message: \\\"The same RegExp pattern ->\\\" + dupPatternSrc + \\\"<-\\\" +\\n                (\\\"has been used in all of the following Token Types: \\\" + tokenTypeNames.join(\\\", \\\") + \\\" <-\\\"),\\n            type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\\n            tokenTypes: setOfIdentical\\n        };\\n    });\\n    return errors;\\n}\\nexports.findDuplicatePatterns = findDuplicatePatterns;\\nfunction findInvalidGroupType(tokenTypes) {\\n    var invalidTypes = utils_1.filter(tokenTypes, function (clazz) {\\n        if (!utils_1.has(clazz, \\\"GROUP\\\")) {\\n            return false;\\n        }\\n        var group = clazz.GROUP;\\n        return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !utils_1.isString(group);\\n    });\\n    var errors = utils_1.map(invalidTypes, function (currType) {\\n        return {\\n            message: \\\"Token Type: ->\\\" +\\n                currType.name +\\n                \\\"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\\n            tokenTypes: [currType]\\n        };\\n    });\\n    return errors;\\n}\\nexports.findInvalidGroupType = findInvalidGroupType;\\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\\n    var invalidModes = utils_1.filter(tokenTypes, function (clazz) {\\n        return (clazz.PUSH_MODE !== undefined && !utils_1.contains(validModes, clazz.PUSH_MODE));\\n    });\\n    var errors = utils_1.map(invalidModes, function (tokType) {\\n        var msg = \\\"Token Type: ->\\\" + tokType.name + \\\"<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->\\\" + tokType.PUSH_MODE + \\\"<-\\\" +\\n            \\\"which does not exist\\\";\\n        return {\\n            message: msg,\\n            type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\\n            tokenTypes: [tokType]\\n        };\\n    });\\n    return errors;\\n}\\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\\nfunction findUnreachablePatterns(tokenTypes) {\\n    var errors = [];\\n    var canBeTested = utils_1.reduce(tokenTypes, function (result, tokType, idx) {\\n        var pattern = tokType.PATTERN;\\n        if (pattern === lexer_public_1.Lexer.NA) {\\n            return result;\\n        }\\n        // a more comprehensive validation for all forms of regExps would require\\n        // deeper regExp analysis capabilities\\n        if (utils_1.isString(pattern)) {\\n            result.push({ str: pattern, idx: idx, tokenType: tokType });\\n        }\\n        else if (utils_1.isRegExp(pattern) && noMetaChar(pattern)) {\\n            result.push({ str: pattern.source, idx: idx, tokenType: tokType });\\n        }\\n        return result;\\n    }, []);\\n    utils_1.forEach(tokenTypes, function (tokType, testIdx) {\\n        utils_1.forEach(canBeTested, function (_a) {\\n            var str = _a.str, idx = _a.idx, tokenType = _a.tokenType;\\n            if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\\n                var msg = \\\"Token: ->\\\" + tokenType.name + \\\"<- can never be matched.\\\\n\\\" +\\n                    (\\\"Because it appears AFTER the Token Type ->\\\" + tokType.name + \\\"<-\\\") +\\n                    \\\"in the lexer's definition.\\\\n\\\" +\\n                    \\\"See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE\\\";\\n                errors.push({\\n                    message: msg,\\n                    type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\\n                    tokenTypes: [tokType, tokenType]\\n                });\\n            }\\n        });\\n    });\\n    return errors;\\n}\\nexports.findUnreachablePatterns = findUnreachablePatterns;\\nfunction testTokenType(str, pattern) {\\n    /* istanbul ignore else */\\n    if (utils_1.isRegExp(pattern)) {\\n        var regExpArray = pattern.exec(str);\\n        return regExpArray !== null && regExpArray.index === 0;\\n    }\\n    else if (utils_1.isFunction(pattern)) {\\n        // maintain the API of custom patterns\\n        return pattern(str, 0, [], {});\\n    }\\n    else if (utils_1.has(pattern, \\\"exec\\\")) {\\n        // maintain the API of custom patterns\\n        return pattern.exec(str, 0, [], {});\\n    }\\n    else if (typeof pattern === \\\"string\\\") {\\n        return pattern === str;\\n    }\\n    else {\\n        throw Error(\\\"non exhaustive match\\\");\\n    }\\n}\\nfunction noMetaChar(regExp) {\\n    //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\\n    var metaChars = [\\n        \\\".\\\",\\n        \\\"\\\\\\\\\\\",\\n        \\\"[\\\",\\n        \\\"]\\\",\\n        \\\"|\\\",\\n        \\\"^\\\",\\n        \\\"$\\\",\\n        \\\"(\\\",\\n        \\\")\\\",\\n        \\\"?\\\",\\n        \\\"*\\\",\\n        \\\"+\\\",\\n        \\\"{\\\"\\n    ];\\n    return (utils_1.find(metaChars, function (char) { return regExp.source.indexOf(char) !== -1; }) === undefined);\\n}\\nfunction addStartOfInput(pattern) {\\n    var flags = pattern.ignoreCase ? \\\"i\\\" : \\\"\\\";\\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\\n    return new RegExp(\\\"^(?:\\\" + pattern.source + \\\")\\\", flags);\\n}\\nexports.addStartOfInput = addStartOfInput;\\nfunction addStickyFlag(pattern) {\\n    var flags = pattern.ignoreCase ? \\\"iy\\\" : \\\"y\\\";\\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\\n    return new RegExp(\\\"\\\" + pattern.source, flags);\\n}\\nexports.addStickyFlag = addStickyFlag;\\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\\n    var errors = [];\\n    // some run time checks to help the end users.\\n    if (!utils_1.has(lexerDefinition, exports.DEFAULT_MODE)) {\\n        errors.push({\\n            message: \\\"A MultiMode Lexer cannot be initialized without a <\\\" +\\n                exports.DEFAULT_MODE +\\n                \\\"> property in its definition\\\\n\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\\n        });\\n    }\\n    if (!utils_1.has(lexerDefinition, exports.MODES)) {\\n        errors.push({\\n            message: \\\"A MultiMode Lexer cannot be initialized without a <\\\" +\\n                exports.MODES +\\n                \\\"> property in its definition\\\\n\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\\n        });\\n    }\\n    if (utils_1.has(lexerDefinition, exports.MODES) &&\\n        utils_1.has(lexerDefinition, exports.DEFAULT_MODE) &&\\n        !utils_1.has(lexerDefinition.modes, lexerDefinition.defaultMode)) {\\n        errors.push({\\n            message: \\\"A MultiMode Lexer cannot be initialized with a \\\" + exports.DEFAULT_MODE + \\\": <\\\" + lexerDefinition.defaultMode + \\\">\\\" +\\n                \\\"which does not exist\\\\n\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\\n        });\\n    }\\n    if (utils_1.has(lexerDefinition, exports.MODES)) {\\n        utils_1.forEach(lexerDefinition.modes, function (currModeValue, currModeName) {\\n            utils_1.forEach(currModeValue, function (currTokType, currIdx) {\\n                if (utils_1.isUndefined(currTokType)) {\\n                    errors.push({\\n                        message: \\\"A Lexer cannot be initialized using an undefined Token Type. Mode:\\\" +\\n                            (\\\"<\\\" + currModeName + \\\"> at index: <\\\" + currIdx + \\\">\\\\n\\\"),\\n                        type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\\n                    });\\n                }\\n            });\\n        });\\n    }\\n    return errors;\\n}\\nexports.performRuntimeChecks = performRuntimeChecks;\\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\\n    var warnings = [];\\n    var hasAnyLineBreak = false;\\n    var allTokenTypes = utils_1.compact(utils_1.flatten(utils_1.mapValues(lexerDefinition.modes, function (tokTypes) { return tokTypes; })));\\n    var concreteTokenTypes = utils_1.reject(allTokenTypes, function (currType) { return currType[PATTERN] === lexer_public_1.Lexer.NA; });\\n    var terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\\n    if (trackLines) {\\n        utils_1.forEach(concreteTokenTypes, function (tokType) {\\n            var currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\\n            if (currIssue !== false) {\\n                var message = buildLineBreakIssueMessage(tokType, currIssue);\\n                var warningDescriptor = {\\n                    message: message,\\n                    type: currIssue.issue,\\n                    tokenType: tokType\\n                };\\n                warnings.push(warningDescriptor);\\n            }\\n            else {\\n                // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\\n                if (utils_1.has(tokType, \\\"LINE_BREAKS\\\")) {\\n                    if (tokType.LINE_BREAKS === true) {\\n                        hasAnyLineBreak = true;\\n                    }\\n                }\\n                else {\\n                    if (reg_exp_1.canMatchCharCode(terminatorCharCodes, tokType.PATTERN)) {\\n                        hasAnyLineBreak = true;\\n                    }\\n                }\\n            }\\n        });\\n    }\\n    if (trackLines && !hasAnyLineBreak) {\\n        warnings.push({\\n            message: \\\"Warning: No LINE_BREAKS Found.\\\\n\\\" +\\n                \\\"\\\\tThis Lexer has been defined to track line and column information,\\\\n\\\" +\\n                \\\"\\\\tBut none of the Token Types can be identified as matching a line terminator.\\\\n\\\" +\\n                \\\"\\\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\\\n\\\" +\\n                \\\"\\\\tfor details.\\\",\\n            type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\\n        });\\n    }\\n    return warnings;\\n}\\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\\nfunction cloneEmptyGroups(emptyGroups) {\\n    var clonedResult = {};\\n    var groupKeys = utils_1.keys(emptyGroups);\\n    utils_1.forEach(groupKeys, function (currKey) {\\n        var currGroupValue = emptyGroups[currKey];\\n        /* istanbul ignore else */\\n        if (utils_1.isArray(currGroupValue)) {\\n            clonedResult[currKey] = [];\\n        }\\n        else {\\n            throw Error(\\\"non exhaustive match\\\");\\n        }\\n    });\\n    return clonedResult;\\n}\\nexports.cloneEmptyGroups = cloneEmptyGroups;\\n// TODO: refactor to avoid duplication\\nfunction isCustomPattern(tokenType) {\\n    var pattern = tokenType.PATTERN;\\n    /* istanbul ignore else */\\n    if (utils_1.isRegExp(pattern)) {\\n        return false;\\n    }\\n    else if (utils_1.isFunction(pattern)) {\\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\\n        return true;\\n    }\\n    else if (utils_1.has(pattern, \\\"exec\\\")) {\\n        // ICustomPattern\\n        return true;\\n    }\\n    else if (utils_1.isString(pattern)) {\\n        return false;\\n    }\\n    else {\\n        throw Error(\\\"non exhaustive match\\\");\\n    }\\n}\\nexports.isCustomPattern = isCustomPattern;\\nfunction isShortPattern(pattern) {\\n    if (utils_1.isString(pattern) && pattern.length === 1) {\\n        return pattern.charCodeAt(0);\\n    }\\n    else {\\n        return false;\\n    }\\n}\\nexports.isShortPattern = isShortPattern;\\n/**\\n * Faster than using a RegExp for default newline detection during lexing.\\n */\\nexports.LineTerminatorOptimizedTester = {\\n    // implements /\\\\n|\\\\r\\\\n?/g.test\\n    test: function (text) {\\n        var len = text.length;\\n        for (var i = this.lastIndex; i < len; i++) {\\n            var c = text.charCodeAt(i);\\n            if (c === 10) {\\n                this.lastIndex = i + 1;\\n                return true;\\n            }\\n            else if (c === 13) {\\n                if (text.charCodeAt(i + 1) === 10) {\\n                    this.lastIndex = i + 2;\\n                }\\n                else {\\n                    this.lastIndex = i + 1;\\n                }\\n                return true;\\n            }\\n        }\\n        return false;\\n    },\\n    lastIndex: 0\\n};\\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\\n    if (utils_1.has(tokType, \\\"LINE_BREAKS\\\")) {\\n        // if the user explicitly declared the line_breaks option we will respect their choice\\n        // and assume it is correct.\\n        return false;\\n    }\\n    else {\\n        /* istanbul ignore else */\\n        if (utils_1.isRegExp(tokType.PATTERN)) {\\n            try {\\n                // TODO: why is the casting suddenly needed?\\n                reg_exp_1.canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN);\\n            }\\n            catch (e) {\\n                /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\\n                return {\\n                    issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\\n                    errMsg: e.message\\n                };\\n            }\\n            return false;\\n        }\\n        else if (utils_1.isString(tokType.PATTERN)) {\\n            // string literal patterns can always be analyzed to detect line terminator usage\\n            return false;\\n        }\\n        else if (isCustomPattern(tokType)) {\\n            // custom token types\\n            return { issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\\n        }\\n        else {\\n            throw Error(\\\"non exhaustive match\\\");\\n        }\\n    }\\n}\\nfunction buildLineBreakIssueMessage(tokType, details) {\\n    /* istanbul ignore else */\\n    if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\\n        return (\\\"Warning: unable to identify line terminator usage in pattern.\\\\n\\\" +\\n            (\\\"\\\\tThe problem is in the <\\\" + tokType.name + \\\"> Token Type\\\\n\\\") +\\n            (\\\"\\\\t Root cause: \\\" + details.errMsg + \\\".\\\\n\\\") +\\n            \\\"\\\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\\\");\\n    }\\n    else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\\n        return (\\\"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\\\n\\\" +\\n            (\\\"\\\\tThe problem is in the <\\\" + tokType.name + \\\"> Token Type\\\\n\\\") +\\n            \\\"\\\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\\\");\\n    }\\n    else {\\n        throw Error(\\\"non exhaustive match\\\");\\n    }\\n}\\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\\nfunction getCharCodes(charsOrCodes) {\\n    var charCodes = utils_1.map(charsOrCodes, function (numOrString) {\\n        if (utils_1.isString(numOrString) && numOrString.length > 0) {\\n            return numOrString.charCodeAt(0);\\n        }\\n        else {\\n            return numOrString;\\n        }\\n    });\\n    return charCodes;\\n}\\nfunction addToMapOfArrays(map, key, value) {\\n    if (map[key] === undefined) {\\n        map[key] = [value];\\n    }\\n    else {\\n        map[key].push(value);\\n    }\\n}\\nexports.minOptimizationVal = 256;\\n/**\\n * We ae mapping charCode above ASCI (256) into buckets each in the size of 256.\\n * This is because ASCI are the most common start chars so each one of those will get its own\\n * possible token configs vector.\\n *\\n * Tokens starting with charCodes \\\"above\\\" ASCI are uncommon, so we can \\\"afford\\\"\\n * to place these into buckets of possible token configs, What we gain from\\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\\n * 256 + (2^16 / 2^8) - 1 === 511\\n *\\n * note the hack for fast division integer part extraction\\n * See: https://stackoverflow.com/a/4228528\\n */\\nvar charCodeToOptimizedIdxMap = [];\\nfunction charCodeToOptimizedIndex(charCode) {\\n    return charCode < exports.minOptimizationVal\\n        ? charCode\\n        : charCodeToOptimizedIdxMap[charCode];\\n}\\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\\n/**\\n * This is a compromise between cold start / hot running performance\\n * Creating this array takes ~3ms on a modern machine,\\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\\n * performance degrades by ~10%\\n *\\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\\n */\\nfunction initCharCodeToOptimizedIndexMap() {\\n    if (utils_1.isEmpty(charCodeToOptimizedIdxMap)) {\\n        charCodeToOptimizedIdxMap = new Array(65536);\\n        for (var i = 0; i < 65536; i++) {\\n            /* tslint:disable */\\n            charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\\n            /* tslint:enable */\\n        }\\n    }\\n}\\n//# sourceMappingURL=lexer.js.map\\n};\"],\n\"names\":[\"shadow$provide\",\"global\",\"require\",\"module\",\"exports\",\"validateRegExpPattern\",\"tokenTypes\",\"errors\",\"withRegExpPatterns\",\"utils_1\",\"filter\",\"currTokType\",\"isRegExp\",\"concat\",\"findEndOfInputAnchor\",\"findStartOfInputAnchor\",\"findUnsupportedFlags\",\"findDuplicatePatterns\",\"findEmptyMatchRegExps\",\"findMissingPatterns\",\"tokenTypesWithMissingPattern\",\"currType\",\"has\",\"PATTERN\",\"map\",\"message\",\"name\",\"type\",\"lexer_public_1\",\"LexerDefinitionErrorType\",\"MISSING_PATTERN\",\"valid\",\"difference\",\"findInvalidPatterns\",\"tokenTypesWithInvalidPattern\",\"pattern\",\"isFunction\",\"isString\",\"INVALID_PATTERN\",\"EndAnchorFinder\",\"_super\",\"_this\",\"apply\",\"arguments\",\"found\",\"__extends\",\"prototype\",\"visitEndAnchor\",\"EndAnchorFinder.prototype.visitEndAnchor\",\"node\",\"regexp_to_ast_1\",\"BaseRegExpVisitor\",\"invalidRegex\",\"regexpAst\",\"reg_exp_parser_1\",\"getRegExpAst\",\"endAnchorVisitor\",\"visit\",\"e\",\"end_of_input\",\"test\",\"source\",\"EOI_ANCHOR_FOUND\",\"matchesEmptyString\",\"EMPTY_MATCH_PATTERN\",\"StartAnchorFinder\",\"visitStartAnchor\",\"StartAnchorFinder.prototype.visitStartAnchor\",\"startAnchorVisitor\",\"start_of_input\",\"SOI_ANCHOR_FOUND\",\"invalidFlags\",\"RegExp\",\"multiline\",\"UNSUPPORTED_FLAGS_FOUND\",\"identicalPatterns\",\"outerType\",\"reduce\",\"result\",\"innerType\",\"contains\",\"Lexer\",\"NA\",\"push\",\"compact\",\"duplicatePatterns\",\"currIdenticalSet\",\"length\",\"setOfIdentical\",\"tokenTypeNames\",\"first\",\"join\",\"DUPLICATE_PATTERNS_FOUND\",\"findInvalidGroupType\",\"invalidTypes\",\"clazz\",\"group\",\"GROUP\",\"SKIPPED\",\"INVALID_GROUP_TYPE_FOUND\",\"findModesThatDoNotExist\",\"validModes\",\"invalidModes\",\"undefined\",\"PUSH_MODE\",\"tokType\",\"PUSH_MODE_DOES_NOT_EXIST\",\"findUnreachablePatterns\",\"canBeTested\",\"idx\",\"str\",\"tokenType\",\"noMetaChar\",\"forEach\",\"testIdx\",\"_a\",\"testTokenType\",\"UNREACHABLE_PATTERN\",\"regExpArray\",\"exec\",\"index\",\"Error\",\"regExp\",\"find\",\"metaChars\",\"char\",\"indexOf\",\"addStartOfInput\",\"ignoreCase\",\"flags\",\"addStickyFlag\",\"isCustomPattern\",\"isShortPattern\",\"charCodeAt\",\"checkLineBreaksIssues\",\"lineTerminatorCharCodes\",\"reg_exp_1\",\"canMatchCharCode\",\"issue\",\"IDENTIFY_TERMINATOR\",\"errMsg\",\"CUSTOM_LINE_BREAK\",\"buildLineBreakIssueMessage\",\"details\",\"getCharCodes\",\"charsOrCodes\",\"charCodes\",\"numOrString\",\"addToMapOfArrays\",\"key\",\"value\",\"charCodeToOptimizedIndex\",\"charCode\",\"minOptimizationVal\",\"charCodeToOptimizedIdxMap\",\"extendStatics\",\"d\",\"b\",\"Object\",\"setPrototypeOf\",\"__proto__\",\"Array\",\"p\",\"hasOwnProperty\",\"call\",\"__\",\"constructor\",\"TypeError\",\"String\",\"create\",\"defineProperty\",\"LineTerminatorOptimizedTester\",\"cloneEmptyGroups\",\"performWarningRuntimeChecks\",\"performRuntimeChecks\",\"validatePatterns\",\"analyzeTokenTypes\",\"enableSticky\",\"disableSticky\",\"SUPPORT_STICKY\",\"MODES\",\"DEFAULT_MODE\",\"sticky\",\"options\",\"defaults\",\"useSticky\",\"debug\",\"safeMode\",\"positionTracking\",\"lineTerminatorCharacters\",\"tracer\",\"msg\",\"action\",\"isEmpty\",\"i\",\"onlyRelevantTypes\",\"reject\",\"hasCustom\",\"allTransformedPatterns\",\"currPattern\",\"regExpSource\",\"escapedRegExpString\",\"replace\",\"wrappedRegExp\",\"patternIdxToType\",\"patternIdxToGroup\",\"patternIdxToLongerAltIdx\",\"patternIdxToPushMode\",\"patternIdxToPopMode\",\"tokenTypeIdx\",\"groupName\",\"isUndefined\",\"longerAltType\",\"LONGER_ALT\",\"longerAltIdx\",\"patternIdxToCanLineTerminator\",\"LINE_BREAKS\",\"patternIdxToIsCustom\",\"patternIdxToShort\",\"emptyGroups\",\"patternIdxToConfig\",\"acc\",\"x\",\"longerAlt\",\"canLineTerminator\",\"isCustom\",\"short\",\"pop\",\"canBeOptimized\",\"charCodeToPatternIdxToConfig\",\"optimizedIdx\",\"isArray\",\"START_CHARS_HINT\",\"lastOptimizedIdx_1\",\"charOrInt\",\"currOptimizedIdx\",\"unicode\",\"ensureOptimizations\",\"PRINT_ERROR\",\"failedOptimizationPrefixMsg\",\"toString\",\"optimizedCodes\",\"getOptimizedStartCodesIndices\",\"code\",\"packArray\",\"validModesNames\",\"missingResult\",\"invalidResult\",\"validTokenTypes\",\"lexerDefinition\",\"trackLines\",\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\",\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\",\"modes\",\"defaultMode\",\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\",\"currModeValue\",\"currModeName\",\"currIdx\",\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\",\"warnings\",\"hasAnyLineBreak\",\"allTokenTypes\",\"flatten\",\"mapValues\",\"tokTypes\",\"concreteTokenTypes\",\"terminatorCharCodes\",\"currIssue\",\"warningDescriptor\",\"NO_LINE_BREAKS_FLAGS\",\"clonedResult\",\"groupKeys\",\"keys\",\"currKey\",\"currGroupValue\",\"text\",\"len\",\"lastIndex\",\"c\"]\n}\n"]