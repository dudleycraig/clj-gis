["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/chevrotain/lib/src/scan/lexer_public.js"],"~:js","shadow$provide.module$node_modules$chevrotain$lib$src$scan$lexer_public=function(global,require,module,exports){Object.defineProperty(exports,\"__esModule\",{value:!0});exports.Lexer=exports.LexerDefinitionErrorType=void 0;var lexer_1=require(\"module$node_modules$chevrotain$lib$src$scan$lexer\"),utils_1=require(\"module$node_modules$$chevrotain$utils$lib$src$api\"),tokens_1=require(\"module$node_modules$chevrotain$lib$src$scan$tokens\");global=require(\"module$node_modules$chevrotain$lib$src$scan$lexer_errors_public\");\nvar reg_exp_parser_1=require(\"module$node_modules$chevrotain$lib$src$scan$reg_exp_parser\");(function(LexerDefinitionErrorType){LexerDefinitionErrorType[LexerDefinitionErrorType.MISSING_PATTERN=0]=\"MISSING_PATTERN\";LexerDefinitionErrorType[LexerDefinitionErrorType.INVALID_PATTERN=1]=\"INVALID_PATTERN\";LexerDefinitionErrorType[LexerDefinitionErrorType.EOI_ANCHOR_FOUND=2]=\"EOI_ANCHOR_FOUND\";LexerDefinitionErrorType[LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND=3]=\"UNSUPPORTED_FLAGS_FOUND\";LexerDefinitionErrorType[LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND=\n4]=\"DUPLICATE_PATTERNS_FOUND\";LexerDefinitionErrorType[LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND=5]=\"INVALID_GROUP_TYPE_FOUND\";LexerDefinitionErrorType[LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST=6]=\"PUSH_MODE_DOES_NOT_EXIST\";LexerDefinitionErrorType[LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE=7]=\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";LexerDefinitionErrorType[LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY=8]=\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\nLexerDefinitionErrorType[LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST=9]=\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";LexerDefinitionErrorType[LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED=10]=\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";LexerDefinitionErrorType[LexerDefinitionErrorType.SOI_ANCHOR_FOUND=11]=\"SOI_ANCHOR_FOUND\";LexerDefinitionErrorType[LexerDefinitionErrorType.EMPTY_MATCH_PATTERN=12]=\"EMPTY_MATCH_PATTERN\";LexerDefinitionErrorType[LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS=\n13]=\"NO_LINE_BREAKS_FLAGS\";LexerDefinitionErrorType[LexerDefinitionErrorType.UNREACHABLE_PATTERN=14]=\"UNREACHABLE_PATTERN\";LexerDefinitionErrorType[LexerDefinitionErrorType.IDENTIFY_TERMINATOR=15]=\"IDENTIFY_TERMINATOR\";LexerDefinitionErrorType[LexerDefinitionErrorType.CUSTOM_LINE_BREAK=16]=\"CUSTOM_LINE_BREAK\"})(exports.LexerDefinitionErrorType||(exports.LexerDefinitionErrorType={}));var DEFAULT_LEXER_CONFIG={deferDefinitionErrorsHandling:!1,positionTracking:\"full\",lineTerminatorsPattern:/\\n|\\r\\n?/g,\nlineTerminatorCharacters:[\"\\n\",\"\\r\"],ensureOptimizations:!1,safeMode:!1,errorMessageProvider:global.defaultLexerErrorProvider,traceInitPerf:!1,skipValidations:!1};Object.freeze(DEFAULT_LEXER_CONFIG);require=function(){function Lexer(lexerDefinition,config){var _this=this;void 0===config&&(config=DEFAULT_LEXER_CONFIG);this.lexerDefinition=lexerDefinition;this.lexerDefinitionErrors=[];this.lexerDefinitionWarning=[];this.patternIdxToConfig={};this.charCodeToPatternIdxToConfig={};this.modes=[];this.emptyGroups=\n{};this.config=void 0;this.trackEndLines=this.trackStartLines=!0;this.hasCustom=!1;this.canModeBeOptimized={};if(\"boolean\"===typeof config)throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\na boolean 2nd argument is no longer supported\");this.config=utils_1.merge(DEFAULT_LEXER_CONFIG,config);var traceInitVal=this.config.traceInitPerf;!0===traceInitVal?(this.traceInitMaxIdent=Infinity,this.traceInitPerf=!0):\"number\"===typeof traceInitVal&&(this.traceInitMaxIdent=\ntraceInitVal,this.traceInitPerf=!0);this.traceInitIndent=-1;this.TRACE_INIT(\"Lexer Constructor\",function(){var actualDefinition,hasOnlySingleMode=!0;_this.TRACE_INIT(\"Lexer Config handling\",function(){if(_this.config.lineTerminatorsPattern===DEFAULT_LEXER_CONFIG.lineTerminatorsPattern)_this.config.lineTerminatorsPattern=lexer_1.LineTerminatorOptimizedTester;else if(_this.config.lineTerminatorCharacters===DEFAULT_LEXER_CONFIG.lineTerminatorCharacters)throw Error(\"Error: Missing \\x3clineTerminatorCharacters\\x3e property on the Lexer config.\\n\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\nif(config.safeMode&&config.ensureOptimizations)throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');_this.trackStartLines=/full|onlyStart/i.test(_this.config.positionTracking);_this.trackEndLines=/full/i.test(_this.config.positionTracking);utils_1.isArray(lexerDefinition)?(actualDefinition={modes:{}},actualDefinition.modes[lexer_1.DEFAULT_MODE]=utils_1.cloneArr(lexerDefinition),actualDefinition[lexer_1.DEFAULT_MODE]=lexer_1.DEFAULT_MODE):(hasOnlySingleMode=!1,actualDefinition=\nutils_1.cloneObj(lexerDefinition))});!1===_this.config.skipValidations&&(_this.TRACE_INIT(\"performRuntimeChecks\",function(){_this.lexerDefinitionErrors=_this.lexerDefinitionErrors.concat(lexer_1.performRuntimeChecks(actualDefinition,_this.trackStartLines,_this.config.lineTerminatorCharacters))}),_this.TRACE_INIT(\"performWarningRuntimeChecks\",function(){_this.lexerDefinitionWarning=_this.lexerDefinitionWarning.concat(lexer_1.performWarningRuntimeChecks(actualDefinition,_this.trackStartLines,_this.config.lineTerminatorCharacters))}));\nactualDefinition.modes=actualDefinition.modes?actualDefinition.modes:{};utils_1.forEach(actualDefinition.modes,function(currModeValue,currModeName){actualDefinition.modes[currModeName]=utils_1.reject(currModeValue,function(currTokType){return utils_1.isUndefined(currTokType)})});var allModeNames=utils_1.keys(actualDefinition.modes);utils_1.forEach(actualDefinition.modes,function(currModDef,currModName){_this.TRACE_INIT(\"Mode: \\x3c\"+currModName+\"\\x3e processing\",function(){_this.modes.push(currModName);\n!1===_this.config.skipValidations&&_this.TRACE_INIT(\"validatePatterns\",function(){_this.lexerDefinitionErrors=_this.lexerDefinitionErrors.concat(lexer_1.validatePatterns(currModDef,allModeNames))});if(utils_1.isEmpty(_this.lexerDefinitionErrors)){tokens_1.augmentTokenTypes(currModDef);var currAnalyzeResult_1;_this.TRACE_INIT(\"analyzeTokenTypes\",function(){currAnalyzeResult_1=lexer_1.analyzeTokenTypes(currModDef,{lineTerminatorCharacters:_this.config.lineTerminatorCharacters,positionTracking:config.positionTracking,\nensureOptimizations:config.ensureOptimizations,safeMode:config.safeMode,tracer:_this.TRACE_INIT.bind(_this)})});_this.patternIdxToConfig[currModName]=currAnalyzeResult_1.patternIdxToConfig;_this.charCodeToPatternIdxToConfig[currModName]=currAnalyzeResult_1.charCodeToPatternIdxToConfig;_this.emptyGroups=utils_1.merge(_this.emptyGroups,currAnalyzeResult_1.emptyGroups);_this.hasCustom=currAnalyzeResult_1.hasCustom||_this.hasCustom;_this.canModeBeOptimized[currModName]=currAnalyzeResult_1.canBeOptimized}})});\n_this.defaultMode=actualDefinition.defaultMode;if(!utils_1.isEmpty(_this.lexerDefinitionErrors)&&!_this.config.deferDefinitionErrorsHandling){var allErrMessagesString=utils_1.map(_this.lexerDefinitionErrors,function(error){return error.message}).join(\"-----------------------\\n\");throw Error(\"Errors detected in definition of Lexer:\\n\"+allErrMessagesString);}utils_1.forEach(_this.lexerDefinitionWarning,function(warningDescriptor){utils_1.PRINT_WARNING(warningDescriptor.message)});_this.TRACE_INIT(\"Choosing sub-methods implementations\",\nfunction(){lexer_1.SUPPORT_STICKY?(_this.chopInput=utils_1.IDENTITY,_this.match=_this.matchWithTest):(_this.updateLastIndex=utils_1.NOOP,_this.match=_this.matchWithExec);hasOnlySingleMode&&(_this.handleModes=utils_1.NOOP);!1===_this.trackStartLines&&(_this.computeNewColumn=utils_1.IDENTITY);!1===_this.trackEndLines&&(_this.updateTokenEndLineColumnLocation=utils_1.NOOP);if(/full/i.test(_this.config.positionTracking))_this.createTokenInstance=_this.createFullToken;else if(/onlyStart/i.test(_this.config.positionTracking))_this.createTokenInstance=\n_this.createStartOnlyToken;else if(/onlyOffset/i.test(_this.config.positionTracking))_this.createTokenInstance=_this.createOffsetOnlyToken;else throw Error('Invalid \\x3cpositionTracking\\x3e config option: \"'+_this.config.positionTracking+'\"');_this.hasCustom?(_this.addToken=_this.addTokenUsingPush,_this.handlePayload=_this.handlePayloadWithCustom):(_this.addToken=_this.addTokenUsingMemberAccess,_this.handlePayload=_this.handlePayloadNoCustom)});_this.TRACE_INIT(\"Failed Optimization Warnings\",function(){var unOptimizedModes=\nutils_1.reduce(_this.canModeBeOptimized,function(cannotBeOptimized,canBeOptimized,modeName){!1===canBeOptimized&&cannotBeOptimized.push(modeName);return cannotBeOptimized},[]);if(config.ensureOptimizations&&!utils_1.isEmpty(unOptimizedModes))throw Error(\"Lexer Modes: \\x3c \"+unOptimizedModes.join(\", \")+' \\x3e cannot be optimized.\\n\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n\\t Or inspect the console log for details on how to resolve these issues.');\n});_this.TRACE_INIT(\"clearRegExpParserCache\",function(){reg_exp_parser_1.clearRegExpParserCache()});_this.TRACE_INIT(\"toFastProperties\",function(){utils_1.toFastProperties(_this)})})}Lexer.prototype.tokenize=function(text,initialMode){void 0===initialMode&&(initialMode=this.defaultMode);if(!utils_1.isEmpty(this.lexerDefinitionErrors))throw text=utils_1.map(this.lexerDefinitionErrors,function(error){return error.message}).join(\"-----------------------\\n\"),Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\"+\ntext);return this.tokenizeInternal(text,initialMode)};Lexer.prototype.tokenizeInternal=function(text,initialMode){function getPossiblePatternsSlow(){return patternIdxToConfig}function getPossiblePatternsOptimized(charCode){charCode=lexer_1.charCodeToOptimizedIndex(charCode);charCode=currCharCodeToPatternIdxToConfig[charCode];return void 0===charCode?emptyArray:charCode}function push_mode(newMode){modeStack.push(newMode);currCharCodeToPatternIdxToConfig=this.charCodeToPatternIdxToConfig[newMode];patternIdxToConfig=\nthis.patternIdxToConfig[newMode];currModePatternsLength=currModePatternsLength=patternIdxToConfig.length;newMode=this.canModeBeOptimized[newMode]&&!1===this.config.safeMode;getPossiblePatterns=currCharCodeToPatternIdxToConfig&&newMode?getPossiblePatternsOptimized:getPossiblePatternsSlow}var _this=this,i,orgText=text,orgLength=orgText.length,offset=0,matchedTokensIndex=0,matchedTokens=Array(this.hasCustom?0:Math.floor(text.length/10)),errors=[],line=this.trackStartLines?1:void 0,column=this.trackStartLines?\n1:void 0,groups=lexer_1.cloneEmptyGroups(this.emptyGroups),trackLines=this.trackStartLines,lineTerminatorPattern=this.config.lineTerminatorsPattern,currModePatternsLength=0,patternIdxToConfig=[],currCharCodeToPatternIdxToConfig=[],modeStack=[],emptyArray=[];Object.freeze(emptyArray);var getPossiblePatterns=void 0,pop_mode=function(popToken){if(1===modeStack.length&&void 0===popToken.tokenType.PUSH_MODE){var msg_1=_this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);errors.push({offset:popToken.startOffset,\nline:void 0!==popToken.startLine?popToken.startLine:void 0,column:void 0!==popToken.startColumn?popToken.startColumn:void 0,length:popToken.image.length,message:msg_1})}else modeStack.pop(),popToken=utils_1.last(modeStack),patternIdxToConfig=_this.patternIdxToConfig[popToken],currCharCodeToPatternIdxToConfig=_this.charCodeToPatternIdxToConfig[popToken],currModePatternsLength=patternIdxToConfig.length,popToken=_this.canModeBeOptimized[popToken]&&!1===_this.config.safeMode,getPossiblePatterns=currCharCodeToPatternIdxToConfig&&\npopToken?getPossiblePatternsOptimized:getPossiblePatternsSlow};push_mode.call(this,initialMode);for(var currConfig;offset<orgLength;){initialMode=null;var matchAltImage=orgText.charCodeAt(offset);var j=getPossiblePatterns(matchAltImage);var chosenPatternsLength=j.length;for(i=0;i<chosenPatternsLength;i++){currConfig=j[i];var longerAltIdx=currConfig.pattern;var payload=null;var altPayload=currConfig.short;!1!==altPayload?matchAltImage===altPayload&&(initialMode=longerAltIdx):!0===currConfig.isCustom?\n(longerAltIdx=longerAltIdx.exec(orgText,offset,matchedTokens,groups),null!==longerAltIdx?(initialMode=longerAltIdx[0],void 0!==longerAltIdx.payload&&(payload=longerAltIdx.payload)):initialMode=null):(this.updateLastIndex(longerAltIdx,offset),initialMode=this.match(longerAltIdx,text,offset));if(null!==initialMode){longerAltIdx=currConfig.longerAlt;void 0!==longerAltIdx&&(i=patternIdxToConfig[longerAltIdx],longerAltIdx=i.pattern,altPayload=null,!0===i.isCustom?(longerAltIdx=longerAltIdx.exec(orgText,\noffset,matchedTokens,groups),null!==longerAltIdx?(matchAltImage=longerAltIdx[0],void 0!==longerAltIdx.payload&&(altPayload=longerAltIdx.payload)):matchAltImage=null):(this.updateLastIndex(longerAltIdx,offset),matchAltImage=this.match(longerAltIdx,text,offset)),matchAltImage&&matchAltImage.length>initialMode.length&&(initialMode=matchAltImage,payload=altPayload,currConfig=i));break}}if(null!==initialMode){longerAltIdx=initialMode.length;altPayload=currConfig.group;if(void 0!==altPayload){var tokType=\ncurrConfig.tokenTypeIdx;tokType=this.createTokenInstance(initialMode,offset,tokType,currConfig.tokenType,line,column,longerAltIdx);this.handlePayload(tokType,payload);!1===altPayload?matchedTokensIndex=this.addToken(matchedTokens,matchedTokensIndex,tokType):groups[altPayload].push(tokType)}text=this.chopInput(text,longerAltIdx);offset+=longerAltIdx;column=this.computeNewColumn(column,longerAltIdx);if(!0===trackLines&&!0===currConfig.canLineTerminator){i=0;j=matchAltImage=void 0;lineTerminatorPattern.lastIndex=\n0;do matchAltImage=lineTerminatorPattern.test(initialMode),!0===matchAltImage&&(j=lineTerminatorPattern.lastIndex-1,i++);while(!0===matchAltImage);0!==i&&(line+=i,column=longerAltIdx-j,this.updateTokenEndLineColumnLocation(tokType,altPayload,j,i,line,column,longerAltIdx))}this.handleModes(currConfig,pop_mode,push_mode,tokType)}else{initialMode=offset;i=line;matchAltImage=column;for(chosenPatternsLength=!1;!chosenPatternsLength&&offset<orgLength;)for(orgText.charCodeAt(offset),text=this.chopInput(text,\n1),offset++,j=0;j<currModePatternsLength;j++){var currConfig_1=patternIdxToConfig[j];longerAltIdx=currConfig_1.pattern;altPayload=currConfig_1.short;!1!==altPayload?orgText.charCodeAt(offset)===altPayload&&(chosenPatternsLength=!0):!0===currConfig_1.isCustom?chosenPatternsLength=null!==longerAltIdx.exec(orgText,offset,matchedTokens,groups):(this.updateLastIndex(longerAltIdx,offset),chosenPatternsLength=null!==longerAltIdx.exec(text));if(!0===chosenPatternsLength)break}longerAltIdx=offset-initialMode;\naltPayload=this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText,initialMode,longerAltIdx,i,matchAltImage);errors.push({offset:initialMode,line:i,column:matchAltImage,length:longerAltIdx,message:altPayload})}}this.hasCustom||(matchedTokens.length=matchedTokensIndex);return{tokens:matchedTokens,groups,errors}};Lexer.prototype.handleModes=function(config,pop_mode,push_mode,newToken){!0===config.pop?(config=config.push,pop_mode(newToken),void 0!==config&&push_mode.call(this,config)):\nvoid 0!==config.push&&push_mode.call(this,config.push)};Lexer.prototype.chopInput=function(text,length){return text.substring(length)};Lexer.prototype.updateLastIndex=function(regExp,newLastIndex){regExp.lastIndex=newLastIndex};Lexer.prototype.updateTokenEndLineColumnLocation=function(newToken,group,lastLTIdx,numOfLTsInMatch,line,column,imageLength){void 0!==group&&(lastLTIdx=(group=lastLTIdx===imageLength-1)?-1:0,1!==numOfLTsInMatch||!0!==group)&&(newToken.endLine=line+lastLTIdx,newToken.endColumn=\ncolumn-1+-lastLTIdx)};Lexer.prototype.computeNewColumn=function(oldColumn,imageLength){return oldColumn+imageLength};Lexer.prototype.createTokenInstance=function(){for(var _i=0;_i<arguments.length;_i++);return null};Lexer.prototype.createOffsetOnlyToken=function(image,startOffset,tokenTypeIdx,tokenType){return{image,startOffset,tokenTypeIdx,tokenType}};Lexer.prototype.createStartOnlyToken=function(image,startOffset,tokenTypeIdx,tokenType,startLine,startColumn){return{image,startOffset,startLine,startColumn,\ntokenTypeIdx,tokenType}};Lexer.prototype.createFullToken=function(image,startOffset,tokenTypeIdx,tokenType,startLine,startColumn,imageLength){return{image,startOffset,endOffset:startOffset+imageLength-1,startLine,endLine:startLine,startColumn,endColumn:startColumn+imageLength-1,tokenTypeIdx,tokenType}};Lexer.prototype.addToken=function(tokenVector,index,tokenToAdd){return 666};Lexer.prototype.addTokenUsingPush=function(tokenVector,index,tokenToAdd){tokenVector.push(tokenToAdd);return index};Lexer.prototype.addTokenUsingMemberAccess=\nfunction(tokenVector,index,tokenToAdd){tokenVector[index]=tokenToAdd;index++;return index};Lexer.prototype.handlePayload=function(token,payload){};Lexer.prototype.handlePayloadNoCustom=function(token,payload){};Lexer.prototype.handlePayloadWithCustom=function(token,payload){null!==payload&&(token.payload=payload)};Lexer.prototype.match=function(pattern,text,offset){return null};Lexer.prototype.matchWithTest=function(pattern,text,offset){return!0===pattern.test(text)?text.substring(offset,pattern.lastIndex):\nnull};Lexer.prototype.matchWithExec=function(pattern,text){pattern=pattern.exec(text);return null!==pattern?pattern[0]:pattern};Lexer.prototype.TRACE_INIT=function(phaseDesc,phaseImpl){if(!0===this.traceInitPerf){this.traceInitIndent++;var indent=Array(this.traceInitIndent+1).join(\"\\t\");this.traceInitIndent<this.traceInitMaxIdent&&console.log(indent+\"--\\x3e \\x3c\"+phaseDesc+\"\\x3e\");var _a=utils_1.timer(phaseImpl);phaseImpl=_a.time;_a=_a.value;var traceMethod=10<phaseImpl?console.warn:console.log;this.traceInitIndent<\nthis.traceInitMaxIdent&&traceMethod(indent+\"\\x3c-- \\x3c\"+phaseDesc+\"\\x3e time: \"+phaseImpl+\"ms\");this.traceInitIndent--;return _a}return phaseImpl()};Lexer.SKIPPED=\"This marks a skipped Token pattern, this means each token identified by it willbe consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";Lexer.NA=/NOT_APPLICABLE/;return Lexer}();exports.Lexer=require}","~:source","shadow$provide[\"module$node_modules$chevrotain$lib$src$scan$lexer_public\"] = function(global,require,module,exports) {\n\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Lexer = exports.LexerDefinitionErrorType = void 0;\nvar lexer_1 = require(\"./lexer\");\nvar utils_1 = require(\"@chevrotain/utils\");\nvar tokens_1 = require(\"./tokens\");\nvar lexer_errors_public_1 = require(\"../scan/lexer_errors_public\");\nvar reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar LexerDefinitionErrorType;\n(function (LexerDefinitionErrorType) {\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\nvar DEFAULT_LEXER_CONFIG = {\n    deferDefinitionErrorsHandling: false,\n    positionTracking: \"full\",\n    lineTerminatorsPattern: /\\n|\\r\\n?/g,\n    lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n    ensureOptimizations: false,\n    safeMode: false,\n    errorMessageProvider: lexer_errors_public_1.defaultLexerErrorProvider,\n    traceInitPerf: false,\n    skipValidations: false\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\nvar Lexer = /** @class */ (function () {\n    function Lexer(lexerDefinition, config) {\n        var _this = this;\n        if (config === void 0) { config = DEFAULT_LEXER_CONFIG; }\n        this.lexerDefinition = lexerDefinition;\n        this.lexerDefinitionErrors = [];\n        this.lexerDefinitionWarning = [];\n        this.patternIdxToConfig = {};\n        this.charCodeToPatternIdxToConfig = {};\n        this.modes = [];\n        this.emptyGroups = {};\n        this.config = undefined;\n        this.trackStartLines = true;\n        this.trackEndLines = true;\n        this.hasCustom = false;\n        this.canModeBeOptimized = {};\n        if (typeof config === \"boolean\") {\n            throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n                \"a boolean 2nd argument is no longer supported\");\n        }\n        // todo: defaults func?\n        this.config = utils_1.merge(DEFAULT_LEXER_CONFIG, config);\n        var traceInitVal = this.config.traceInitPerf;\n        if (traceInitVal === true) {\n            this.traceInitMaxIdent = Infinity;\n            this.traceInitPerf = true;\n        }\n        else if (typeof traceInitVal === \"number\") {\n            this.traceInitMaxIdent = traceInitVal;\n            this.traceInitPerf = true;\n        }\n        this.traceInitIndent = -1;\n        this.TRACE_INIT(\"Lexer Constructor\", function () {\n            var actualDefinition;\n            var hasOnlySingleMode = true;\n            _this.TRACE_INIT(\"Lexer Config handling\", function () {\n                if (_this.config.lineTerminatorsPattern ===\n                    DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n                    // optimized built-in implementation for the defaults definition of lineTerminators\n                    _this.config.lineTerminatorsPattern = lexer_1.LineTerminatorOptimizedTester;\n                }\n                else {\n                    if (_this.config.lineTerminatorCharacters ===\n                        DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n                        throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n                    }\n                }\n                if (config.safeMode && config.ensureOptimizations) {\n                    throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n                }\n                _this.trackStartLines = /full|onlyStart/i.test(_this.config.positionTracking);\n                _this.trackEndLines = /full/i.test(_this.config.positionTracking);\n                // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n                if (utils_1.isArray(lexerDefinition)) {\n                    actualDefinition = { modes: {} };\n                    actualDefinition.modes[lexer_1.DEFAULT_MODE] = utils_1.cloneArr(lexerDefinition);\n                    actualDefinition[lexer_1.DEFAULT_MODE] = lexer_1.DEFAULT_MODE;\n                }\n                else {\n                    // no conversion needed, input should already be a IMultiModeLexerDefinition\n                    hasOnlySingleMode = false;\n                    actualDefinition = utils_1.cloneObj(lexerDefinition);\n                }\n            });\n            if (_this.config.skipValidations === false) {\n                _this.TRACE_INIT(\"performRuntimeChecks\", function () {\n                    _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat(lexer_1.performRuntimeChecks(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n                });\n                _this.TRACE_INIT(\"performWarningRuntimeChecks\", function () {\n                    _this.lexerDefinitionWarning = _this.lexerDefinitionWarning.concat(lexer_1.performWarningRuntimeChecks(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\n                });\n            }\n            // for extra robustness to avoid throwing an none informative error message\n            actualDefinition.modes = actualDefinition.modes\n                ? actualDefinition.modes\n                : {};\n            // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n            // this transformation is to increase robustness in the case of partially invalid lexer definition.\n            utils_1.forEach(actualDefinition.modes, function (currModeValue, currModeName) {\n                actualDefinition.modes[currModeName] = utils_1.reject(currModeValue, function (currTokType) { return utils_1.isUndefined(currTokType); });\n            });\n            var allModeNames = utils_1.keys(actualDefinition.modes);\n            utils_1.forEach(actualDefinition.modes, function (currModDef, currModName) {\n                _this.TRACE_INIT(\"Mode: <\" + currModName + \"> processing\", function () {\n                    _this.modes.push(currModName);\n                    if (_this.config.skipValidations === false) {\n                        _this.TRACE_INIT(\"validatePatterns\", function () {\n                            _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat(lexer_1.validatePatterns(currModDef, allModeNames));\n                        });\n                    }\n                    // If definition errors were encountered, the analysis phase may fail unexpectedly/\n                    // Considering a lexer with definition errors may never be used, there is no point\n                    // to performing the analysis anyhow...\n                    if (utils_1.isEmpty(_this.lexerDefinitionErrors)) {\n                        tokens_1.augmentTokenTypes(currModDef);\n                        var currAnalyzeResult_1;\n                        _this.TRACE_INIT(\"analyzeTokenTypes\", function () {\n                            currAnalyzeResult_1 = lexer_1.analyzeTokenTypes(currModDef, {\n                                lineTerminatorCharacters: _this.config\n                                    .lineTerminatorCharacters,\n                                positionTracking: config.positionTracking,\n                                ensureOptimizations: config.ensureOptimizations,\n                                safeMode: config.safeMode,\n                                tracer: _this.TRACE_INIT.bind(_this)\n                            });\n                        });\n                        _this.patternIdxToConfig[currModName] =\n                            currAnalyzeResult_1.patternIdxToConfig;\n                        _this.charCodeToPatternIdxToConfig[currModName] =\n                            currAnalyzeResult_1.charCodeToPatternIdxToConfig;\n                        _this.emptyGroups = utils_1.merge(_this.emptyGroups, currAnalyzeResult_1.emptyGroups);\n                        _this.hasCustom = currAnalyzeResult_1.hasCustom || _this.hasCustom;\n                        _this.canModeBeOptimized[currModName] =\n                            currAnalyzeResult_1.canBeOptimized;\n                    }\n                });\n            });\n            _this.defaultMode = actualDefinition.defaultMode;\n            if (!utils_1.isEmpty(_this.lexerDefinitionErrors) &&\n                !_this.config.deferDefinitionErrorsHandling) {\n                var allErrMessages = utils_1.map(_this.lexerDefinitionErrors, function (error) {\n                    return error.message;\n                });\n                var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n                throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n            }\n            // Only print warning if there are no errors, This will avoid pl\n            utils_1.forEach(_this.lexerDefinitionWarning, function (warningDescriptor) {\n                utils_1.PRINT_WARNING(warningDescriptor.message);\n            });\n            _this.TRACE_INIT(\"Choosing sub-methods implementations\", function () {\n                // Choose the relevant internal implementations for this specific parser.\n                // These implementations should be in-lined by the JavaScript engine\n                // to provide optimal performance in each scenario.\n                if (lexer_1.SUPPORT_STICKY) {\n                    _this.chopInput = utils_1.IDENTITY;\n                    _this.match = _this.matchWithTest;\n                }\n                else {\n                    _this.updateLastIndex = utils_1.NOOP;\n                    _this.match = _this.matchWithExec;\n                }\n                if (hasOnlySingleMode) {\n                    _this.handleModes = utils_1.NOOP;\n                }\n                if (_this.trackStartLines === false) {\n                    _this.computeNewColumn = utils_1.IDENTITY;\n                }\n                if (_this.trackEndLines === false) {\n                    _this.updateTokenEndLineColumnLocation = utils_1.NOOP;\n                }\n                if (/full/i.test(_this.config.positionTracking)) {\n                    _this.createTokenInstance = _this.createFullToken;\n                }\n                else if (/onlyStart/i.test(_this.config.positionTracking)) {\n                    _this.createTokenInstance = _this.createStartOnlyToken;\n                }\n                else if (/onlyOffset/i.test(_this.config.positionTracking)) {\n                    _this.createTokenInstance = _this.createOffsetOnlyToken;\n                }\n                else {\n                    throw Error(\"Invalid <positionTracking> config option: \\\"\" + _this.config.positionTracking + \"\\\"\");\n                }\n                if (_this.hasCustom) {\n                    _this.addToken = _this.addTokenUsingPush;\n                    _this.handlePayload = _this.handlePayloadWithCustom;\n                }\n                else {\n                    _this.addToken = _this.addTokenUsingMemberAccess;\n                    _this.handlePayload = _this.handlePayloadNoCustom;\n                }\n            });\n            _this.TRACE_INIT(\"Failed Optimization Warnings\", function () {\n                var unOptimizedModes = utils_1.reduce(_this.canModeBeOptimized, function (cannotBeOptimized, canBeOptimized, modeName) {\n                    if (canBeOptimized === false) {\n                        cannotBeOptimized.push(modeName);\n                    }\n                    return cannotBeOptimized;\n                }, []);\n                if (config.ensureOptimizations && !utils_1.isEmpty(unOptimizedModes)) {\n                    throw Error(\"Lexer Modes: < \" + unOptimizedModes.join(\", \") + \" > cannot be optimized.\\n\" +\n                        '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n                        \"\\t Or inspect the console log for details on how to resolve these issues.\");\n                }\n            });\n            _this.TRACE_INIT(\"clearRegExpParserCache\", function () {\n                reg_exp_parser_1.clearRegExpParserCache();\n            });\n            _this.TRACE_INIT(\"toFastProperties\", function () {\n                utils_1.toFastProperties(_this);\n            });\n        });\n    }\n    Lexer.prototype.tokenize = function (text, initialMode) {\n        if (initialMode === void 0) { initialMode = this.defaultMode; }\n        if (!utils_1.isEmpty(this.lexerDefinitionErrors)) {\n            var allErrMessages = utils_1.map(this.lexerDefinitionErrors, function (error) {\n                return error.message;\n            });\n            var allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n            throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n                allErrMessagesString);\n        }\n        var lexResult = this.tokenizeInternal(text, initialMode);\n        return lexResult;\n    };\n    // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n    // This is intentional due to performance considerations.\n    Lexer.prototype.tokenizeInternal = function (text, initialMode) {\n        var _this = this;\n        var i, j, matchAltImage, longerAltIdx, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n        var orgText = text;\n        var orgLength = orgText.length;\n        var offset = 0;\n        var matchedTokensIndex = 0;\n        // initializing the tokensArray to the \"guessed\" size.\n        // guessing too little will still reduce the number of array re-sizes on pushes.\n        // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n        // but would still have a faster runtime by avoiding (All but one) array resizing.\n        var guessedNumberOfTokens = this.hasCustom\n            ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n            : Math.floor(text.length / 10);\n        var matchedTokens = new Array(guessedNumberOfTokens);\n        var errors = [];\n        var line = this.trackStartLines ? 1 : undefined;\n        var column = this.trackStartLines ? 1 : undefined;\n        var groups = lexer_1.cloneEmptyGroups(this.emptyGroups);\n        var trackLines = this.trackStartLines;\n        var lineTerminatorPattern = this.config.lineTerminatorsPattern;\n        var currModePatternsLength = 0;\n        var patternIdxToConfig = [];\n        var currCharCodeToPatternIdxToConfig = [];\n        var modeStack = [];\n        var emptyArray = [];\n        Object.freeze(emptyArray);\n        var getPossiblePatterns = undefined;\n        function getPossiblePatternsSlow() {\n            return patternIdxToConfig;\n        }\n        function getPossiblePatternsOptimized(charCode) {\n            var optimizedCharIdx = lexer_1.charCodeToOptimizedIndex(charCode);\n            var possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n            if (possiblePatterns === undefined) {\n                return emptyArray;\n            }\n            else {\n                return possiblePatterns;\n            }\n        }\n        var pop_mode = function (popToken) {\n            // TODO: perhaps avoid this error in the edge case there is no more input?\n            if (modeStack.length === 1 &&\n                // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n                // So no error should occur.\n                popToken.tokenType.PUSH_MODE === undefined) {\n                // if we try to pop the last mode there lexer will no longer have ANY mode.\n                // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n                var msg_1 = _this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n                errors.push({\n                    offset: popToken.startOffset,\n                    line: popToken.startLine !== undefined ? popToken.startLine : undefined,\n                    column: popToken.startColumn !== undefined\n                        ? popToken.startColumn\n                        : undefined,\n                    length: popToken.image.length,\n                    message: msg_1\n                });\n            }\n            else {\n                modeStack.pop();\n                var newMode = utils_1.last(modeStack);\n                patternIdxToConfig = _this.patternIdxToConfig[newMode];\n                currCharCodeToPatternIdxToConfig = _this.charCodeToPatternIdxToConfig[newMode];\n                currModePatternsLength = patternIdxToConfig.length;\n                var modeCanBeOptimized = _this.canModeBeOptimized[newMode] && _this.config.safeMode === false;\n                if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                    getPossiblePatterns = getPossiblePatternsOptimized;\n                }\n                else {\n                    getPossiblePatterns = getPossiblePatternsSlow;\n                }\n            }\n        };\n        function push_mode(newMode) {\n            modeStack.push(newMode);\n            currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n            patternIdxToConfig = this.patternIdxToConfig[newMode];\n            currModePatternsLength = patternIdxToConfig.length;\n            currModePatternsLength = patternIdxToConfig.length;\n            var modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n            if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                getPossiblePatterns = getPossiblePatternsOptimized;\n            }\n            else {\n                getPossiblePatterns = getPossiblePatternsSlow;\n            }\n        }\n        // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n        // seem to matter performance wise.\n        push_mode.call(this, initialMode);\n        var currConfig;\n        while (offset < orgLength) {\n            matchedImage = null;\n            var nextCharCode = orgText.charCodeAt(offset);\n            var chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n            var chosenPatternsLength = chosenPatternIdxToConfig.length;\n            for (i = 0; i < chosenPatternsLength; i++) {\n                currConfig = chosenPatternIdxToConfig[i];\n                var currPattern = currConfig.pattern;\n                payload = null;\n                // manually in-lined because > 600 chars won't be in-lined in V8\n                var singleCharCode = currConfig.short;\n                if (singleCharCode !== false) {\n                    if (nextCharCode === singleCharCode) {\n                        // single character string\n                        matchedImage = currPattern;\n                    }\n                }\n                else if (currConfig.isCustom === true) {\n                    match = currPattern.exec(orgText, offset, matchedTokens, groups);\n                    if (match !== null) {\n                        matchedImage = match[0];\n                        if (match.payload !== undefined) {\n                            payload = match.payload;\n                        }\n                    }\n                    else {\n                        matchedImage = null;\n                    }\n                }\n                else {\n                    this.updateLastIndex(currPattern, offset);\n                    matchedImage = this.match(currPattern, text, offset);\n                }\n                if (matchedImage !== null) {\n                    // even though this pattern matched we must try a another longer alternative.\n                    // this can be used to prioritize keywords over identifiers\n                    longerAltIdx = currConfig.longerAlt;\n                    if (longerAltIdx !== undefined) {\n                        // TODO: micro optimize, avoid extra prop access\n                        // by saving/linking longerAlt on the original config?\n                        var longerAltConfig = patternIdxToConfig[longerAltIdx];\n                        var longerAltPattern = longerAltConfig.pattern;\n                        altPayload = null;\n                        // single Char can never be a longer alt so no need to test it.\n                        // manually in-lined because > 600 chars won't be in-lined in V8\n                        if (longerAltConfig.isCustom === true) {\n                            match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                            if (match !== null) {\n                                matchAltImage = match[0];\n                                if (match.payload !== undefined) {\n                                    altPayload = match.payload;\n                                }\n                            }\n                            else {\n                                matchAltImage = null;\n                            }\n                        }\n                        else {\n                            this.updateLastIndex(longerAltPattern, offset);\n                            matchAltImage = this.match(longerAltPattern, text, offset);\n                        }\n                        if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                            matchedImage = matchAltImage;\n                            payload = altPayload;\n                            currConfig = longerAltConfig;\n                        }\n                    }\n                    break;\n                }\n            }\n            // successful match\n            if (matchedImage !== null) {\n                imageLength = matchedImage.length;\n                group = currConfig.group;\n                if (group !== undefined) {\n                    tokType = currConfig.tokenTypeIdx;\n                    // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n                    // createFullToken method\n                    newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n                    this.handlePayload(newToken, payload);\n                    // TODO: optimize NOOP in case there are no special groups?\n                    if (group === false) {\n                        matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n                    }\n                    else {\n                        groups[group].push(newToken);\n                    }\n                }\n                text = this.chopInput(text, imageLength);\n                offset = offset + imageLength;\n                // TODO: with newlines the column may be assigned twice\n                column = this.computeNewColumn(column, imageLength);\n                if (trackLines === true && currConfig.canLineTerminator === true) {\n                    var numOfLTsInMatch = 0;\n                    var foundTerminator = void 0;\n                    var lastLTEndOffset = void 0;\n                    lineTerminatorPattern.lastIndex = 0;\n                    do {\n                        foundTerminator = lineTerminatorPattern.test(matchedImage);\n                        if (foundTerminator === true) {\n                            lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n                            numOfLTsInMatch++;\n                        }\n                    } while (foundTerminator === true);\n                    if (numOfLTsInMatch !== 0) {\n                        line = line + numOfLTsInMatch;\n                        column = imageLength - lastLTEndOffset;\n                        this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n                    }\n                }\n                // will be NOOP if no modes present\n                this.handleModes(currConfig, pop_mode, push_mode, newToken);\n            }\n            else {\n                // error recovery, drop characters until we identify a valid token's start point\n                var errorStartOffset = offset;\n                var errorLine = line;\n                var errorColumn = column;\n                var foundResyncPoint = false;\n                while (!foundResyncPoint && offset < orgLength) {\n                    // drop chars until we succeed in matching something\n                    droppedChar = orgText.charCodeAt(offset);\n                    // Identity Func (when sticky flag is enabled)\n                    text = this.chopInput(text, 1);\n                    offset++;\n                    for (j = 0; j < currModePatternsLength; j++) {\n                        var currConfig_1 = patternIdxToConfig[j];\n                        var currPattern = currConfig_1.pattern;\n                        // manually in-lined because > 600 chars won't be in-lined in V8\n                        var singleCharCode = currConfig_1.short;\n                        if (singleCharCode !== false) {\n                            if (orgText.charCodeAt(offset) === singleCharCode) {\n                                // single character string\n                                foundResyncPoint = true;\n                            }\n                        }\n                        else if (currConfig_1.isCustom === true) {\n                            foundResyncPoint =\n                                currPattern.exec(orgText, offset, matchedTokens, groups) !==\n                                    null;\n                        }\n                        else {\n                            this.updateLastIndex(currPattern, offset);\n                            foundResyncPoint = currPattern.exec(text) !== null;\n                        }\n                        if (foundResyncPoint === true) {\n                            break;\n                        }\n                    }\n                }\n                errLength = offset - errorStartOffset;\n                // at this point we either re-synced or reached the end of the input text\n                msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n                errors.push({\n                    offset: errorStartOffset,\n                    line: errorLine,\n                    column: errorColumn,\n                    length: errLength,\n                    message: msg\n                });\n            }\n        }\n        // if we do have custom patterns which push directly into the\n        // TODO: custom tokens should not push directly??\n        if (!this.hasCustom) {\n            // if we guessed a too large size for the tokens array this will shrink it to the right size.\n            matchedTokens.length = matchedTokensIndex;\n        }\n        return {\n            tokens: matchedTokens,\n            groups: groups,\n            errors: errors\n        };\n    };\n    Lexer.prototype.handleModes = function (config, pop_mode, push_mode, newToken) {\n        if (config.pop === true) {\n            // need to save the PUSH_MODE property as if the mode is popped\n            // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n            var pushMode = config.push;\n            pop_mode(newToken);\n            if (pushMode !== undefined) {\n                push_mode.call(this, pushMode);\n            }\n        }\n        else if (config.push !== undefined) {\n            push_mode.call(this, config.push);\n        }\n    };\n    Lexer.prototype.chopInput = function (text, length) {\n        return text.substring(length);\n    };\n    Lexer.prototype.updateLastIndex = function (regExp, newLastIndex) {\n        regExp.lastIndex = newLastIndex;\n    };\n    // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n    Lexer.prototype.updateTokenEndLineColumnLocation = function (newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n        var lastCharIsLT, fixForEndingInLT;\n        if (group !== undefined) {\n            // a none skipped multi line Token, need to update endLine/endColumn\n            lastCharIsLT = lastLTIdx === imageLength - 1;\n            fixForEndingInLT = lastCharIsLT ? -1 : 0;\n            if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n                // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n                newToken.endLine = line + fixForEndingInLT;\n                // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n                // inclusive to exclusive range.\n                newToken.endColumn = column - 1 + -fixForEndingInLT;\n            }\n            // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n        }\n    };\n    Lexer.prototype.computeNewColumn = function (oldColumn, imageLength) {\n        return oldColumn + imageLength;\n    };\n    // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n    /* istanbul ignore next - place holder */\n    Lexer.prototype.createTokenInstance = function () {\n        var args = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            args[_i] = arguments[_i];\n        }\n        return null;\n    };\n    Lexer.prototype.createOffsetOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType) {\n        return {\n            image: image,\n            startOffset: startOffset,\n            tokenTypeIdx: tokenTypeIdx,\n            tokenType: tokenType\n        };\n    };\n    Lexer.prototype.createStartOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n        return {\n            image: image,\n            startOffset: startOffset,\n            startLine: startLine,\n            startColumn: startColumn,\n            tokenTypeIdx: tokenTypeIdx,\n            tokenType: tokenType\n        };\n    };\n    Lexer.prototype.createFullToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n        return {\n            image: image,\n            startOffset: startOffset,\n            endOffset: startOffset + imageLength - 1,\n            startLine: startLine,\n            endLine: startLine,\n            startColumn: startColumn,\n            endColumn: startColumn + imageLength - 1,\n            tokenTypeIdx: tokenTypeIdx,\n            tokenType: tokenType\n        };\n    };\n    // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n    /* istanbul ignore next - place holder */\n    Lexer.prototype.addToken = function (tokenVector, index, tokenToAdd) {\n        return 666;\n    };\n    Lexer.prototype.addTokenUsingPush = function (tokenVector, index, tokenToAdd) {\n        tokenVector.push(tokenToAdd);\n        return index;\n    };\n    Lexer.prototype.addTokenUsingMemberAccess = function (tokenVector, index, tokenToAdd) {\n        tokenVector[index] = tokenToAdd;\n        index++;\n        return index;\n    };\n    // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\n    /* istanbul ignore next - place holder */\n    Lexer.prototype.handlePayload = function (token, payload) { };\n    Lexer.prototype.handlePayloadNoCustom = function (token, payload) { };\n    Lexer.prototype.handlePayloadWithCustom = function (token, payload) {\n        if (payload !== null) {\n            token.payload = payload;\n        }\n    };\n    /* istanbul ignore next - place holder to be replaced with chosen alternative at runtime */\n    Lexer.prototype.match = function (pattern, text, offset) {\n        return null;\n    };\n    Lexer.prototype.matchWithTest = function (pattern, text, offset) {\n        var found = pattern.test(text);\n        if (found === true) {\n            return text.substring(offset, pattern.lastIndex);\n        }\n        return null;\n    };\n    Lexer.prototype.matchWithExec = function (pattern, text) {\n        var regExpArray = pattern.exec(text);\n        return regExpArray !== null ? regExpArray[0] : regExpArray;\n    };\n    // Duplicated from the parser's perf trace trait to allow future extraction\n    // of the lexer to a separate package.\n    Lexer.prototype.TRACE_INIT = function (phaseDesc, phaseImpl) {\n        // No need to optimize this using NOOP pattern because\n        // It is not called in a hot spot...\n        if (this.traceInitPerf === true) {\n            this.traceInitIndent++;\n            var indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\n                console.log(indent + \"--> <\" + phaseDesc + \">\");\n            }\n            var _a = utils_1.timer(phaseImpl), time = _a.time, value = _a.value;\n            /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n            var traceMethod = time > 10 ? console.warn : console.log;\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\n                traceMethod(indent + \"<-- <\" + phaseDesc + \"> time: \" + time + \"ms\");\n            }\n            this.traceInitIndent--;\n            return value;\n        }\n        else {\n            return phaseImpl();\n        }\n    };\n    Lexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" +\n        \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n    Lexer.NA = /NOT_APPLICABLE/;\n    return Lexer;\n}());\nexports.Lexer = Lexer;\n//# sourceMappingURL=lexer_public.js.map\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$module$node_modules$chevrotain$lib$src$scan$reg_exp_parser","~$module$node_modules$$chevrotain$utils$lib$src$api","~$module$node_modules$chevrotain$lib$src$scan$tokens","~$module$node_modules$chevrotain$lib$src$scan$lexer","~$module$node_modules$chevrotain$lib$src$scan$lexer_errors_public","~$shadow.js"]],"~:properties",["^5",["addTokenUsingPush","message","lexerDefinitionWarning","createOffsetOnlyToken","tokenize","endColumn","hasCustom","config","offset","endLine","addToken","image","tokenizeInternal","patternIdxToConfig","updateLastIndex","__esModule","tokenType","positionTracking","createFullToken","lastIndex","traceInitIndent","errors","createTokenInstance","deferDefinitionErrorsHandling","endOffset","updateTokenEndLineColumnLocation","value","createStartOnlyToken","defaultMode","ensureOptimizations","startOffset","startLine","TRACE_INIT","tokenTypeIdx","trackEndLines","safeMode","matchWithTest","tracer","emptyGroups","length","lineTerminatorsPattern","computeNewColumn","line","lexerDefinitionErrors","column","startColumn","chopInput","handlePayload","charCodeToPatternIdxToConfig","match","lexerDefinition","handlePayloadNoCustom","LexerDefinitionErrorType","Lexer","modes","addTokenUsingMemberAccess","traceInitPerf","trackStartLines","canModeBeOptimized","matchWithExec","payload","errorMessageProvider","traceInitMaxIdent","handleModes","groups","handlePayloadWithCustom","lineTerminatorCharacters","skipValidations","SKIPPED","NA","tokens"]],"~:compiled-at",1630917515678,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$chevrotain$lib$src$scan$lexer_public.js\",\n\"lineCount\":35,\n\"mappings\":\"AAAAA,cAAA,CAAA,wDAAA,CAA6E,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAErHC,MAAOC,CAAAA,cAAP,CAAsBF,OAAtB,CAA+B,YAA/B,CAA6C,CAAEG,MAAO,CAAA,CAAT,CAA7C,CACAH,QAAQI,CAAAA,KAAR,CAAgBJ,OAAQK,CAAAA,wBAAxB,CAAmD,IAAK,EACxD,KAAIC,QAAUR,OAAA,CAAQ,mDAAR,CAAd,CACIS,QAAUT,OAAA,CAAQ,mDAAR,CADd,CAEIU,SAAWV,OAAA,CAAQ,oDAAR,CACXW,OAAAA,CAAwBX,OAAA,CAAQ,iEAAR,CAC5B;IAAIY,iBAAmBZ,OAAA,CAAQ,4DAAR,CAEtB,UAAS,CAACO,wBAAD,CAA2B,CACjCA,wBAAA,CAAyBA,wBAAA,CAAA,eAAzB,CAAuE,CAAvE,CAAA,CAA4E,iBAC5EA,yBAAA,CAAyBA,wBAAA,CAAA,eAAzB,CAAuE,CAAvE,CAAA,CAA4E,iBAC5EA,yBAAA,CAAyBA,wBAAA,CAAA,gBAAzB,CAAwE,CAAxE,CAAA,CAA6E,kBAC7EA,yBAAA,CAAyBA,wBAAA,CAAA,uBAAzB,CAA+E,CAA/E,CAAA,CAAoF,yBACpFA,yBAAA,CAAyBA,wBAAA,CAAA,wBAAzB;AAAgF,CAAhF,CAAA,CAAqF,0BACrFA,yBAAA,CAAyBA,wBAAA,CAAA,wBAAzB,CAAgF,CAAhF,CAAA,CAAqF,0BACrFA,yBAAA,CAAyBA,wBAAA,CAAA,wBAAzB,CAAgF,CAAhF,CAAA,CAAqF,0BACrFA,yBAAA,CAAyBA,wBAAA,CAAA,qCAAzB,CAA6F,CAA7F,CAAA,CAAkG,uCAClGA,yBAAA,CAAyBA,wBAAA,CAAA,uCAAzB,CAA+F,CAA/F,CAAA,CAAoG,yCACpGA;wBAAA,CAAyBA,wBAAA,CAAA,kDAAzB,CAA0G,CAA1G,CAAA,CAA+G,oDAC/GA,yBAAA,CAAyBA,wBAAA,CAAA,yCAAzB,CAAiG,EAAjG,CAAA,CAAuG,2CACvGA,yBAAA,CAAyBA,wBAAA,CAAA,gBAAzB,CAAwE,EAAxE,CAAA,CAA8E,kBAC9EA,yBAAA,CAAyBA,wBAAA,CAAA,mBAAzB,CAA2E,EAA3E,CAAA,CAAiF,qBACjFA,yBAAA,CAAyBA,wBAAA,CAAA,oBAAzB;AAA4E,EAA5E,CAAA,CAAkF,sBAClFA,yBAAA,CAAyBA,wBAAA,CAAA,mBAAzB,CAA2E,EAA3E,CAAA,CAAiF,qBACjFA,yBAAA,CAAyBA,wBAAA,CAAA,mBAAzB,CAA2E,EAA3E,CAAA,CAAiF,qBACjFA,yBAAA,CAAyBA,wBAAA,CAAA,iBAAzB,CAAyE,EAAzE,CAAA,CAA+E,mBAjB9C,CAApC,CAAD,CAkB8BL,OAAQK,CAAAA,wBAlBtC,GAkBmEL,OAAQK,CAAAA,wBAlB3E,CAkBsG,EAlBtG,EAmBA,KAAIM,qBAAuB,CACvBC,8BAA+B,CAAA,CADR,CAEvBC,iBAAkB,MAFK,CAGvBC,uBAAwB,WAHD;AAIvBC,yBAA0B,CAAC,IAAD,CAAO,IAAP,CAJH,CAKvBC,oBAAqB,CAAA,CALE,CAMvBC,SAAU,CAAA,CANa,CAOvBC,qBAAsBT,MAAsBU,CAAAA,yBAPrB,CAQvBC,cAAe,CAAA,CARQ,CASvBC,gBAAiB,CAAA,CATM,CAW3BpB,OAAOqB,CAAAA,MAAP,CAAcX,oBAAd,CACIP,QAAAA,CAAuB,QAAS,EAAG,CACnCA,QAASA,MAAK,CAACmB,eAAD,CAAkBC,MAAlB,CAA0B,CACpC,IAAIC,MAAQ,IACG,KAAK,EAApB,GAAID,MAAJ,GAAyBA,MAAzB,CAAkCb,oBAAlC,CACA,KAAKY,CAAAA,eAAL,CAAuBA,eACvB,KAAKG,CAAAA,qBAAL,CAA6B,EAC7B,KAAKC,CAAAA,sBAAL,CAA8B,EAC9B,KAAKC,CAAAA,kBAAL,CAA0B,EAC1B,KAAKC,CAAAA,4BAAL,CAAoC,EACpC,KAAKC,CAAAA,KAAL,CAAa,EACb,KAAKC,CAAAA,WAAL;AAAmB,EACnB,KAAKP,CAAAA,MAAL,CAAcQ,IAAAA,EAEd,KAAKC,CAAAA,aAAL,CADA,IAAKC,CAAAA,eACL,CADuB,CAAA,CAEvB,KAAKC,CAAAA,SAAL,CAAiB,CAAA,CACjB,KAAKC,CAAAA,kBAAL,CAA0B,EAC1B,IAAsB,SAAtB,GAAI,MAAOZ,OAAX,CACI,KAAMa,MAAA,CAAM,4HAAN,CAAN,CAIJ,IAAKb,CAAAA,MAAL,CAAcjB,OAAQ+B,CAAAA,KAAR,CAAc3B,oBAAd,CAAoCa,MAApC,CACd,KAAIe,aAAe,IAAKf,CAAAA,MAAOJ,CAAAA,aACV,EAAA,CAArB,GAAImB,YAAJ,EACI,IAAKC,CAAAA,iBACL,CADyBC,QACzB,CAAA,IAAKrB,CAAAA,aAAL,CAAqB,CAAA,CAFzB,EAIiC,QAJjC,GAIS,MAAOmB,aAJhB,GAKI,IAAKC,CAAAA,iBACL;AADyBD,YACzB,CAAA,IAAKnB,CAAAA,aAAL,CAAqB,CAAA,CANzB,CAQA,KAAKsB,CAAAA,eAAL,CAAuB,EACvB,KAAKC,CAAAA,UAAL,CAAgB,mBAAhB,CAAqC,QAAS,EAAG,CAC7C,IAAIC,gBAAJ,CACIC,kBAAoB,CAAA,CACxBpB,MAAMkB,CAAAA,UAAN,CAAiB,uBAAjB,CAA0C,QAAS,EAAG,CAClD,GAAIlB,KAAMD,CAAAA,MAAOV,CAAAA,sBAAjB,GACIH,oBAAqBG,CAAAA,sBADzB,CAGIW,KAAMD,CAAAA,MAAOV,CAAAA,sBAAb,CAAsCR,OAAQwC,CAAAA,6BAHlD,KAMI,IAAIrB,KAAMD,CAAAA,MAAOT,CAAAA,wBAAjB,GACIJ,oBAAqBI,CAAAA,wBADzB,CAEI,KAAMsB,MAAA,CAAM,wLAAN,CAAN;AAIR,GAAIb,MAAOP,CAAAA,QAAX,EAAuBO,MAAOR,CAAAA,mBAA9B,CACI,KAAMqB,MAAA,CAAM,oEAAN,CAAN,CAEJZ,KAAMS,CAAAA,eAAN,CAAwB,iBAAkBa,CAAAA,IAAlB,CAAuBtB,KAAMD,CAAAA,MAAOX,CAAAA,gBAApC,CACxBY,MAAMQ,CAAAA,aAAN,CAAsB,OAAQc,CAAAA,IAAR,CAAatB,KAAMD,CAAAA,MAAOX,CAAAA,gBAA1B,CAElBN,QAAQyC,CAAAA,OAAR,CAAgBzB,eAAhB,CAAJ,EACIqB,gBAEA,CAFmB,CAAEd,MAAO,EAAT,CAEnB,CADAc,gBAAiBd,CAAAA,KAAjB,CAAuBxB,OAAQ2C,CAAAA,YAA/B,CACA,CAD+C1C,OAAQ2C,CAAAA,QAAR,CAAiB3B,eAAjB,CAC/C,CAAAqB,gBAAA,CAAiBtC,OAAQ2C,CAAAA,YAAzB,CAAA,CAAyC3C,OAAQ2C,CAAAA,YAHrD,GAOIJ,iBACA,CADoB,CAAA,CACpB,CAAAD,gBAAA;AAAmBrC,OAAQ4C,CAAAA,QAAR,CAAiB5B,eAAjB,CARvB,CAnBkD,CAAtD,CA8BqC,EAAA,CAArC,GAAIE,KAAMD,CAAAA,MAAOH,CAAAA,eAAjB,GACII,KAAMkB,CAAAA,UAAN,CAAiB,sBAAjB,CAAyC,QAAS,EAAG,CACjDlB,KAAMC,CAAAA,qBAAN,CAA8BD,KAAMC,CAAAA,qBAAsB0B,CAAAA,MAA5B,CAAmC9C,OAAQ+C,CAAAA,oBAAR,CAA6BT,gBAA7B,CAA+CnB,KAAMS,CAAAA,eAArD,CAAsET,KAAMD,CAAAA,MAAOT,CAAAA,wBAAnF,CAAnC,CADmB,CAArD,CAGA,CAAAU,KAAMkB,CAAAA,UAAN,CAAiB,6BAAjB,CAAgD,QAAS,EAAG,CACxDlB,KAAME,CAAAA,sBAAN,CAA+BF,KAAME,CAAAA,sBAAuByB,CAAAA,MAA7B,CAAoC9C,OAAQgD,CAAAA,2BAAR,CAAoCV,gBAApC,CAAsDnB,KAAMS,CAAAA,eAA5D,CAA6ET,KAAMD,CAAAA,MAAOT,CAAAA,wBAA1F,CAApC,CADyB,CAA5D,CAJJ,CASA6B;gBAAiBd,CAAAA,KAAjB,CAAyBc,gBAAiBd,CAAAA,KAAjB,CACnBc,gBAAiBd,CAAAA,KADE,CAEnB,EAGNvB,QAAQgD,CAAAA,OAAR,CAAgBX,gBAAiBd,CAAAA,KAAjC,CAAwC,QAAS,CAAC0B,aAAD,CAAgBC,YAAhB,CAA8B,CAC3Eb,gBAAiBd,CAAAA,KAAjB,CAAuB2B,YAAvB,CAAA,CAAuClD,OAAQmD,CAAAA,MAAR,CAAeF,aAAf,CAA8B,QAAS,CAACG,WAAD,CAAc,CAAE,MAAOpD,QAAQqD,CAAAA,WAAR,CAAoBD,WAApB,CAAT,CAArD,CADoC,CAA/E,CAGA,KAAIE,aAAetD,OAAQuD,CAAAA,IAAR,CAAalB,gBAAiBd,CAAAA,KAA9B,CACnBvB,QAAQgD,CAAAA,OAAR,CAAgBX,gBAAiBd,CAAAA,KAAjC,CAAwC,QAAS,CAACiC,UAAD,CAAaC,WAAb,CAA0B,CACvEvC,KAAMkB,CAAAA,UAAN,CAAiB,YAAjB,CAA6BqB,WAA7B,CAA2C,iBAA3C,CAA2D,QAAS,EAAG,CACnEvC,KAAMK,CAAAA,KAAMmC,CAAAA,IAAZ,CAAiBD,WAAjB,CACqC;CAAA,CAArC,GAAIvC,KAAMD,CAAAA,MAAOH,CAAAA,eAAjB,EACII,KAAMkB,CAAAA,UAAN,CAAiB,kBAAjB,CAAqC,QAAS,EAAG,CAC7ClB,KAAMC,CAAAA,qBAAN,CAA8BD,KAAMC,CAAAA,qBAAsB0B,CAAAA,MAA5B,CAAmC9C,OAAQ4D,CAAAA,gBAAR,CAAyBH,UAAzB,CAAqCF,YAArC,CAAnC,CADe,CAAjD,CAOJ,IAAItD,OAAQ4D,CAAAA,OAAR,CAAgB1C,KAAMC,CAAAA,qBAAtB,CAAJ,CAAkD,CAC9ClB,QAAS4D,CAAAA,iBAAT,CAA2BL,UAA3B,CACA,KAAIM,mBACJ5C,MAAMkB,CAAAA,UAAN,CAAiB,mBAAjB,CAAsC,QAAS,EAAG,CAC9C0B,mBAAA,CAAsB/D,OAAQgE,CAAAA,iBAAR,CAA0BP,UAA1B,CAAsC,CACxDhD,yBAA0BU,KAAMD,CAAAA,MAC3BT,CAAAA,wBAFmD,CAGxDF,iBAAkBW,MAAOX,CAAAA,gBAH+B;AAIxDG,oBAAqBQ,MAAOR,CAAAA,mBAJ4B,CAKxDC,SAAUO,MAAOP,CAAAA,QALuC,CAMxDsD,OAAQ9C,KAAMkB,CAAAA,UAAW6B,CAAAA,IAAjB,CAAsB/C,KAAtB,CANgD,CAAtC,CADwB,CAAlD,CAUAA,MAAMG,CAAAA,kBAAN,CAAyBoC,WAAzB,CAAA,CACIK,mBAAoBzC,CAAAA,kBACxBH,MAAMI,CAAAA,4BAAN,CAAmCmC,WAAnC,CAAA,CACIK,mBAAoBxC,CAAAA,4BACxBJ,MAAMM,CAAAA,WAAN,CAAoBxB,OAAQ+B,CAAAA,KAAR,CAAcb,KAAMM,CAAAA,WAApB,CAAiCsC,mBAAoBtC,CAAAA,WAArD,CACpBN,MAAMU,CAAAA,SAAN,CAAkBkC,mBAAoBlC,CAAAA,SAAtC,EAAmDV,KAAMU,CAAAA,SACzDV,MAAMW,CAAAA,kBAAN,CAAyB4B,WAAzB,CAAA,CACIK,mBAAoBI,CAAAA,cApBsB,CAViB,CAAvE,CADuE,CAA3E,CAmCAhD;KAAMiD,CAAAA,WAAN,CAAoB9B,gBAAiB8B,CAAAA,WACrC,IAAI,CAACnE,OAAQ4D,CAAAA,OAAR,CAAgB1C,KAAMC,CAAAA,qBAAtB,CAAL,EACI,CAACD,KAAMD,CAAAA,MAAOZ,CAAAA,6BADlB,CACiD,CAI7C,IAAI+D,qBAHiBpE,OAAQqE,CAAAA,GAARC,CAAYpD,KAAMC,CAAAA,qBAAlBmD,CAAyC,QAAS,CAACC,KAAD,CAAQ,CAC3E,MAAOA,MAAMC,CAAAA,OAD8D,CAA1DF,CAGqBG,CAAAA,IAAf,CAAoB,2BAApB,CAC3B,MAAU3C,MAAJ,CAAU,2CAAV,CAAwDsC,oBAAxD,CAAN,CAL6C,CAQjDpE,OAAQgD,CAAAA,OAAR,CAAgB9B,KAAME,CAAAA,sBAAtB,CAA8C,QAAS,CAACsD,iBAAD,CAAoB,CACvE1E,OAAQ2E,CAAAA,aAAR,CAAsBD,iBAAkBF,CAAAA,OAAxC,CADuE,CAA3E,CAGAtD,MAAMkB,CAAAA,UAAN,CAAiB,sCAAjB;AAAyD,QAAS,EAAG,CAI7DrC,OAAQ6E,CAAAA,cAAZ,EACI1D,KAAM2D,CAAAA,SACN,CADkB7E,OAAQ8E,CAAAA,QAC1B,CAAA5D,KAAM6D,CAAAA,KAAN,CAAc7D,KAAM8D,CAAAA,aAFxB,GAKI9D,KAAM+D,CAAAA,eACN,CADwBjF,OAAQkF,CAAAA,IAChC,CAAAhE,KAAM6D,CAAAA,KAAN,CAAc7D,KAAMiE,CAAAA,aANxB,CAQI7C,kBAAJ,GACIpB,KAAMkE,CAAAA,WADV,CACwBpF,OAAQkF,CAAAA,IADhC,CAG8B,EAAA,CAA9B,GAAIhE,KAAMS,CAAAA,eAAV,GACIT,KAAMmE,CAAAA,gBADV,CAC6BrF,OAAQ8E,CAAAA,QADrC,CAG4B,EAAA,CAA5B,GAAI5D,KAAMQ,CAAAA,aAAV,GACIR,KAAMoE,CAAAA,gCADV,CAC6CtF,OAAQkF,CAAAA,IADrD,CAGA,IAAI,OAAQ1C,CAAAA,IAAR,CAAatB,KAAMD,CAAAA,MAAOX,CAAAA,gBAA1B,CAAJ,CACIY,KAAMqE,CAAAA,mBAAN,CAA4BrE,KAAMsE,CAAAA,eADtC,KAGK,IAAI,YAAahD,CAAAA,IAAb,CAAkBtB,KAAMD,CAAAA,MAAOX,CAAAA,gBAA/B,CAAJ,CACDY,KAAMqE,CAAAA,mBAAN;AAA4BrE,KAAMuE,CAAAA,oBADjC,KAGA,IAAI,aAAcjD,CAAAA,IAAd,CAAmBtB,KAAMD,CAAAA,MAAOX,CAAAA,gBAAhC,CAAJ,CACDY,KAAMqE,CAAAA,mBAAN,CAA4BrE,KAAMwE,CAAAA,qBADjC,KAID,MAAM5D,MAAA,CAAM,mDAAN,CAAuDZ,KAAMD,CAAAA,MAAOX,CAAAA,gBAApE,CAAuF,GAAvF,CAAN,CAEAY,KAAMU,CAAAA,SAAV,EACIV,KAAMyE,CAAAA,QACN,CADiBzE,KAAM0E,CAAAA,iBACvB,CAAA1E,KAAM2E,CAAAA,aAAN,CAAsB3E,KAAM4E,CAAAA,uBAFhC,GAKI5E,KAAMyE,CAAAA,QACN,CADiBzE,KAAM6E,CAAAA,yBACvB,CAAA7E,KAAM2E,CAAAA,aAAN,CAAsB3E,KAAM8E,CAAAA,qBANhC,CAjCiE,CAArE,CA0CA9E,MAAMkB,CAAAA,UAAN,CAAiB,8BAAjB,CAAiD,QAAS,EAAG,CACzD,IAAI6D;AAAmBjG,OAAQkG,CAAAA,MAAR,CAAehF,KAAMW,CAAAA,kBAArB,CAAyC,QAAS,CAACsE,iBAAD,CAAoBjC,cAApB,CAAoCkC,QAApC,CAA8C,CAC5F,CAAA,CAAvB,GAAIlC,cAAJ,EACIiC,iBAAkBzC,CAAAA,IAAlB,CAAuB0C,QAAvB,CAEJ,OAAOD,kBAJ4G,CAAhG,CAKpB,EALoB,CAMvB,IAAIlF,MAAOR,CAAAA,mBAAX,EAAkC,CAACT,OAAQ4D,CAAAA,OAAR,CAAgBqC,gBAAhB,CAAnC,CACI,KAAMnE,MAAA,CAAM,oBAAN,CAA0BmE,gBAAiBxB,CAAAA,IAAjB,CAAsB,IAAtB,CAA1B,CAAwD,kOAAxD,CAAN;AARqD,CAA7D,CAaAvD,MAAMkB,CAAAA,UAAN,CAAiB,wBAAjB,CAA2C,QAAS,EAAG,CACnDjC,gBAAiBkG,CAAAA,sBAAjB,EADmD,CAAvD,CAGAnF,MAAMkB,CAAAA,UAAN,CAAiB,kBAAjB,CAAqC,QAAS,EAAG,CAC7CpC,OAAQsG,CAAAA,gBAAR,CAAyBpF,KAAzB,CAD6C,CAAjD,CA7J6C,CAAjD,CA/BoC,CAiMxCrB,KAAM0G,CAAAA,SAAUC,CAAAA,QAAhB,CAA2BC,QAAS,CAACC,IAAD,CAAOC,WAAP,CAAoB,CAChC,IAAK,EAAzB,GAAIA,WAAJ,GAA8BA,WAA9B,CAA4C,IAAKxC,CAAAA,WAAjD,CACA,IAAI,CAACnE,OAAQ4D,CAAAA,OAAR,CAAgB,IAAKzC,CAAAA,qBAArB,CAAL,CAKI,KADIiD,KACE,CAJepE,OAAQqE,CAAAA,GAARC,CAAY,IAAKnD,CAAAA,qBAAjBmD,CAAwC,QAAS,CAACC,KAAD,CAAQ,CAC1E,MAAOA,MAAMC,CAAAA,OAD6D,CAAzDF,CAGqBG,CAAAA,IAAf,CAAoB,2BAApB,CACrB,CAAI3C,KAAJ,CAAU,sEAAV;AACFsC,IADE,CAAN,CAIJ,MADgB,KAAKwC,CAAAA,gBAALC,CAAsBH,IAAtBG,CAA4BF,WAA5BE,CAVoC,CAexDhH,MAAM0G,CAAAA,SAAUK,CAAAA,gBAAhB,CAAmCE,QAAS,CAACJ,IAAD,CAAOC,WAAP,CAAoB,CA4B5DI,QAASA,wBAAuB,EAAG,CAC/B,MAAO1F,mBADwB,CAGnC2F,QAASA,6BAA4B,CAACC,QAAD,CAAW,CACxCC,QAAAA,CAAmBnH,OAAQoH,CAAAA,wBAAR,CAAiCF,QAAjC,CACnBG,SAAAA,CAAmBC,gCAAA,CAAiCH,QAAjC,CACvB,OAAyBzF,KAAAA,EAAzB,GAAI2F,QAAJ,CACWE,UADX,CAIWF,QAPiC,CA4ChDG,QAASA,UAAS,CAACC,OAAD,CAAU,CACxBC,SAAU/D,CAAAA,IAAV,CAAe8D,OAAf,CACAH,iCAAA,CAAmC,IAAK/F,CAAAA,4BAAL,CAAkCkG,OAAlC,CACnCnG,mBAAA;AAAqB,IAAKA,CAAAA,kBAAL,CAAwBmG,OAAxB,CAErBE,uBAAA,CADAA,sBACA,CADyBrG,kBAAmBsG,CAAAA,MAExCC,QAAAA,CAAqB,IAAK/F,CAAAA,kBAAL,CAAwB2F,OAAxB,CAArBI,EAAkF,CAAA,CAAlFA,GAAyD,IAAK3G,CAAAA,MAAOP,CAAAA,QAErEmH,oBAAA,CADAR,gCAAJ,EAAwCO,OAAxC,CAC0BZ,4BAD1B,CAI0BD,uBAXF,CA1E5B,IAAI7F,MAAQ,IAAZ,CACI4G,CADJ,CAEIC,QAAUrB,IAFd,CAGIsB,UAAYD,OAAQJ,CAAAA,MAHxB,CAIIM,OAAS,CAJb,CAKIC,mBAAqB,CALzB,CAaIC,cAAoBC,KAAJ,CAHQ,IAAKxG,CAAAA,SAALyG,CACtB,CADsBA,CAEtBC,IAAKC,CAAAA,KAAL,CAAW7B,IAAKiB,CAAAA,MAAhB,CAAyB,EAAzB,CACc,CAbpB,CAcIa,OAAS,EAdb,CAeIC,KAAO,IAAK9G,CAAAA,eAAL,CAAuB,CAAvB,CAA2BF,IAAAA,EAftC,CAgBIiH,OAAS,IAAK/G,CAAAA,eAAL;AAAuB,CAAvB,CAA2BF,IAAAA,EAhBxC,CAiBIkH,OAAS5I,OAAQ6I,CAAAA,gBAAR,CAAyB,IAAKpH,CAAAA,WAA9B,CAjBb,CAkBIqH,WAAa,IAAKlH,CAAAA,eAlBtB,CAmBImH,sBAAwB,IAAK7H,CAAAA,MAAOV,CAAAA,sBAnBxC,CAoBImH,uBAAyB,CApB7B,CAqBIrG,mBAAqB,EArBzB,CAsBIgG,iCAAmC,EAtBvC,CAuBII,UAAY,EAvBhB,CAwBIH,WAAa,EACjB5H,OAAOqB,CAAAA,MAAP,CAAcuG,UAAd,CACA,KAAIO,oBAAsBpG,IAAAA,EAA1B,CAcIsH,SAAWA,QAAS,CAACC,QAAD,CAAW,CAE/B,GAAyB,CAAzB,GAAIvB,SAAUE,CAAAA,MAAd,EAGqClG,IAAAA,EAHrC,GAGIuH,QAASC,CAAAA,SAAUC,CAAAA,SAHvB,CAGgD,CAG5C,IAAIC,MAAQjI,KAAMD,CAAAA,MAAON,CAAAA,oBAAqByI,CAAAA,gCAAlC,CAAmEJ,QAAnE,CACZR,OAAO9E,CAAAA,IAAP,CAAY,CACRuE,OAAQe,QAASK,CAAAA,WADT;AAERZ,KAA6BhH,IAAAA,EAAvB,GAAAuH,QAASM,CAAAA,SAAT,CAAmCN,QAASM,CAAAA,SAA5C,CAAwD7H,IAAAA,EAFtD,CAGRiH,OAAiCjH,IAAAA,EAAzB,GAAAuH,QAASO,CAAAA,WAAT,CACFP,QAASO,CAAAA,WADP,CAEF9H,IAAAA,EALE,CAMRkG,OAAQqB,QAASQ,CAAAA,KAAM7B,CAAAA,MANf,CAORnD,QAAS2E,KAPD,CAAZ,CAJ4C,CAHhD,IAkBI1B,UAAUgC,CAAAA,GAAV,EAOI,CANAjC,QAMA,CANUxH,OAAQ0J,CAAAA,IAAR,CAAajC,SAAb,CAMV,CALJpG,kBAKI,CALiBH,KAAMG,CAAAA,kBAAN,CAAyBmG,QAAzB,CAKjB,CAJJH,gCAII,CAJ+BnG,KAAMI,CAAAA,4BAAN,CAAmCkG,QAAnC,CAI/B,CAHJE,sBAGI,CAHqBrG,kBAAmBsG,CAAAA,MAGxC,CAFAC,QAEA,CAFqB1G,KAAMW,CAAAA,kBAAN,CAAyB2F,QAAzB,CAErB,EAFoF,CAAA,CAEpF,GAF0DtG,KAAMD,CAAAA,MAAOP,CAAAA,QAEvE,CAAAmH,mBAAA,CADAR,gCAAJ;AAAwCO,QAAxC,CAC0BZ,4BAD1B,CAI0BD,uBA9BC,CAkDnCQ,UAAUoC,CAAAA,IAAV,CAAe,IAAf,CAAqBhD,WAArB,CAEA,KADA,IAAIiD,UACJ,CAAO3B,MAAP,CAAgBD,SAAhB,CAAA,CAA2B,CACvB6B,WAAA,CAAe,IACXC,KAAAA,cAAe/B,OAAQgC,CAAAA,UAAR,CAAmB9B,MAAnB,CACf+B,KAAAA,EAA2BnC,mBAAA,CAAoBiC,aAApB,CAC/B,KAAIG,qBAAuBD,CAAyBrC,CAAAA,MACpD,KAAKG,CAAL,CAAS,CAAT,CAAYA,CAAZ,CAAgBmC,oBAAhB,CAAsCnC,CAAA,EAAtC,CAA2C,CACvC8B,UAAA,CAAaI,CAAA,CAAyBlC,CAAzB,CACToC,KAAAA,aAAcN,UAAWO,CAAAA,OAC7B,KAAAC,QAAU,IAENC,KAAAA,WAAiBT,UAAWU,CAAAA,KACT,EAAA,CAAvB,GAAID,UAAJ,CACQP,aADR,GACyBO,UADzB,GAGQR,WAHR,CAGuBK,YAHvB,EAMiC,CAAA,CAA5B,GAAIN,UAAWW,CAAAA,QAAf;CACDxF,YACA,CADQmF,YAAYM,CAAAA,IAAZ,CAAiBzC,OAAjB,CAA0BE,MAA1B,CAAkCE,aAAlC,CAAiDQ,MAAjD,CACR,CAAc,IAAd,GAAI5D,YAAJ,EACI8E,WACA,CADe9E,YAAA,CAAM,CAAN,CACf,CAAsBtD,IAAAA,EAAtB,GAAIsD,YAAMqF,CAAAA,OAAV,GACIA,OADJ,CACcrF,YAAMqF,CAAAA,OADpB,CAFJ,EAOIP,WAPJ,CAOmB,IATlB,GAaD,IAAK5E,CAAAA,eAAL,CAAqBiF,YAArB,CAAkCjC,MAAlC,CACA,CAAA4B,WAAA,CAAe,IAAK9E,CAAAA,KAAL,CAAWmF,YAAX,CAAwBxD,IAAxB,CAA8BuB,MAA9B,CAdd,CAgBL,IAAqB,IAArB,GAAI4B,WAAJ,CAA2B,CAGvBY,YAAA,CAAeb,UAAWc,CAAAA,SACLjJ,KAAAA,EAArB,GAAIgJ,YAAJ,GAGQE,CAqBJ,CArBsBtJ,kBAAA,CAAmBoJ,YAAnB,CAqBtB,CApBIG,YAoBJ,CApBuBD,CAAgBR,CAAAA,OAoBvC,CAnBAU,UAmBA,CAnBa,IAmBb,CAhBiC,CAAA,CAAjC,GAAIF,CAAgBJ,CAAAA,QAApB,EACIxF,YACA,CADQ6F,YAAiBJ,CAAAA,IAAjB,CAAsBzC,OAAtB;AAA+BE,MAA/B,CAAuCE,aAAvC,CAAsDQ,MAAtD,CACR,CAAc,IAAd,GAAI5D,YAAJ,EACI+F,aACA,CADgB/F,YAAA,CAAM,CAAN,CAChB,CAAsBtD,IAAAA,EAAtB,GAAIsD,YAAMqF,CAAAA,OAAV,GACIS,UADJ,CACiB9F,YAAMqF,CAAAA,OADvB,CAFJ,EAOIU,aAPJ,CAOoB,IATxB,GAaI,IAAK7F,CAAAA,eAAL,CAAqB2F,YAArB,CAAuC3C,MAAvC,CACA,CAAA6C,aAAA,CAAgB,IAAK/F,CAAAA,KAAL,CAAW6F,YAAX,CAA6BlE,IAA7B,CAAmCuB,MAAnC,CAdpB,CAgBA,CAAI6C,aAAJ,EAAqBA,aAAcnD,CAAAA,MAAnC,CAA4CkC,WAAalC,CAAAA,MAAzD,GACIkC,WAEA,CAFeiB,aAEf,CADAV,OACA,CADUS,UACV,CAAAjB,UAAA,CAAae,CAHjB,CAxBJ,CA8BA,MAlCuB,CA5BY,CAkE3C,GAAqB,IAArB,GAAId,WAAJ,CAA2B,CACvBkB,YAAA,CAAclB,WAAalC,CAAAA,MAC3BqD,WAAA,CAAQpB,UAAWoB,CAAAA,KACnB,IAAcvJ,IAAAA,EAAd,GAAIuJ,UAAJ,CAAyB,CACrB,IAAAC;AAAUrB,UAAWsB,CAAAA,YAGrBC,QAAA,CAAW,IAAK5F,CAAAA,mBAAL,CAAyBsE,WAAzB,CAAuC5B,MAAvC,CAA+CgD,OAA/C,CAAwDrB,UAAWX,CAAAA,SAAnE,CAA8ER,IAA9E,CAAoFC,MAApF,CAA4FqC,YAA5F,CACX,KAAKlF,CAAAA,aAAL,CAAmBsF,OAAnB,CAA6Bf,OAA7B,CAEc,EAAA,CAAd,GAAIY,UAAJ,CACI9C,kBADJ,CACyB,IAAKvC,CAAAA,QAAL,CAAcwC,aAAd,CAA6BD,kBAA7B,CAAiDiD,OAAjD,CADzB,CAIIxC,MAAA,CAAOqC,UAAP,CAActH,CAAAA,IAAd,CAAmByH,OAAnB,CAXiB,CAczBzE,IAAA,CAAO,IAAK7B,CAAAA,SAAL,CAAe6B,IAAf,CAAqBqE,YAArB,CACE9C,OAAT,EAAkB8C,YAElBrC,OAAA,CAAS,IAAKrD,CAAAA,gBAAL,CAAsBqD,MAAtB,CAA8BqC,YAA9B,CACT,IAAmB,CAAA,CAAnB,GAAIlC,UAAJ,EAA4D,CAAA,CAA5D,GAA2Be,UAAWwB,CAAAA,iBAAtC,CAAkE,CAC1DC,CAAAA,CAAkB,CAElBC,EAAAA,CADAC,aACAD,CADkB,IAAK,EAE3BxC,sBAAsB0C,CAAAA,SAAtB;AAAkC,CAClC,GACID,cACA,CADkBzC,qBAAsBtG,CAAAA,IAAtB,CAA2BqH,WAA3B,CAClB,CAAwB,CAAA,CAAxB,GAAI0B,aAAJ,GACID,CACA,CADkBxC,qBAAsB0C,CAAAA,SACxC,CADoD,CACpD,CAAAH,CAAA,EAFJ,CAFJ,OAM6B,CAAA,CAN7B,GAMSE,aANT,CAOwB,EAAxB,GAAIF,CAAJ,GACW5C,IAEP,EAFc4C,CAEd,CADA3C,MACA,CADSqC,YACT,CADuBO,CACvB,CAAA,IAAKhG,CAAAA,gCAAL,CAAsC6F,OAAtC,CAAgDH,UAAhD,CAAuDM,CAAvD,CAAwED,CAAxE,CAAyF5C,IAAzF,CAA+FC,MAA/F,CAAuGqC,YAAvG,CAHJ,CAZ8D,CAmBlE,IAAK3F,CAAAA,WAAL,CAAiBwE,UAAjB,CAA6Bb,QAA7B,CAAuCxB,SAAvC,CAAkD4D,OAAlD,CAxCuB,CAA3B,IA0CK,CAEGM,WAAAA,CAAmBxD,MACnByD,EAAAA,CAAYjD,IACZkD,cAAAA,CAAcjD,MAElB,KADIkD,oBACJ,CADuB,CAAA,CACvB,CAAO,CAACA,oBAAR,EAA4B3D,MAA5B,CAAqCD,SAArC,CAAA,CAMI,IAJcD,OAAQgC,CAAAA,UAAR,CAAmB9B,MAAnB,CAIT,CAFLvB,IAEK,CAFE,IAAK7B,CAAAA,SAAL,CAAe6B,IAAf;AAAqB,CAArB,CAEF,CADLuB,MAAA,EACK,CAAA4D,CAAA,CAAI,CAAT,CAAYA,CAAZ,CAAgBnE,sBAAhB,CAAwCmE,CAAA,EAAxC,CAA6C,CACzC,IAAIC,aAAezK,kBAAA,CAAmBwK,CAAnB,CACf3B,aAAJ,CAAkB4B,YAAa3B,CAAAA,OAE3BE,WAAJ,CAAqByB,YAAaxB,CAAAA,KACX,EAAA,CAAvB,GAAID,UAAJ,CACQtC,OAAQgC,CAAAA,UAAR,CAAmB9B,MAAnB,CADR,GACuCoC,UADvC,GAGQuB,oBAHR,CAG2B,CAAA,CAH3B,EAMmC,CAAA,CAA9B,GAAIE,YAAavB,CAAAA,QAAjB,CACDqB,oBADC,CAGO,IAHP,GAEG1B,YAAYM,CAAAA,IAAZ,CAAiBzC,OAAjB,CAA0BE,MAA1B,CAAkCE,aAAlC,CAAiDQ,MAAjD,CAFH,EAMD,IAAK1D,CAAAA,eAAL,CAAqBiF,YAArB,CAAkCjC,MAAlC,CACA,CAAA2D,oBAAA,CAA8C,IAA9C,GAAmB1B,YAAYM,CAAAA,IAAZ,CAAiB9D,IAAjB,CAPlB,CASL,IAAyB,CAAA,CAAzB,GAAIkF,oBAAJ,CACI,KArBqC,CAyBjDG,YAAA,CAAY9D,MAAZ,CAAqBwD,WAErBO;UAAA,CAAM,IAAK/K,CAAAA,MAAON,CAAAA,oBAAqBsL,CAAAA,gCAAjC,CAAkElE,OAAlE,CAA2E0D,WAA3E,CAA6FM,YAA7F,CAAwGL,CAAxG,CAAmHC,aAAnH,CACNnD,OAAO9E,CAAAA,IAAP,CAAY,CACRuE,OAAQwD,WADA,CAERhD,KAAMiD,CAFE,CAGRhD,OAAQiD,aAHA,CAIRhE,OAAQoE,YAJA,CAKRvH,QAASwH,UALD,CAAZ,CAxCC,CAjHkB,CAoKtB,IAAKpK,CAAAA,SAAV,GAEIuG,aAAcR,CAAAA,MAFlB,CAE2BO,kBAF3B,CAIA,OAAO,CACHgE,OAAQ/D,aADL,CAEKQ,MAFL,CAGKH,MAHL,CArQqD,CA2QhE3I,MAAM0G,CAAAA,SAAUnB,CAAAA,WAAhB,CAA8B+G,QAAS,CAAClL,MAAD,CAAS8H,QAAT,CAAmBxB,SAAnB,CAA8B4D,QAA9B,CAAwC,CACxD,CAAA,CAAnB,GAAIlK,MAAOwI,CAAAA,GAAX,EAGQ2C,MAEJ,CAFenL,MAAOyC,CAAAA,IAEtB,CADAqF,QAAA,CAASoC,QAAT,CACA,CAAiB1J,IAAAA,EAAjB,GAAI2K,MAAJ,EACI7E,SAAUoC,CAAAA,IAAV,CAAe,IAAf,CAAqByC,MAArB,CANR;AASyB3K,IAAAA,EATzB,GASSR,MAAOyC,CAAAA,IAThB,EAUI6D,SAAUoC,CAAAA,IAAV,CAAe,IAAf,CAAqB1I,MAAOyC,CAAAA,IAA5B,CAXuE,CAc/E7D,MAAM0G,CAAAA,SAAU1B,CAAAA,SAAhB,CAA4BwH,QAAS,CAAC3F,IAAD,CAAOiB,MAAP,CAAe,CAChD,MAAOjB,KAAK4F,CAAAA,SAAL,CAAe3E,MAAf,CADyC,CAGpD9H,MAAM0G,CAAAA,SAAUtB,CAAAA,eAAhB,CAAkCsH,QAAS,CAACC,MAAD,CAASC,YAAT,CAAuB,CAC9DD,MAAOhB,CAAAA,SAAP,CAAmBiB,YAD2C,CAIlE5M,MAAM0G,CAAAA,SAAUjB,CAAAA,gCAAhB,CAAmDoH,QAAS,CAACvB,QAAD,CAAWH,KAAX,CAAkB2B,SAAlB,CAA6BtB,eAA7B,CAA8C5C,IAA9C,CAAoDC,MAApD,CAA4DqC,WAA5D,CAAyE,CAEnHtJ,IAAAA,EAAd,GAAIuJ,KAAJ,GAGI4B,SACM,CADa,CADnBC,KACmB,CADJF,SACI,GADU5B,WACV,CADwB,CACxB,EAAe,EAAf,CAAoB,CACjC,CAAoB,CAApB,GAAAM,eAAA,EAA0C,CAAA,CAA1C,GAAyBwB,KAJnC,IAMQ1B,QAAS2B,CAAAA,OAGT,CAHmBrE,IAGnB,CAH0BmE,SAG1B,CAAAzB,QAAS4B,CAAAA,SAAT;AAAqBrE,MAArB,CAA8B,CAA9B,CAAkC,CAACkE,SAT3C,CAFiI,CAgBrI/M,MAAM0G,CAAAA,SAAUlB,CAAAA,gBAAhB,CAAmC2H,QAAS,CAACC,SAAD,CAAYlC,WAAZ,CAAyB,CACjE,MAAOkC,UAAP,CAAmBlC,WAD8C,CAKrElL,MAAM0G,CAAAA,SAAUhB,CAAAA,mBAAhB,CAAsC2H,QAAS,EAAG,CAE9C,IAAK,IAAIC,GAAK,CAAd,CAAiBA,EAAjB,CAAsBC,SAAUzF,CAAAA,MAAhC,CAAwCwF,EAAA,EAAxC,EAGA,MAAO,KALuC,CAOlDtN,MAAM0G,CAAAA,SAAUb,CAAAA,qBAAhB,CAAwC2H,QAAS,CAAC7D,KAAD,CAAQH,WAAR,CAAqB6B,YAArB,CAAmCjC,SAAnC,CAA8C,CAC3F,MAAO,CACIO,KADJ,CAEUH,WAFV,CAGW6B,YAHX,CAIQjC,SAJR,CADoF,CAQ/FpJ,MAAM0G,CAAAA,SAAUd,CAAAA,oBAAhB,CAAuC6H,QAAS,CAAC9D,KAAD,CAAQH,WAAR,CAAqB6B,YAArB,CAAmCjC,SAAnC,CAA8CK,SAA9C,CAAyDC,WAAzD,CAAsE,CAClH,MAAO,CACIC,KADJ,CAEUH,WAFV,CAGQC,SAHR,CAIUC,WAJV;AAKW2B,YALX,CAMQjC,SANR,CAD2G,CAUtHpJ,MAAM0G,CAAAA,SAAUf,CAAAA,eAAhB,CAAkC+H,QAAS,CAAC/D,KAAD,CAAQH,WAAR,CAAqB6B,YAArB,CAAmCjC,SAAnC,CAA8CK,SAA9C,CAAyDC,WAAzD,CAAsEwB,WAAtE,CAAmF,CAC1H,MAAO,CACIvB,KADJ,CAEUH,WAFV,CAGHmE,UAAWnE,WAAXmE,CAAyBzC,WAAzByC,CAAuC,CAHpC,CAIQlE,SAJR,CAKHwD,QAASxD,SALN,CAMUC,WANV,CAOHwD,UAAWxD,WAAXwD,CAAyBhC,WAAzBgC,CAAuC,CAPpC,CAQW7B,YARX,CASQjC,SATR,CADmH,CAe9HpJ,MAAM0G,CAAAA,SAAUZ,CAAAA,QAAhB,CAA2B8H,QAAS,CAACC,WAAD,CAAcC,KAAd,CAAqBC,UAArB,CAAiC,CACjE,MAAO,IAD0D,CAGrE/N,MAAM0G,CAAAA,SAAUX,CAAAA,iBAAhB,CAAoCiI,QAAS,CAACH,WAAD,CAAcC,KAAd,CAAqBC,UAArB,CAAiC,CAC1EF,WAAYhK,CAAAA,IAAZ,CAAiBkK,UAAjB,CACA,OAAOD,MAFmE,CAI9E9N,MAAM0G,CAAAA,SAAUR,CAAAA,yBAAhB;AAA4C+H,QAAS,CAACJ,WAAD,CAAcC,KAAd,CAAqBC,UAArB,CAAiC,CAClFF,WAAA,CAAYC,KAAZ,CAAA,CAAqBC,UACrBD,MAAA,EACA,OAAOA,MAH2E,CAOtF9N,MAAM0G,CAAAA,SAAUV,CAAAA,aAAhB,CAAgCkI,QAAS,CAACC,KAAD,CAAQ5D,OAAR,CAAiB,EAC1DvK,MAAM0G,CAAAA,SAAUP,CAAAA,qBAAhB,CAAwCiI,QAAS,CAACD,KAAD,CAAQ5D,OAAR,CAAiB,EAClEvK,MAAM0G,CAAAA,SAAUT,CAAAA,uBAAhB,CAA0CoI,QAAS,CAACF,KAAD,CAAQ5D,OAAR,CAAiB,CAChD,IAAhB,GAAIA,OAAJ,GACI4D,KAAM5D,CAAAA,OADV,CACoBA,OADpB,CADgE,CAMpEvK,MAAM0G,CAAAA,SAAUxB,CAAAA,KAAhB,CAAwBoJ,QAAS,CAAChE,OAAD,CAAUzD,IAAV,CAAgBuB,MAAhB,CAAwB,CACrD,MAAO,KAD8C,CAGzDpI,MAAM0G,CAAAA,SAAUvB,CAAAA,aAAhB,CAAgCoJ,QAAS,CAACjE,OAAD,CAAUzD,IAAV,CAAgBuB,MAAhB,CAAwB,CAE7D,MAAc,CAAA,CAAd,GADYkC,OAAQ3H,CAAAA,IAAR6L,CAAa3H,IAAb2H,CACZ,CACW3H,IAAK4F,CAAAA,SAAL,CAAerE,MAAf,CAAuBkC,OAAQqB,CAAAA,SAA/B,CADX;AAGO,IALsD,CAOjE3L,MAAM0G,CAAAA,SAAUpB,CAAAA,aAAhB,CAAgCmJ,QAAS,CAACnE,OAAD,CAAUzD,IAAV,CAAgB,CACjD6H,OAAAA,CAAcpE,OAAQK,CAAAA,IAAR,CAAa9D,IAAb,CAClB,OAAuB,KAAhB,GAAA6H,OAAA,CAAuBA,OAAA,CAAY,CAAZ,CAAvB,CAAwCA,OAFM,CAMzD1O,MAAM0G,CAAAA,SAAUnE,CAAAA,UAAhB,CAA6BoM,QAAS,CAACC,SAAD,CAAYC,SAAZ,CAAuB,CAGzD,GAA2B,CAAA,CAA3B,GAAI,IAAK7N,CAAAA,aAAT,CAAiC,CAC7B,IAAKsB,CAAAA,eAAL,EACA,KAAIwM,OAAavG,KAAJ,CAAU,IAAKjG,CAAAA,eAAf,CAAiC,CAAjC,CAAoCsC,CAAAA,IAApC,CAAyC,IAAzC,CACT,KAAKtC,CAAAA,eAAT,CAA2B,IAAKF,CAAAA,iBAAhC,EACI2M,OAAQC,CAAAA,GAAR,CAAYF,MAAZ,CAAqB,aAArB,CAA+BF,SAA/B,CAA2C,MAA3C,CAJyB,KAMzBK,GAAK9O,OAAQ+O,CAAAA,KAAR,CAAcL,SAAd,CAA0BM,UAAAA,CAAOF,EAAGE,CAAAA,IAAMpP,GAAAA,CAAQkP,EAAGlP,CAAAA,KAE9D,KAAIqP,YAAqB,EAAP,CAAAD,SAAA,CAAYJ,OAAQM,CAAAA,IAApB,CAA2BN,OAAQC,CAAAA,GACjD,KAAK1M,CAAAA,eAAT;AAA2B,IAAKF,CAAAA,iBAAhC,EACIgN,WAAA,CAAYN,MAAZ,CAAqB,aAArB,CAA+BF,SAA/B,CAA2C,aAA3C,CAAwDO,SAAxD,CAA+D,IAA/D,CAEJ,KAAK7M,CAAAA,eAAL,EACA,OAAOvC,GAbsB,CAgB7B,MAAO8O,UAAA,EAnB8C,CAsB7D7O,MAAMsP,CAAAA,OAAN,CAAgB,4LAEhBtP,MAAMuP,CAAAA,EAAN,CAAW,gBACX,OAAOvP,MA7mB4B,CAAZ,EA+mB3BJ,QAAQI,CAAAA,KAAR,CAAgBA,OAxpBqG;\",\n\"sources\":[\"node_modules/chevrotain/lib/src/scan/lexer_public.js\"],\n\"sourcesContent\":[\"shadow$provide[\\\"module$node_modules$chevrotain$lib$src$scan$lexer_public\\\"] = function(global,require,module,exports) {\\n\\\"use strict\\\";\\nObject.defineProperty(exports, \\\"__esModule\\\", { value: true });\\nexports.Lexer = exports.LexerDefinitionErrorType = void 0;\\nvar lexer_1 = require(\\\"./lexer\\\");\\nvar utils_1 = require(\\\"@chevrotain/utils\\\");\\nvar tokens_1 = require(\\\"./tokens\\\");\\nvar lexer_errors_public_1 = require(\\\"../scan/lexer_errors_public\\\");\\nvar reg_exp_parser_1 = require(\\\"./reg_exp_parser\\\");\\nvar LexerDefinitionErrorType;\\n(function (LexerDefinitionErrorType) {\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"MISSING_PATTERN\\\"] = 0] = \\\"MISSING_PATTERN\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"INVALID_PATTERN\\\"] = 1] = \\\"INVALID_PATTERN\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"EOI_ANCHOR_FOUND\\\"] = 2] = \\\"EOI_ANCHOR_FOUND\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"UNSUPPORTED_FLAGS_FOUND\\\"] = 3] = \\\"UNSUPPORTED_FLAGS_FOUND\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"DUPLICATE_PATTERNS_FOUND\\\"] = 4] = \\\"DUPLICATE_PATTERNS_FOUND\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"INVALID_GROUP_TYPE_FOUND\\\"] = 5] = \\\"INVALID_GROUP_TYPE_FOUND\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"PUSH_MODE_DOES_NOT_EXIST\\\"] = 6] = \\\"PUSH_MODE_DOES_NOT_EXIST\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\\\"] = 7] = \\\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\\\"] = 8] = \\\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\\\"] = 9] = \\\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\\\"] = 10] = \\\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"SOI_ANCHOR_FOUND\\\"] = 11] = \\\"SOI_ANCHOR_FOUND\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"EMPTY_MATCH_PATTERN\\\"] = 12] = \\\"EMPTY_MATCH_PATTERN\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"NO_LINE_BREAKS_FLAGS\\\"] = 13] = \\\"NO_LINE_BREAKS_FLAGS\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"UNREACHABLE_PATTERN\\\"] = 14] = \\\"UNREACHABLE_PATTERN\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"IDENTIFY_TERMINATOR\\\"] = 15] = \\\"IDENTIFY_TERMINATOR\\\";\\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\\\"CUSTOM_LINE_BREAK\\\"] = 16] = \\\"CUSTOM_LINE_BREAK\\\";\\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\\nvar DEFAULT_LEXER_CONFIG = {\\n    deferDefinitionErrorsHandling: false,\\n    positionTracking: \\\"full\\\",\\n    lineTerminatorsPattern: /\\\\n|\\\\r\\\\n?/g,\\n    lineTerminatorCharacters: [\\\"\\\\n\\\", \\\"\\\\r\\\"],\\n    ensureOptimizations: false,\\n    safeMode: false,\\n    errorMessageProvider: lexer_errors_public_1.defaultLexerErrorProvider,\\n    traceInitPerf: false,\\n    skipValidations: false\\n};\\nObject.freeze(DEFAULT_LEXER_CONFIG);\\nvar Lexer = /** @class */ (function () {\\n    function Lexer(lexerDefinition, config) {\\n        var _this = this;\\n        if (config === void 0) { config = DEFAULT_LEXER_CONFIG; }\\n        this.lexerDefinition = lexerDefinition;\\n        this.lexerDefinitionErrors = [];\\n        this.lexerDefinitionWarning = [];\\n        this.patternIdxToConfig = {};\\n        this.charCodeToPatternIdxToConfig = {};\\n        this.modes = [];\\n        this.emptyGroups = {};\\n        this.config = undefined;\\n        this.trackStartLines = true;\\n        this.trackEndLines = true;\\n        this.hasCustom = false;\\n        this.canModeBeOptimized = {};\\n        if (typeof config === \\\"boolean\\\") {\\n            throw Error(\\\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\\\n\\\" +\\n                \\\"a boolean 2nd argument is no longer supported\\\");\\n        }\\n        // todo: defaults func?\\n        this.config = utils_1.merge(DEFAULT_LEXER_CONFIG, config);\\n        var traceInitVal = this.config.traceInitPerf;\\n        if (traceInitVal === true) {\\n            this.traceInitMaxIdent = Infinity;\\n            this.traceInitPerf = true;\\n        }\\n        else if (typeof traceInitVal === \\\"number\\\") {\\n            this.traceInitMaxIdent = traceInitVal;\\n            this.traceInitPerf = true;\\n        }\\n        this.traceInitIndent = -1;\\n        this.TRACE_INIT(\\\"Lexer Constructor\\\", function () {\\n            var actualDefinition;\\n            var hasOnlySingleMode = true;\\n            _this.TRACE_INIT(\\\"Lexer Config handling\\\", function () {\\n                if (_this.config.lineTerminatorsPattern ===\\n                    DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\\n                    // optimized built-in implementation for the defaults definition of lineTerminators\\n                    _this.config.lineTerminatorsPattern = lexer_1.LineTerminatorOptimizedTester;\\n                }\\n                else {\\n                    if (_this.config.lineTerminatorCharacters ===\\n                        DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\\n                        throw Error(\\\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\\\n\\\" +\\n                            \\\"\\\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\\\");\\n                    }\\n                }\\n                if (config.safeMode && config.ensureOptimizations) {\\n                    throw Error('\\\"safeMode\\\" and \\\"ensureOptimizations\\\" flags are mutually exclusive.');\\n                }\\n                _this.trackStartLines = /full|onlyStart/i.test(_this.config.positionTracking);\\n                _this.trackEndLines = /full/i.test(_this.config.positionTracking);\\n                // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\\n                if (utils_1.isArray(lexerDefinition)) {\\n                    actualDefinition = { modes: {} };\\n                    actualDefinition.modes[lexer_1.DEFAULT_MODE] = utils_1.cloneArr(lexerDefinition);\\n                    actualDefinition[lexer_1.DEFAULT_MODE] = lexer_1.DEFAULT_MODE;\\n                }\\n                else {\\n                    // no conversion needed, input should already be a IMultiModeLexerDefinition\\n                    hasOnlySingleMode = false;\\n                    actualDefinition = utils_1.cloneObj(lexerDefinition);\\n                }\\n            });\\n            if (_this.config.skipValidations === false) {\\n                _this.TRACE_INIT(\\\"performRuntimeChecks\\\", function () {\\n                    _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat(lexer_1.performRuntimeChecks(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\\n                });\\n                _this.TRACE_INIT(\\\"performWarningRuntimeChecks\\\", function () {\\n                    _this.lexerDefinitionWarning = _this.lexerDefinitionWarning.concat(lexer_1.performWarningRuntimeChecks(actualDefinition, _this.trackStartLines, _this.config.lineTerminatorCharacters));\\n                });\\n            }\\n            // for extra robustness to avoid throwing an none informative error message\\n            actualDefinition.modes = actualDefinition.modes\\n                ? actualDefinition.modes\\n                : {};\\n            // an error of undefined TokenTypes will be detected in \\\"performRuntimeChecks\\\" above.\\n            // this transformation is to increase robustness in the case of partially invalid lexer definition.\\n            utils_1.forEach(actualDefinition.modes, function (currModeValue, currModeName) {\\n                actualDefinition.modes[currModeName] = utils_1.reject(currModeValue, function (currTokType) { return utils_1.isUndefined(currTokType); });\\n            });\\n            var allModeNames = utils_1.keys(actualDefinition.modes);\\n            utils_1.forEach(actualDefinition.modes, function (currModDef, currModName) {\\n                _this.TRACE_INIT(\\\"Mode: <\\\" + currModName + \\\"> processing\\\", function () {\\n                    _this.modes.push(currModName);\\n                    if (_this.config.skipValidations === false) {\\n                        _this.TRACE_INIT(\\\"validatePatterns\\\", function () {\\n                            _this.lexerDefinitionErrors = _this.lexerDefinitionErrors.concat(lexer_1.validatePatterns(currModDef, allModeNames));\\n                        });\\n                    }\\n                    // If definition errors were encountered, the analysis phase may fail unexpectedly/\\n                    // Considering a lexer with definition errors may never be used, there is no point\\n                    // to performing the analysis anyhow...\\n                    if (utils_1.isEmpty(_this.lexerDefinitionErrors)) {\\n                        tokens_1.augmentTokenTypes(currModDef);\\n                        var currAnalyzeResult_1;\\n                        _this.TRACE_INIT(\\\"analyzeTokenTypes\\\", function () {\\n                            currAnalyzeResult_1 = lexer_1.analyzeTokenTypes(currModDef, {\\n                                lineTerminatorCharacters: _this.config\\n                                    .lineTerminatorCharacters,\\n                                positionTracking: config.positionTracking,\\n                                ensureOptimizations: config.ensureOptimizations,\\n                                safeMode: config.safeMode,\\n                                tracer: _this.TRACE_INIT.bind(_this)\\n                            });\\n                        });\\n                        _this.patternIdxToConfig[currModName] =\\n                            currAnalyzeResult_1.patternIdxToConfig;\\n                        _this.charCodeToPatternIdxToConfig[currModName] =\\n                            currAnalyzeResult_1.charCodeToPatternIdxToConfig;\\n                        _this.emptyGroups = utils_1.merge(_this.emptyGroups, currAnalyzeResult_1.emptyGroups);\\n                        _this.hasCustom = currAnalyzeResult_1.hasCustom || _this.hasCustom;\\n                        _this.canModeBeOptimized[currModName] =\\n                            currAnalyzeResult_1.canBeOptimized;\\n                    }\\n                });\\n            });\\n            _this.defaultMode = actualDefinition.defaultMode;\\n            if (!utils_1.isEmpty(_this.lexerDefinitionErrors) &&\\n                !_this.config.deferDefinitionErrorsHandling) {\\n                var allErrMessages = utils_1.map(_this.lexerDefinitionErrors, function (error) {\\n                    return error.message;\\n                });\\n                var allErrMessagesString = allErrMessages.join(\\\"-----------------------\\\\n\\\");\\n                throw new Error(\\\"Errors detected in definition of Lexer:\\\\n\\\" + allErrMessagesString);\\n            }\\n            // Only print warning if there are no errors, This will avoid pl\\n            utils_1.forEach(_this.lexerDefinitionWarning, function (warningDescriptor) {\\n                utils_1.PRINT_WARNING(warningDescriptor.message);\\n            });\\n            _this.TRACE_INIT(\\\"Choosing sub-methods implementations\\\", function () {\\n                // Choose the relevant internal implementations for this specific parser.\\n                // These implementations should be in-lined by the JavaScript engine\\n                // to provide optimal performance in each scenario.\\n                if (lexer_1.SUPPORT_STICKY) {\\n                    _this.chopInput = utils_1.IDENTITY;\\n                    _this.match = _this.matchWithTest;\\n                }\\n                else {\\n                    _this.updateLastIndex = utils_1.NOOP;\\n                    _this.match = _this.matchWithExec;\\n                }\\n                if (hasOnlySingleMode) {\\n                    _this.handleModes = utils_1.NOOP;\\n                }\\n                if (_this.trackStartLines === false) {\\n                    _this.computeNewColumn = utils_1.IDENTITY;\\n                }\\n                if (_this.trackEndLines === false) {\\n                    _this.updateTokenEndLineColumnLocation = utils_1.NOOP;\\n                }\\n                if (/full/i.test(_this.config.positionTracking)) {\\n                    _this.createTokenInstance = _this.createFullToken;\\n                }\\n                else if (/onlyStart/i.test(_this.config.positionTracking)) {\\n                    _this.createTokenInstance = _this.createStartOnlyToken;\\n                }\\n                else if (/onlyOffset/i.test(_this.config.positionTracking)) {\\n                    _this.createTokenInstance = _this.createOffsetOnlyToken;\\n                }\\n                else {\\n                    throw Error(\\\"Invalid <positionTracking> config option: \\\\\\\"\\\" + _this.config.positionTracking + \\\"\\\\\\\"\\\");\\n                }\\n                if (_this.hasCustom) {\\n                    _this.addToken = _this.addTokenUsingPush;\\n                    _this.handlePayload = _this.handlePayloadWithCustom;\\n                }\\n                else {\\n                    _this.addToken = _this.addTokenUsingMemberAccess;\\n                    _this.handlePayload = _this.handlePayloadNoCustom;\\n                }\\n            });\\n            _this.TRACE_INIT(\\\"Failed Optimization Warnings\\\", function () {\\n                var unOptimizedModes = utils_1.reduce(_this.canModeBeOptimized, function (cannotBeOptimized, canBeOptimized, modeName) {\\n                    if (canBeOptimized === false) {\\n                        cannotBeOptimized.push(modeName);\\n                    }\\n                    return cannotBeOptimized;\\n                }, []);\\n                if (config.ensureOptimizations && !utils_1.isEmpty(unOptimizedModes)) {\\n                    throw Error(\\\"Lexer Modes: < \\\" + unOptimizedModes.join(\\\", \\\") + \\\" > cannot be optimized.\\\\n\\\" +\\n                        '\\\\t Disable the \\\"ensureOptimizations\\\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\\\n' +\\n                        \\\"\\\\t Or inspect the console log for details on how to resolve these issues.\\\");\\n                }\\n            });\\n            _this.TRACE_INIT(\\\"clearRegExpParserCache\\\", function () {\\n                reg_exp_parser_1.clearRegExpParserCache();\\n            });\\n            _this.TRACE_INIT(\\\"toFastProperties\\\", function () {\\n                utils_1.toFastProperties(_this);\\n            });\\n        });\\n    }\\n    Lexer.prototype.tokenize = function (text, initialMode) {\\n        if (initialMode === void 0) { initialMode = this.defaultMode; }\\n        if (!utils_1.isEmpty(this.lexerDefinitionErrors)) {\\n            var allErrMessages = utils_1.map(this.lexerDefinitionErrors, function (error) {\\n                return error.message;\\n            });\\n            var allErrMessagesString = allErrMessages.join(\\\"-----------------------\\\\n\\\");\\n            throw new Error(\\\"Unable to Tokenize because Errors detected in definition of Lexer:\\\\n\\\" +\\n                allErrMessagesString);\\n        }\\n        var lexResult = this.tokenizeInternal(text, initialMode);\\n        return lexResult;\\n    };\\n    // There is quite a bit of duplication between this and \\\"tokenizeInternalLazy\\\"\\n    // This is intentional due to performance considerations.\\n    Lexer.prototype.tokenizeInternal = function (text, initialMode) {\\n        var _this = this;\\n        var i, j, matchAltImage, longerAltIdx, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\\n        var orgText = text;\\n        var orgLength = orgText.length;\\n        var offset = 0;\\n        var matchedTokensIndex = 0;\\n        // initializing the tokensArray to the \\\"guessed\\\" size.\\n        // guessing too little will still reduce the number of array re-sizes on pushes.\\n        // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\\n        // but would still have a faster runtime by avoiding (All but one) array resizing.\\n        var guessedNumberOfTokens = this.hasCustom\\n            ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\\n            : Math.floor(text.length / 10);\\n        var matchedTokens = new Array(guessedNumberOfTokens);\\n        var errors = [];\\n        var line = this.trackStartLines ? 1 : undefined;\\n        var column = this.trackStartLines ? 1 : undefined;\\n        var groups = lexer_1.cloneEmptyGroups(this.emptyGroups);\\n        var trackLines = this.trackStartLines;\\n        var lineTerminatorPattern = this.config.lineTerminatorsPattern;\\n        var currModePatternsLength = 0;\\n        var patternIdxToConfig = [];\\n        var currCharCodeToPatternIdxToConfig = [];\\n        var modeStack = [];\\n        var emptyArray = [];\\n        Object.freeze(emptyArray);\\n        var getPossiblePatterns = undefined;\\n        function getPossiblePatternsSlow() {\\n            return patternIdxToConfig;\\n        }\\n        function getPossiblePatternsOptimized(charCode) {\\n            var optimizedCharIdx = lexer_1.charCodeToOptimizedIndex(charCode);\\n            var possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\\n            if (possiblePatterns === undefined) {\\n                return emptyArray;\\n            }\\n            else {\\n                return possiblePatterns;\\n            }\\n        }\\n        var pop_mode = function (popToken) {\\n            // TODO: perhaps avoid this error in the edge case there is no more input?\\n            if (modeStack.length === 1 &&\\n                // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \\\"transition\\\"\\n                // So no error should occur.\\n                popToken.tokenType.PUSH_MODE === undefined) {\\n                // if we try to pop the last mode there lexer will no longer have ANY mode.\\n                // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\\n                var msg_1 = _this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\\n                errors.push({\\n                    offset: popToken.startOffset,\\n                    line: popToken.startLine !== undefined ? popToken.startLine : undefined,\\n                    column: popToken.startColumn !== undefined\\n                        ? popToken.startColumn\\n                        : undefined,\\n                    length: popToken.image.length,\\n                    message: msg_1\\n                });\\n            }\\n            else {\\n                modeStack.pop();\\n                var newMode = utils_1.last(modeStack);\\n                patternIdxToConfig = _this.patternIdxToConfig[newMode];\\n                currCharCodeToPatternIdxToConfig = _this.charCodeToPatternIdxToConfig[newMode];\\n                currModePatternsLength = patternIdxToConfig.length;\\n                var modeCanBeOptimized = _this.canModeBeOptimized[newMode] && _this.config.safeMode === false;\\n                if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\\n                    getPossiblePatterns = getPossiblePatternsOptimized;\\n                }\\n                else {\\n                    getPossiblePatterns = getPossiblePatternsSlow;\\n                }\\n            }\\n        };\\n        function push_mode(newMode) {\\n            modeStack.push(newMode);\\n            currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\\n            patternIdxToConfig = this.patternIdxToConfig[newMode];\\n            currModePatternsLength = patternIdxToConfig.length;\\n            currModePatternsLength = patternIdxToConfig.length;\\n            var modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\\n            if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\\n                getPossiblePatterns = getPossiblePatternsOptimized;\\n            }\\n            else {\\n                getPossiblePatterns = getPossiblePatternsSlow;\\n            }\\n        }\\n        // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\\n        // seem to matter performance wise.\\n        push_mode.call(this, initialMode);\\n        var currConfig;\\n        while (offset < orgLength) {\\n            matchedImage = null;\\n            var nextCharCode = orgText.charCodeAt(offset);\\n            var chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\\n            var chosenPatternsLength = chosenPatternIdxToConfig.length;\\n            for (i = 0; i < chosenPatternsLength; i++) {\\n                currConfig = chosenPatternIdxToConfig[i];\\n                var currPattern = currConfig.pattern;\\n                payload = null;\\n                // manually in-lined because > 600 chars won't be in-lined in V8\\n                var singleCharCode = currConfig.short;\\n                if (singleCharCode !== false) {\\n                    if (nextCharCode === singleCharCode) {\\n                        // single character string\\n                        matchedImage = currPattern;\\n                    }\\n                }\\n                else if (currConfig.isCustom === true) {\\n                    match = currPattern.exec(orgText, offset, matchedTokens, groups);\\n                    if (match !== null) {\\n                        matchedImage = match[0];\\n                        if (match.payload !== undefined) {\\n                            payload = match.payload;\\n                        }\\n                    }\\n                    else {\\n                        matchedImage = null;\\n                    }\\n                }\\n                else {\\n                    this.updateLastIndex(currPattern, offset);\\n                    matchedImage = this.match(currPattern, text, offset);\\n                }\\n                if (matchedImage !== null) {\\n                    // even though this pattern matched we must try a another longer alternative.\\n                    // this can be used to prioritize keywords over identifiers\\n                    longerAltIdx = currConfig.longerAlt;\\n                    if (longerAltIdx !== undefined) {\\n                        // TODO: micro optimize, avoid extra prop access\\n                        // by saving/linking longerAlt on the original config?\\n                        var longerAltConfig = patternIdxToConfig[longerAltIdx];\\n                        var longerAltPattern = longerAltConfig.pattern;\\n                        altPayload = null;\\n                        // single Char can never be a longer alt so no need to test it.\\n                        // manually in-lined because > 600 chars won't be in-lined in V8\\n                        if (longerAltConfig.isCustom === true) {\\n                            match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\\n                            if (match !== null) {\\n                                matchAltImage = match[0];\\n                                if (match.payload !== undefined) {\\n                                    altPayload = match.payload;\\n                                }\\n                            }\\n                            else {\\n                                matchAltImage = null;\\n                            }\\n                        }\\n                        else {\\n                            this.updateLastIndex(longerAltPattern, offset);\\n                            matchAltImage = this.match(longerAltPattern, text, offset);\\n                        }\\n                        if (matchAltImage && matchAltImage.length > matchedImage.length) {\\n                            matchedImage = matchAltImage;\\n                            payload = altPayload;\\n                            currConfig = longerAltConfig;\\n                        }\\n                    }\\n                    break;\\n                }\\n            }\\n            // successful match\\n            if (matchedImage !== null) {\\n                imageLength = matchedImage.length;\\n                group = currConfig.group;\\n                if (group !== undefined) {\\n                    tokType = currConfig.tokenTypeIdx;\\n                    // TODO: \\\"offset + imageLength\\\" and the new column may be computed twice in case of \\\"full\\\" location information inside\\n                    // createFullToken method\\n                    newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\\n                    this.handlePayload(newToken, payload);\\n                    // TODO: optimize NOOP in case there are no special groups?\\n                    if (group === false) {\\n                        matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\\n                    }\\n                    else {\\n                        groups[group].push(newToken);\\n                    }\\n                }\\n                text = this.chopInput(text, imageLength);\\n                offset = offset + imageLength;\\n                // TODO: with newlines the column may be assigned twice\\n                column = this.computeNewColumn(column, imageLength);\\n                if (trackLines === true && currConfig.canLineTerminator === true) {\\n                    var numOfLTsInMatch = 0;\\n                    var foundTerminator = void 0;\\n                    var lastLTEndOffset = void 0;\\n                    lineTerminatorPattern.lastIndex = 0;\\n                    do {\\n                        foundTerminator = lineTerminatorPattern.test(matchedImage);\\n                        if (foundTerminator === true) {\\n                            lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\\n                            numOfLTsInMatch++;\\n                        }\\n                    } while (foundTerminator === true);\\n                    if (numOfLTsInMatch !== 0) {\\n                        line = line + numOfLTsInMatch;\\n                        column = imageLength - lastLTEndOffset;\\n                        this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\\n                    }\\n                }\\n                // will be NOOP if no modes present\\n                this.handleModes(currConfig, pop_mode, push_mode, newToken);\\n            }\\n            else {\\n                // error recovery, drop characters until we identify a valid token's start point\\n                var errorStartOffset = offset;\\n                var errorLine = line;\\n                var errorColumn = column;\\n                var foundResyncPoint = false;\\n                while (!foundResyncPoint && offset < orgLength) {\\n                    // drop chars until we succeed in matching something\\n                    droppedChar = orgText.charCodeAt(offset);\\n                    // Identity Func (when sticky flag is enabled)\\n                    text = this.chopInput(text, 1);\\n                    offset++;\\n                    for (j = 0; j < currModePatternsLength; j++) {\\n                        var currConfig_1 = patternIdxToConfig[j];\\n                        var currPattern = currConfig_1.pattern;\\n                        // manually in-lined because > 600 chars won't be in-lined in V8\\n                        var singleCharCode = currConfig_1.short;\\n                        if (singleCharCode !== false) {\\n                            if (orgText.charCodeAt(offset) === singleCharCode) {\\n                                // single character string\\n                                foundResyncPoint = true;\\n                            }\\n                        }\\n                        else if (currConfig_1.isCustom === true) {\\n                            foundResyncPoint =\\n                                currPattern.exec(orgText, offset, matchedTokens, groups) !==\\n                                    null;\\n                        }\\n                        else {\\n                            this.updateLastIndex(currPattern, offset);\\n                            foundResyncPoint = currPattern.exec(text) !== null;\\n                        }\\n                        if (foundResyncPoint === true) {\\n                            break;\\n                        }\\n                    }\\n                }\\n                errLength = offset - errorStartOffset;\\n                // at this point we either re-synced or reached the end of the input text\\n                msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\\n                errors.push({\\n                    offset: errorStartOffset,\\n                    line: errorLine,\\n                    column: errorColumn,\\n                    length: errLength,\\n                    message: msg\\n                });\\n            }\\n        }\\n        // if we do have custom patterns which push directly into the\\n        // TODO: custom tokens should not push directly??\\n        if (!this.hasCustom) {\\n            // if we guessed a too large size for the tokens array this will shrink it to the right size.\\n            matchedTokens.length = matchedTokensIndex;\\n        }\\n        return {\\n            tokens: matchedTokens,\\n            groups: groups,\\n            errors: errors\\n        };\\n    };\\n    Lexer.prototype.handleModes = function (config, pop_mode, push_mode, newToken) {\\n        if (config.pop === true) {\\n            // need to save the PUSH_MODE property as if the mode is popped\\n            // patternIdxToPopMode is updated to reflect the new mode after popping the stack\\n            var pushMode = config.push;\\n            pop_mode(newToken);\\n            if (pushMode !== undefined) {\\n                push_mode.call(this, pushMode);\\n            }\\n        }\\n        else if (config.push !== undefined) {\\n            push_mode.call(this, config.push);\\n        }\\n    };\\n    Lexer.prototype.chopInput = function (text, length) {\\n        return text.substring(length);\\n    };\\n    Lexer.prototype.updateLastIndex = function (regExp, newLastIndex) {\\n        regExp.lastIndex = newLastIndex;\\n    };\\n    // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\\n    Lexer.prototype.updateTokenEndLineColumnLocation = function (newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\\n        var lastCharIsLT, fixForEndingInLT;\\n        if (group !== undefined) {\\n            // a none skipped multi line Token, need to update endLine/endColumn\\n            lastCharIsLT = lastLTIdx === imageLength - 1;\\n            fixForEndingInLT = lastCharIsLT ? -1 : 0;\\n            if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\\n                // if a token ends in a LT that last LT only affects the line numbering of following Tokens\\n                newToken.endLine = line + fixForEndingInLT;\\n                // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\\n                // inclusive to exclusive range.\\n                newToken.endColumn = column - 1 + -fixForEndingInLT;\\n            }\\n            // else single LT in the last character of a token, no need to modify the endLine/EndColumn\\n        }\\n    };\\n    Lexer.prototype.computeNewColumn = function (oldColumn, imageLength) {\\n        return oldColumn + imageLength;\\n    };\\n    // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\\n    /* istanbul ignore next - place holder */\\n    Lexer.prototype.createTokenInstance = function () {\\n        var args = [];\\n        for (var _i = 0; _i < arguments.length; _i++) {\\n            args[_i] = arguments[_i];\\n        }\\n        return null;\\n    };\\n    Lexer.prototype.createOffsetOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType) {\\n        return {\\n            image: image,\\n            startOffset: startOffset,\\n            tokenTypeIdx: tokenTypeIdx,\\n            tokenType: tokenType\\n        };\\n    };\\n    Lexer.prototype.createStartOnlyToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\\n        return {\\n            image: image,\\n            startOffset: startOffset,\\n            startLine: startLine,\\n            startColumn: startColumn,\\n            tokenTypeIdx: tokenTypeIdx,\\n            tokenType: tokenType\\n        };\\n    };\\n    Lexer.prototype.createFullToken = function (image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\\n        return {\\n            image: image,\\n            startOffset: startOffset,\\n            endOffset: startOffset + imageLength - 1,\\n            startLine: startLine,\\n            endLine: startLine,\\n            startColumn: startColumn,\\n            endColumn: startColumn + imageLength - 1,\\n            tokenTypeIdx: tokenTypeIdx,\\n            tokenType: tokenType\\n        };\\n    };\\n    // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\\n    /* istanbul ignore next - place holder */\\n    Lexer.prototype.addToken = function (tokenVector, index, tokenToAdd) {\\n        return 666;\\n    };\\n    Lexer.prototype.addTokenUsingPush = function (tokenVector, index, tokenToAdd) {\\n        tokenVector.push(tokenToAdd);\\n        return index;\\n    };\\n    Lexer.prototype.addTokenUsingMemberAccess = function (tokenVector, index, tokenToAdd) {\\n        tokenVector[index] = tokenToAdd;\\n        index++;\\n        return index;\\n    };\\n    // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\\n    /* istanbul ignore next - place holder */\\n    Lexer.prototype.handlePayload = function (token, payload) { };\\n    Lexer.prototype.handlePayloadNoCustom = function (token, payload) { };\\n    Lexer.prototype.handlePayloadWithCustom = function (token, payload) {\\n        if (payload !== null) {\\n            token.payload = payload;\\n        }\\n    };\\n    /* istanbul ignore next - place holder to be replaced with chosen alternative at runtime */\\n    Lexer.prototype.match = function (pattern, text, offset) {\\n        return null;\\n    };\\n    Lexer.prototype.matchWithTest = function (pattern, text, offset) {\\n        var found = pattern.test(text);\\n        if (found === true) {\\n            return text.substring(offset, pattern.lastIndex);\\n        }\\n        return null;\\n    };\\n    Lexer.prototype.matchWithExec = function (pattern, text) {\\n        var regExpArray = pattern.exec(text);\\n        return regExpArray !== null ? regExpArray[0] : regExpArray;\\n    };\\n    // Duplicated from the parser's perf trace trait to allow future extraction\\n    // of the lexer to a separate package.\\n    Lexer.prototype.TRACE_INIT = function (phaseDesc, phaseImpl) {\\n        // No need to optimize this using NOOP pattern because\\n        // It is not called in a hot spot...\\n        if (this.traceInitPerf === true) {\\n            this.traceInitIndent++;\\n            var indent = new Array(this.traceInitIndent + 1).join(\\\"\\\\t\\\");\\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\\n                console.log(indent + \\\"--\\u003e <\\\" + phaseDesc + \\\">\\\");\\n            }\\n            var _a = utils_1.timer(phaseImpl), time = _a.time, value = _a.value;\\n            /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\\n            var traceMethod = time > 10 ? console.warn : console.log;\\n            if (this.traceInitIndent < this.traceInitMaxIdent) {\\n                traceMethod(indent + \\\"<-- <\\\" + phaseDesc + \\\"> time: \\\" + time + \\\"ms\\\");\\n            }\\n            this.traceInitIndent--;\\n            return value;\\n        }\\n        else {\\n            return phaseImpl();\\n        }\\n    };\\n    Lexer.SKIPPED = \\\"This marks a skipped Token pattern, this means each token identified by it will\\\" +\\n        \\\"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\\\";\\n    Lexer.NA = /NOT_APPLICABLE/;\\n    return Lexer;\\n}());\\nexports.Lexer = Lexer;\\n//# sourceMappingURL=lexer_public.js.map\\n};\"],\n\"names\":[\"shadow$provide\",\"global\",\"require\",\"module\",\"exports\",\"Object\",\"defineProperty\",\"value\",\"Lexer\",\"LexerDefinitionErrorType\",\"lexer_1\",\"utils_1\",\"tokens_1\",\"lexer_errors_public_1\",\"reg_exp_parser_1\",\"DEFAULT_LEXER_CONFIG\",\"deferDefinitionErrorsHandling\",\"positionTracking\",\"lineTerminatorsPattern\",\"lineTerminatorCharacters\",\"ensureOptimizations\",\"safeMode\",\"errorMessageProvider\",\"defaultLexerErrorProvider\",\"traceInitPerf\",\"skipValidations\",\"freeze\",\"lexerDefinition\",\"config\",\"_this\",\"lexerDefinitionErrors\",\"lexerDefinitionWarning\",\"patternIdxToConfig\",\"charCodeToPatternIdxToConfig\",\"modes\",\"emptyGroups\",\"undefined\",\"trackEndLines\",\"trackStartLines\",\"hasCustom\",\"canModeBeOptimized\",\"Error\",\"merge\",\"traceInitVal\",\"traceInitMaxIdent\",\"Infinity\",\"traceInitIndent\",\"TRACE_INIT\",\"actualDefinition\",\"hasOnlySingleMode\",\"LineTerminatorOptimizedTester\",\"test\",\"isArray\",\"DEFAULT_MODE\",\"cloneArr\",\"cloneObj\",\"concat\",\"performRuntimeChecks\",\"performWarningRuntimeChecks\",\"forEach\",\"currModeValue\",\"currModeName\",\"reject\",\"currTokType\",\"isUndefined\",\"allModeNames\",\"keys\",\"currModDef\",\"currModName\",\"push\",\"validatePatterns\",\"isEmpty\",\"augmentTokenTypes\",\"currAnalyzeResult_1\",\"analyzeTokenTypes\",\"tracer\",\"bind\",\"canBeOptimized\",\"defaultMode\",\"allErrMessagesString\",\"map\",\"allErrMessages\",\"error\",\"message\",\"join\",\"warningDescriptor\",\"PRINT_WARNING\",\"SUPPORT_STICKY\",\"chopInput\",\"IDENTITY\",\"match\",\"matchWithTest\",\"updateLastIndex\",\"NOOP\",\"matchWithExec\",\"handleModes\",\"computeNewColumn\",\"updateTokenEndLineColumnLocation\",\"createTokenInstance\",\"createFullToken\",\"createStartOnlyToken\",\"createOffsetOnlyToken\",\"addToken\",\"addTokenUsingPush\",\"handlePayload\",\"handlePayloadWithCustom\",\"addTokenUsingMemberAccess\",\"handlePayloadNoCustom\",\"unOptimizedModes\",\"reduce\",\"cannotBeOptimized\",\"modeName\",\"clearRegExpParserCache\",\"toFastProperties\",\"prototype\",\"tokenize\",\"Lexer.prototype.tokenize\",\"text\",\"initialMode\",\"tokenizeInternal\",\"lexResult\",\"Lexer.prototype.tokenizeInternal\",\"getPossiblePatternsSlow\",\"getPossiblePatternsOptimized\",\"charCode\",\"optimizedCharIdx\",\"charCodeToOptimizedIndex\",\"possiblePatterns\",\"currCharCodeToPatternIdxToConfig\",\"emptyArray\",\"push_mode\",\"newMode\",\"modeStack\",\"currModePatternsLength\",\"length\",\"modeCanBeOptimized\",\"getPossiblePatterns\",\"i\",\"orgText\",\"orgLength\",\"offset\",\"matchedTokensIndex\",\"matchedTokens\",\"Array\",\"guessedNumberOfTokens\",\"Math\",\"floor\",\"errors\",\"line\",\"column\",\"groups\",\"cloneEmptyGroups\",\"trackLines\",\"lineTerminatorPattern\",\"pop_mode\",\"popToken\",\"tokenType\",\"PUSH_MODE\",\"msg_1\",\"buildUnableToPopLexerModeMessage\",\"startOffset\",\"startLine\",\"startColumn\",\"image\",\"pop\",\"last\",\"call\",\"currConfig\",\"matchedImage\",\"nextCharCode\",\"charCodeAt\",\"chosenPatternIdxToConfig\",\"chosenPatternsLength\",\"currPattern\",\"pattern\",\"payload\",\"singleCharCode\",\"short\",\"isCustom\",\"exec\",\"longerAltIdx\",\"longerAlt\",\"longerAltConfig\",\"longerAltPattern\",\"altPayload\",\"matchAltImage\",\"imageLength\",\"group\",\"tokType\",\"tokenTypeIdx\",\"newToken\",\"canLineTerminator\",\"numOfLTsInMatch\",\"lastLTEndOffset\",\"foundTerminator\",\"lastIndex\",\"errorStartOffset\",\"errorLine\",\"errorColumn\",\"foundResyncPoint\",\"j\",\"currConfig_1\",\"errLength\",\"msg\",\"buildUnexpectedCharactersMessage\",\"tokens\",\"Lexer.prototype.handleModes\",\"pushMode\",\"Lexer.prototype.chopInput\",\"substring\",\"Lexer.prototype.updateLastIndex\",\"regExp\",\"newLastIndex\",\"Lexer.prototype.updateTokenEndLineColumnLocation\",\"lastLTIdx\",\"fixForEndingInLT\",\"lastCharIsLT\",\"endLine\",\"endColumn\",\"Lexer.prototype.computeNewColumn\",\"oldColumn\",\"Lexer.prototype.createTokenInstance\",\"_i\",\"arguments\",\"Lexer.prototype.createOffsetOnlyToken\",\"Lexer.prototype.createStartOnlyToken\",\"Lexer.prototype.createFullToken\",\"endOffset\",\"Lexer.prototype.addToken\",\"tokenVector\",\"index\",\"tokenToAdd\",\"Lexer.prototype.addTokenUsingPush\",\"Lexer.prototype.addTokenUsingMemberAccess\",\"Lexer.prototype.handlePayload\",\"token\",\"Lexer.prototype.handlePayloadNoCustom\",\"Lexer.prototype.handlePayloadWithCustom\",\"Lexer.prototype.match\",\"Lexer.prototype.matchWithTest\",\"found\",\"Lexer.prototype.matchWithExec\",\"regExpArray\",\"Lexer.prototype.TRACE_INIT\",\"phaseDesc\",\"phaseImpl\",\"indent\",\"console\",\"log\",\"_a\",\"timer\",\"time\",\"traceMethod\",\"warn\",\"SKIPPED\",\"NA\"]\n}\n"]