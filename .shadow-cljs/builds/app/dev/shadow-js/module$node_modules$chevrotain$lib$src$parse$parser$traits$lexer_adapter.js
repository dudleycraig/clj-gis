["^ ","~:resource-id",["~:shadow.build.npm/resource","node_modules/chevrotain/lib/src/parse/parser/traits/lexer_adapter.js"],"~:js","shadow$provide.module$node_modules$chevrotain$lib$src$parse$parser$traits$lexer_adapter=function(global,require,module,exports){Object.defineProperty(exports,\"__esModule\",{value:!0});exports.LexerAdapter=void 0;var parser_1=require(\"module$node_modules$chevrotain$lib$src$parse$parser$parser\");global=function(){function LexerAdapter(){}LexerAdapter.prototype.initLexerAdapter=function(){this.tokVector=[];this.tokVectorLength=0;this.currIdx=-1};Object.defineProperty(LexerAdapter.prototype,\"input\",{get:function(){return this.tokVector},\nset:function(newInput){if(!0!==this.selfAnalysisDone)throw Error(\"Missing \\x3cperformSelfAnalysis\\x3e invocation at the end of the Parser's constructor.\");this.reset();this.tokVector=newInput;this.tokVectorLength=newInput.length},enumerable:!1,configurable:!0});LexerAdapter.prototype.SKIP_TOKEN=function(){return this.currIdx<=this.tokVector.length-2?(this.consumeToken(),this.LA(1)):parser_1.END_OF_FILE};LexerAdapter.prototype.LA=function(howMuch){howMuch=this.currIdx+howMuch;return 0>howMuch||this.tokVectorLength<=\nhowMuch?parser_1.END_OF_FILE:this.tokVector[howMuch]};LexerAdapter.prototype.consumeToken=function(){this.currIdx++};LexerAdapter.prototype.exportLexerState=function(){return this.currIdx};LexerAdapter.prototype.importLexerState=function(newState){this.currIdx=newState};LexerAdapter.prototype.resetLexerState=function(){this.currIdx=-1};LexerAdapter.prototype.moveToTerminatedState=function(){this.currIdx=this.tokVector.length-1};LexerAdapter.prototype.getLexerPosition=function(){return this.exportLexerState()};\nreturn LexerAdapter}();exports.LexerAdapter=global}","~:source","shadow$provide[\"module$node_modules$chevrotain$lib$src$parse$parser$traits$lexer_adapter\"] = function(global,require,module,exports) {\n\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.LexerAdapter = void 0;\nvar parser_1 = require(\"../parser\");\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nvar LexerAdapter = /** @class */ (function () {\n    function LexerAdapter() {\n    }\n    LexerAdapter.prototype.initLexerAdapter = function () {\n        this.tokVector = [];\n        this.tokVectorLength = 0;\n        this.currIdx = -1;\n    };\n    Object.defineProperty(LexerAdapter.prototype, \"input\", {\n        get: function () {\n            return this.tokVector;\n        },\n        set: function (newInput) {\n            // @ts-ignore - `this parameter` not supported in setters/getters\n            //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n            if (this.selfAnalysisDone !== true) {\n                throw Error(\"Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.\");\n            }\n            // @ts-ignore - `this parameter` not supported in setters/getters\n            //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n            this.reset();\n            this.tokVector = newInput;\n            this.tokVectorLength = newInput.length;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    // skips a token and returns the next token\n    LexerAdapter.prototype.SKIP_TOKEN = function () {\n        if (this.currIdx <= this.tokVector.length - 2) {\n            this.consumeToken();\n            return this.LA(1);\n        }\n        else {\n            return parser_1.END_OF_FILE;\n        }\n    };\n    // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n    // or lexers dependent on parser context.\n    LexerAdapter.prototype.LA = function (howMuch) {\n        var soughtIdx = this.currIdx + howMuch;\n        if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n            return parser_1.END_OF_FILE;\n        }\n        else {\n            return this.tokVector[soughtIdx];\n        }\n    };\n    LexerAdapter.prototype.consumeToken = function () {\n        this.currIdx++;\n    };\n    LexerAdapter.prototype.exportLexerState = function () {\n        return this.currIdx;\n    };\n    LexerAdapter.prototype.importLexerState = function (newState) {\n        this.currIdx = newState;\n    };\n    LexerAdapter.prototype.resetLexerState = function () {\n        this.currIdx = -1;\n    };\n    LexerAdapter.prototype.moveToTerminatedState = function () {\n        this.currIdx = this.tokVector.length - 1;\n    };\n    LexerAdapter.prototype.getLexerPosition = function () {\n        return this.exportLexerState();\n    };\n    return LexerAdapter;\n}());\nexports.LexerAdapter = LexerAdapter;\n//# sourceMappingURL=lexer_adapter.js.map\n};","~:removed-requires",["~#set",[]],"~:actual-requires",["^5",["~$shadow.js","~$module$node_modules$chevrotain$lib$src$parse$parser$parser"]],"~:properties",["^5",["SKIP_TOKEN","exportLexerState","__esModule","importLexerState","getLexerPosition","configurable","value","enumerable","tokVector","initLexerAdapter","moveToTerminatedState","input","LA","currIdx","set","LexerAdapter","resetLexerState","get","tokVectorLength","consumeToken"]],"~:compiled-at",1630917515707,"~:source-map-json","{\n\"version\":3,\n\"file\":\"module$node_modules$chevrotain$lib$src$parse$parser$traits$lexer_adapter.js\",\n\"lineCount\":4,\n\"mappings\":\"AAAAA,cAAA,CAAA,wEAAA,CAA6F,QAAQ,CAACC,MAAD,CAAQC,OAAR,CAAgBC,MAAhB,CAAuBC,OAAvB,CAAgC,CAErIC,MAAOC,CAAAA,cAAP,CAAsBF,OAAtB,CAA+B,YAA/B,CAA6C,CAAEG,MAAO,CAAA,CAAT,CAA7C,CACAH,QAAQI,CAAAA,YAAR,CAAuB,IAAK,EAC5B,KAAIC,SAAWP,OAAA,CAAQ,4DAAR,CAQXM,OAAAA,CAA8B,QAAS,EAAG,CAC1CA,QAASA,aAAY,EAAG,EAExBA,YAAaE,CAAAA,SAAUC,CAAAA,gBAAvB,CAA0CC,QAAS,EAAG,CAClD,IAAKC,CAAAA,SAAL,CAAiB,EACjB,KAAKC,CAAAA,eAAL,CAAuB,CACvB,KAAKC,CAAAA,OAAL,CAAe,EAHmC,CAKtDV,OAAOC,CAAAA,cAAP,CAAsBE,YAAaE,CAAAA,SAAnC,CAA8C,OAA9C,CAAuD,CACnDM,IAAKA,QAAS,EAAG,CACb,MAAO,KAAKH,CAAAA,SADC,CADkC;AAInDI,IAAKA,QAAS,CAACC,QAAD,CAAW,CAGrB,GAA8B,CAAA,CAA9B,GAAI,IAAKC,CAAAA,gBAAT,CACI,KAAMC,MAAA,CAAM,wFAAN,CAAN,CAIJ,IAAKC,CAAAA,KAAL,EACA,KAAKR,CAAAA,SAAL,CAAiBK,QACjB,KAAKJ,CAAAA,eAAL,CAAuBI,QAASI,CAAAA,MAVX,CAJ0B,CAgBnDC,WAAY,CAAA,CAhBuC,CAiBnDC,aAAc,CAAA,CAjBqC,CAAvD,CAoBAhB,aAAaE,CAAAA,SAAUe,CAAAA,UAAvB,CAAoCC,QAAS,EAAG,CAC5C,MAAI,KAAKX,CAAAA,OAAT,EAAoB,IAAKF,CAAAA,SAAUS,CAAAA,MAAnC,CAA4C,CAA5C,EACI,IAAKK,CAAAA,YAAL,EACO,CAAA,IAAKC,CAAAA,EAAL,CAAQ,CAAR,CAFX,EAKWnB,QAASoB,CAAAA,WANwB,CAWhDrB,aAAaE,CAAAA,SAAUkB,CAAAA,EAAvB,CAA4BE,QAAS,CAACC,OAAD,CAAU,CACvCC,OAAAA,CAAY,IAAKjB,CAAAA,OAAjBiB,CAA2BD,OAC/B,OAAgB,EAAhB,CAAIC,OAAJ,EAAqB,IAAKlB,CAAAA,eAA1B;AAA6CkB,OAA7C,CACWvB,QAASoB,CAAAA,WADpB,CAIW,IAAKhB,CAAAA,SAAL,CAAemB,OAAf,CANgC,CAS/CxB,aAAaE,CAAAA,SAAUiB,CAAAA,YAAvB,CAAsCM,QAAS,EAAG,CAC9C,IAAKlB,CAAAA,OAAL,EAD8C,CAGlDP,aAAaE,CAAAA,SAAUwB,CAAAA,gBAAvB,CAA0CC,QAAS,EAAG,CAClD,MAAO,KAAKpB,CAAAA,OADsC,CAGtDP,aAAaE,CAAAA,SAAU0B,CAAAA,gBAAvB,CAA0CC,QAAS,CAACC,QAAD,CAAW,CAC1D,IAAKvB,CAAAA,OAAL,CAAeuB,QAD2C,CAG9D9B,aAAaE,CAAAA,SAAU6B,CAAAA,eAAvB,CAAyCC,QAAS,EAAG,CACjD,IAAKzB,CAAAA,OAAL,CAAe,EADkC,CAGrDP,aAAaE,CAAAA,SAAU+B,CAAAA,qBAAvB,CAA+CC,QAAS,EAAG,CACvD,IAAK3B,CAAAA,OAAL,CAAe,IAAKF,CAAAA,SAAUS,CAAAA,MAA9B,CAAuC,CADgB,CAG3Dd,aAAaE,CAAAA,SAAUiC,CAAAA,gBAAvB,CAA0CC,QAAS,EAAG,CAClD,MAAO,KAAKV,CAAAA,gBAAL,EAD2C,CAGtD;MAAO1B,aAlEmC,CAAZ,EAoElCJ,QAAQI,CAAAA,YAAR,CAAuBA,MAhF8G;\",\n\"sources\":[\"node_modules/chevrotain/lib/src/parse/parser/traits/lexer_adapter.js\"],\n\"sourcesContent\":[\"shadow$provide[\\\"module$node_modules$chevrotain$lib$src$parse$parser$traits$lexer_adapter\\\"] = function(global,require,module,exports) {\\n\\\"use strict\\\";\\nObject.defineProperty(exports, \\\"__esModule\\\", { value: true });\\nexports.LexerAdapter = void 0;\\nvar parser_1 = require(\\\"../parser\\\");\\n/**\\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\\n *\\n * This could be generalized to support other kinds of lexers, e.g.\\n * - Just in Time Lexing / Lexer-Less parsing.\\n * - Streaming Lexer.\\n */\\nvar LexerAdapter = /** @class */ (function () {\\n    function LexerAdapter() {\\n    }\\n    LexerAdapter.prototype.initLexerAdapter = function () {\\n        this.tokVector = [];\\n        this.tokVectorLength = 0;\\n        this.currIdx = -1;\\n    };\\n    Object.defineProperty(LexerAdapter.prototype, \\\"input\\\", {\\n        get: function () {\\n            return this.tokVector;\\n        },\\n        set: function (newInput) {\\n            // @ts-ignore - `this parameter` not supported in setters/getters\\n            //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\\n            if (this.selfAnalysisDone !== true) {\\n                throw Error(\\\"Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.\\\");\\n            }\\n            // @ts-ignore - `this parameter` not supported in setters/getters\\n            //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\\n            this.reset();\\n            this.tokVector = newInput;\\n            this.tokVectorLength = newInput.length;\\n        },\\n        enumerable: false,\\n        configurable: true\\n    });\\n    // skips a token and returns the next token\\n    LexerAdapter.prototype.SKIP_TOKEN = function () {\\n        if (this.currIdx <= this.tokVector.length - 2) {\\n            this.consumeToken();\\n            return this.LA(1);\\n        }\\n        else {\\n            return parser_1.END_OF_FILE;\\n        }\\n    };\\n    // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\\n    // or lexers dependent on parser context.\\n    LexerAdapter.prototype.LA = function (howMuch) {\\n        var soughtIdx = this.currIdx + howMuch;\\n        if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\\n            return parser_1.END_OF_FILE;\\n        }\\n        else {\\n            return this.tokVector[soughtIdx];\\n        }\\n    };\\n    LexerAdapter.prototype.consumeToken = function () {\\n        this.currIdx++;\\n    };\\n    LexerAdapter.prototype.exportLexerState = function () {\\n        return this.currIdx;\\n    };\\n    LexerAdapter.prototype.importLexerState = function (newState) {\\n        this.currIdx = newState;\\n    };\\n    LexerAdapter.prototype.resetLexerState = function () {\\n        this.currIdx = -1;\\n    };\\n    LexerAdapter.prototype.moveToTerminatedState = function () {\\n        this.currIdx = this.tokVector.length - 1;\\n    };\\n    LexerAdapter.prototype.getLexerPosition = function () {\\n        return this.exportLexerState();\\n    };\\n    return LexerAdapter;\\n}());\\nexports.LexerAdapter = LexerAdapter;\\n//# sourceMappingURL=lexer_adapter.js.map\\n};\"],\n\"names\":[\"shadow$provide\",\"global\",\"require\",\"module\",\"exports\",\"Object\",\"defineProperty\",\"value\",\"LexerAdapter\",\"parser_1\",\"prototype\",\"initLexerAdapter\",\"LexerAdapter.prototype.initLexerAdapter\",\"tokVector\",\"tokVectorLength\",\"currIdx\",\"get\",\"set\",\"newInput\",\"selfAnalysisDone\",\"Error\",\"reset\",\"length\",\"enumerable\",\"configurable\",\"SKIP_TOKEN\",\"LexerAdapter.prototype.SKIP_TOKEN\",\"consumeToken\",\"LA\",\"END_OF_FILE\",\"LexerAdapter.prototype.LA\",\"howMuch\",\"soughtIdx\",\"LexerAdapter.prototype.consumeToken\",\"exportLexerState\",\"LexerAdapter.prototype.exportLexerState\",\"importLexerState\",\"LexerAdapter.prototype.importLexerState\",\"newState\",\"resetLexerState\",\"LexerAdapter.prototype.resetLexerState\",\"moveToTerminatedState\",\"LexerAdapter.prototype.moveToTerminatedState\",\"getLexerPosition\",\"LexerAdapter.prototype.getLexerPosition\"]\n}\n"]